{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skquark/AI-Friends/blob/main/Stable_Diffusion_Deluxe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49n2AC6spxQS"
      },
      "source": [
        "# üé® **Stable Diffusion Deluxe Edition** üë®‚Äçüé®Ô∏è - Full Featured Fancy Flet/Flutter Framework\n",
        "\n",
        "*...using `üß®diffusers`* and many advanced bonus features...\n",
        "\n",
        "---\n",
        "### Designed by [**Skquark**, Inc.](https://www.Skquark.com) üòã\n",
        "<p align=center>\n",
        "<a href=\"https://github.com/Skquark/AI-Friends/blob/main/Stable_Diffusion_Deluxe.ipynb\"><img src=\"https://badgen.net/badge/icon/github?icon=github&label\" alt=\"Github\"></a> <a href=\"https://github.com/Skquark/AI-Friends\"><img src=\"https://badgen.net/github/release/Skquark/AI-Friends/stable\" alt=\"Release version\"></a>\n",
        "<a href=\"https://colab.research.google.com/github/Skquark/AI-Friends/blob/main/Stable_Diffusion_Deluxe.ipynb\"><img src=\"https://img.shields.io/badge/Open-in%20Colab-brightgreen?logo=google-colab&style=flat-square\" alt=\"Open in Google Colab\"/></a>\n",
        "</p>\n",
        "\n",
        "*   Runs in a pretty WebUI using [Flet - Flutter for Python](https://flet.dev) with themes, interactivity & sound\n",
        "*   Saves all settings/parameters in your config file, don't need to Copy to Drive\n",
        "*   Run a batch list of prompts at once, so queue many and walk away\n",
        "*   Option to override any parameter per prompt in queue\n",
        "*   Use Stable Diffusion [2.1](https://huggingface.co/stabilityai/stable-diffusion-2-1), [2.0](https://huggingface.co/stabilityai/stable-diffusion-2), [1.5 ](https://huggingface.co/runwayml/stable-diffusion-v1-5), or [1.4](https://huggingface.co/CompVis/stable-diffusion-v1-4) Checkpoint Model File\n",
        "*   Supports many custom community Finetuned Model checkpoints & DreamBooth Libraries\n",
        "*   Supports Stable Diffusion image2image to use an init_image\n",
        "*   Supports Stable Diffusion [Inpaint](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting) mask_image layer\n",
        "*   Supports Negative Prompts to specify what you don't want\n",
        "*   Supports Long Prompt Weighting to emphasize (positive) & [negative] word strengths\n",
        "*   Prompt tweening to combine latent space of 2 prompts in a series\n",
        "*   Can use Interpolation to walk steps between latent space of prompt list\n",
        "*   Can use CLIP Guidance with LAION & OpenAI ViT models\n",
        "*   Can use Textual Inversion Conceptualizer with 760+ Community Concepts\n",
        "*   Can Centipede prompts as init images feeding down the list\n",
        "*   Can use Composable weighted | prompt | segments for img2img\n",
        "*   Can use iMagic to edit init image with your prompt \n",
        "*   Can save all images to your Google Drive (PyDrive support soon)\n",
        "*   Can Upscale automatically with Real-ESRGAN enlarging\n",
        "*   Option to use Stability-API tokens for more samplers, bigger size & CPU runtime\n",
        "*   Embeds exif metadata directly into png files\n",
        "*   Disabled NSFW filtering and added custom sampler options\n",
        "*   Renames image filenames to the prompt text, with options\n",
        "*   OpenAI Prompt Generator, Remixer, Brainstormer & Noodle Soup Prompt Writer included\n",
        "*   Standalone ESRGAN Upscaler for batch uploads and image splitting\n",
        "*   Train your own models with DreamBooth or Textual-Inversion & upload to HuggingFace\n",
        "*   Replicate Material Diffusion to make Seamless Tile Textures\n",
        "*   Experimental HarmonAI Dance Diffusion audio generator\n",
        "*   Experimental DreamFusion 3D model generator with texture & video\n",
        "*   Image2Text CLIP-Interrogator to get prompt from images\n",
        "*   Bonus Image Generators DALL-E 2 and Kandinsky 2 to compare\n",
        "*   Additional features added regularly...\n",
        "\n",
        "Can also use origional Colab implementation of [Enhanced Stable Diffusion](https://colab.research.google.com/github/Skquark/structured-prompt-generator/blob/main/Enhanced_Stable_Diffusion_with_diffusers.ipynb) instead..\n",
        "\n",
        "Try these other useful notebooks [Enhanced DiscoArt](https://colab.research.google.com/github/Skquark/structured-prompt-generator/blob/main/DiscoArt_%5B_w_Batch_Prompts_%26_GPT_3_Generator%5D.ipynb) and [Structured Prompt Generator](https://colab.research.google.com/github/Skquark/structured-prompt-generator/blob/main/Structured_Prompt_Generator.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jf90tMc3tu9q"
      },
      "outputs": [],
      "source": [
        "#@title üñ•Ô∏è Check GPU Status (A100 > G100 > V100 > P100 > T4 > K8)\n",
        "import subprocess\n",
        "simple_nvidia_smi_display = True #@param {type:\"boolean\"}\n",
        "if simple_nvidia_smi_display:\n",
        "    print(subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "else:\n",
        "    print(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    print(subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EH3ClNnvV1S"
      },
      "source": [
        "# üß∞ **Stable Diffusion Deluxe** - Easy Web App Launcher\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KTwZrpxEuKR0"
      },
      "outputs": [],
      "source": [
        "#@title ## ‚öôÔ∏è Install WebUI Framework & Initiallize Settings\n",
        "#markdown If you're running on Google Colab, authorize Google Drive with the popup to connect storage. If you're on a local or cloud Jupyter Notebook, you must get a OAuth json using instructions below to save images to GDrive, however the feature is not currently working and in progress. When set, continue to run the Web UI and experiment away..\n",
        "#@markdown We'll connect to your Google Drive and save all of your preferences in realtime there, as well as your created images. This is the folder location and file name we recommend in your mounted gdrive, will be created if you're new, but you can save elsewhere.  Launches webpage with localtunnel, but in case it's down you can use ngrok instead.\n",
        "storage_type = \"Colab Google Drive\" #@param [\"Colab Google Drive\", \"PyDrive Google Drive\", \"Local Drive\"]\n",
        "Google_OAuth_client_secret_json = \"/content/client_secrets.json\" #param {'type': 'string'}\n",
        "save_to_GDrive = True #param {'type': 'boolean'}\n",
        "saved_settings_json = '/content/drive/MyDrive/AI/Stable_Diffusion/sdd-settings.json' #@param {'type': 'string'}\n",
        "tunnel_type = \"localtunnel\" #@param [\"localtunnel\", \"ngrok\"] \n",
        "#, \"cloudflared\"\n",
        "auto_launch_website = True #@param {'type': 'boolean'}\n",
        "version = \"v1.6.0\"\n",
        "import os, subprocess, sys, shutil\n",
        "root_dir = '/content/'\n",
        "dist_dir = root_dir\n",
        "is_Colab = True\n",
        "try:\n",
        "  import google.colab\n",
        "  root_dir = '/content/'\n",
        "except:\n",
        "  root_dir = os.getcwd()\n",
        "  dist_dir = os.path.join(root_dir, 'dist', 'Stable-Diffusion-Deluxe')\n",
        "  if not os.path.isdir(dist_dir):\n",
        "    dist_dir = root_dir\n",
        "  print(f'Root: {root_dir} Dist:{dist_dir}')\n",
        "  is_Colab = False\n",
        "  pass\n",
        "stable_dir = root_dir\n",
        "save_to_GDrive = storage_type == \"Colab Google Drive\"\n",
        "if save_to_GDrive:\n",
        "  if not os.path.isdir(f'{root_dir}drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "elif storage_type == \"PyDrive Google Drive\":\n",
        "  \"pip install PyDrive2\"\n",
        "stable_dir = os.path.join(root_dir, 'Stable_Diffusion')\n",
        "if not os.path.exists(stable_dir):\n",
        "  os.makedirs(stable_dir)\n",
        "#if not os.path.exists(image_output):\n",
        "#  os.makedirs(image_output)\n",
        "sample_data = '/content/sample_data'\n",
        "if os.path.exists(sample_data):\n",
        "  for f in os.listdir(sample_data):\n",
        "    os.remove(os.path.join(sample_data, f))\n",
        "  os.rmdir(sample_data)\n",
        "os.chdir(stable_dir)\n",
        "from IPython.display import clear_output\n",
        "#loaded_Stability_api = False\n",
        "#loaded_img2img = False\n",
        "#use_Stability_api = False\n",
        "\n",
        "import requests\n",
        "import random as rnd\n",
        "def version_checker():\n",
        "  response = requests.get(\"https://raw.githubusercontent.com/Skquark/AI-Friends/main/DSD_version.txt\")\n",
        "  current_v = response.text.strip()\n",
        "  if current_v != version:\n",
        "    print(f'A new update is available. You are running {version} and {current_v} is up. We recommended refreshing Stable Diffusion Deluxe for the latest cool features or fixes.\\nhttps://colab.research.google.com/github/Skquark/AI-Friends/blob/main/Stable_Diffusion_Deluxe.ipynb\\nChangelog if interested: https://github.com/Skquark/AI-Friends/commits/main/Stable_Diffusion_Deluxe.ipynb')\n",
        "def ng():\n",
        "  response = requests.get(\"https://raw.githubusercontent.com/Skquark/AI-Friends/main/_ng\")\n",
        "  ng_list = response.text.strip().split('\\n')\n",
        "  _ng = rnd.choice(ng_list).partition('_')\n",
        "  return _ng[2]+_ng[1]+_ng[0]\n",
        "\n",
        "env = os.environ.copy()\n",
        "def run_sp(cmd_str, cwd=None, realtime=True):\n",
        "  cmd_list = cmd_str if type(cmd_str) is list else cmd_str.split()\n",
        "  if realtime:\n",
        "    if cwd is None:\n",
        "      process = subprocess.Popen(cmd_str, shell = True, env=env, bufsize = 1, stdout=subprocess.PIPE, stderr = subprocess.STDOUT, encoding='utf-8', errors = 'replace' ) \n",
        "    else:\n",
        "      process = subprocess.Popen(cmd_str, shell = True, cwd=cwd, env=env, bufsize = 1, stdout=subprocess.PIPE, stderr = subprocess.STDOUT, encoding='utf-8', errors = 'replace' ) \n",
        "    while True:\n",
        "      realtime_output = process.stdout.readline()\n",
        "      if realtime_output == '' and process.poll() is not None:\n",
        "        break\n",
        "      if realtime_output:\n",
        "        print(realtime_output.strip(), flush=False)\n",
        "        sys.stdout.flush()\n",
        "  else:\n",
        "    if cwd is None:\n",
        "      return subprocess.run(cmd_list, stdout=subprocess.PIPE, env=env).stdout.decode('utf-8')\n",
        "    else:\n",
        "      return subprocess.run(cmd_list, stdout=subprocess.PIPE, env=env, cwd=cwd).stdout.decode('utf-8')\n",
        "try:\n",
        "  import flet\n",
        "except ImportError as e:\n",
        "  run_sp(\"pip install flet --upgrade --quiet\")\n",
        "  #run_sp(\"pip install -i https://test.pypi.org/simple/ flet\")\n",
        "  #run_sp(\"pip install --upgrade git+https://github.com/flet-dev/flet.git@controls-s3#egg=flet-dev\")\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  from emoji import emojize\n",
        "except ImportError as e:\n",
        "  run_sp(\"pip install emoji --quiet\")\n",
        "  from emoji import emojize\n",
        "  pass\n",
        "if 'url' not in locals():\n",
        "  url=\"\"\n",
        "if tunnel_type == \"ngrok\":\n",
        "  try:\n",
        "    import pyngrok\n",
        "  except ImportError as e:\n",
        "    run_sp(\"pip install pyngrok --quiet\", realtime=False)\n",
        "    run_sp(f\"ngrok authtoken {ng()}\", realtime=False)\n",
        "    import pyngrok\n",
        "    pass\n",
        "elif tunnel_type == \"localtunnel\":\n",
        "  if not bool(url):\n",
        "    import re\n",
        "    run_sp(\"npm install -g -q localtunnel\")\n",
        "    localtunnel = subprocess.Popen(['lt', '--port', '80', 'http'], stdout=subprocess.PIPE)\n",
        "    url = str(localtunnel.stdout.readline())\n",
        "    url = (re.search(\"(?P<url>https?:\\/\\/[^\\s]+loca.lt)\", url).group(\"url\"))\n",
        "    print(url)\n",
        "\n",
        "gdrive = None\n",
        "if storage_type == \"PyDrive Google Drive\":\n",
        "  if not os.path.isfile(Google_OAuth_client_secret_json):\n",
        "    raise ValueError(\"Couldn't locate your client_secret.json file to authenticate. Follow instructions below then copy certificate to your root dir.\")\n",
        "  try:\n",
        "    from pydrive2.auth import GoogleAuth, ServiceAccountCredentials\n",
        "    from pydrive2.drive import GoogleDrive\n",
        "    from oauth2client.contrib.gce import AppAssertionCredentials\n",
        "  except ImportError as e:\n",
        "    run_sp(\"pip install PyDrive2 -q\")\n",
        "    from pydrive2.auth import GoogleAuth, ServiceAccountCredentials\n",
        "    from pydrive2.drive import GoogleDrive\n",
        "    from oauth2client.contrib.gce import AppAssertionCredentials\n",
        "    pass\n",
        "  import httplib2\n",
        "\n",
        "  old_local_webserver_auth = GoogleAuth.LocalWebserverAuth\n",
        "  def LocalWebServerAuth(self, *args, **kwargs):\n",
        "      if isinstance(self.credentials, AppAssertionCredentials):\n",
        "          self.credentials.refresh(httplib2.Http())\n",
        "          return\n",
        "      return old_local_webserver_auth(self, *args, **kwargs)\n",
        "  GoogleAuth.LocalWebserverAuth = LocalWebServerAuth\n",
        "\n",
        "  #scope = 'https://www.googleapis.com/auth/drive'\n",
        "  #credentials = ServiceAccountCredentials.from_json_keyfile_name(Google_OAuth_client_secret_json, scope)\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.LoadCredentialsFile(Google_OAuth_client_secret_json)\n",
        "  #gauth.LocalWebserverAuth()\n",
        "  if is_Colab: gauth.CommandLineAuth()\n",
        "  else:\n",
        "    gauth.LocalWebserverAuth()\n",
        "    gauth.SaveCredentialsFile(Google_OAuth_client_secret_json)\n",
        "  gdrive = GoogleDrive(gauth)\n",
        "slash = '/'\n",
        "from pathlib import Path\n",
        "if not is_Colab:\n",
        "    image_output = os.path.join(Path.home(), \"Pictures\", \"Stable_Diffusion\")\n",
        "    if \"\\\\\" in image_output:\n",
        "        slash = '\\\\'\n",
        "else:\n",
        "    image_output = '/content/drive/MyDrive/AI/Stable_Diffusion/images_out'\n",
        "    \n",
        "clear_output()\n",
        "\n",
        "import json\n",
        "prefs = {}\n",
        "def load_settings_file():\n",
        "  global prefs\n",
        "  if os.path.isfile(saved_settings_json):\n",
        "    with open(saved_settings_json) as settings:\n",
        "      prefs = json.load(settings)\n",
        "    print(\"Successfully loaded settings json...\")\n",
        "  else:\n",
        "    print(\"Settings file not found, starting with defaults...\")\n",
        "    prefs = {\n",
        "      'save_to_GDrive': True,\n",
        "      'image_output': image_output,\n",
        "      'file_prefix': 'sd-',\n",
        "      'file_suffix_seed': False,\n",
        "      'file_max_length': 220,\n",
        "      'file_allowSpace': False,\n",
        "      'save_image_metadata': True,\n",
        "      'meta_ArtistName':'',\n",
        "      'meta_Copyright': '',\n",
        "      'save_config_in_metadata': True,\n",
        "      'save_config_json': False,\n",
        "      'theme_mode': 'Dark',\n",
        "      'theme_color': 'Green',\n",
        "      'enable_sounds': True,\n",
        "      'start_in_installation': False,\n",
        "      'disable_nsfw_filter': True,\n",
        "      'retry_attempts': 3,\n",
        "      'HuggingFace_api_key': \"\",\n",
        "      'Stability_api_key': \"\",\n",
        "      'OpenAI_api_key': \"\",\n",
        "      'TextSynth_api_key': \"\",\n",
        "      'Replicate_api_key': \"\",\n",
        "      'api_key_file': '/content/drive/MyDrive/AI/Stable_Diffusion/sd_api_keys.txt',\n",
        "      'scheduler_mode': \"DDIM\",\n",
        "      'higher_vram_mode': False,\n",
        "      'enable_attention_slicing': True,\n",
        "      'memory_optimization': 'Attention Slicing',\n",
        "      'sequential_cpu_offload': False,\n",
        "      'vae_slicing': False,\n",
        "      'cache_dir': '',\n",
        "      'install_diffusers': True,\n",
        "      'install_interpolation': False,\n",
        "      'install_text2img': True,\n",
        "      'install_img2img': False,\n",
        "      'install_megapipe': True,\n",
        "      'install_CLIP_guided': False,\n",
        "      'install_OpenAI': False,\n",
        "      'install_TextSynth': False,\n",
        "      'install_dreamfusion': False,\n",
        "      'install_repaint': False,\n",
        "      'install_imagic': False,\n",
        "      'install_composable': False,\n",
        "      'install_safe': False,\n",
        "      'install_versatile': False,\n",
        "      'install_depth2img': False,\n",
        "      'install_upscale': False,\n",
        "      'safety_config': 'Strong',\n",
        "      'use_imagic': False,\n",
        "      'use_composable': False,\n",
        "      'use_safe': False,\n",
        "      'use_versatile': False,\n",
        "      'use_upscale': False,\n",
        "      'upscale_noise_level': 20,\n",
        "      'install_conceptualizer': False,\n",
        "      'use_conceptualizer': False,\n",
        "      'concepts_model': 'cat-toy',\n",
        "      'model_ckpt': 'Stable Diffusion v1.5',\n",
        "      'finetuned_model': 'Midjourney v4 style',\n",
        "      'dreambooth_model': 'disco-diffusion-style',\n",
        "      'custom_model': '',\n",
        "      'custom_models': [],\n",
        "      'clip_model_id': \"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\",\n",
        "      'install_Stability_api': False,\n",
        "      'use_Stability_api': False,\n",
        "      'model_checkpoint': \"stable-diffusion-768-v2-1\",\n",
        "      'generation_sampler': \"K_EULER_ANCESTRAL\",\n",
        "      'clip_guidance_preset': \"FAST_BLUE\",\n",
        "      'install_ESRGAN': True,\n",
        "      'batch_folder_name': \"\",\n",
        "      'batch_size': 1,\n",
        "      'n_iterations': 1,\n",
        "      'steps': 50,\n",
        "      'eta': 0.4,\n",
        "      'seed': 0,\n",
        "      'guidance_scale': 8,\n",
        "      'width': 960,\n",
        "      'height': 512,\n",
        "      'init_image': \"\",\n",
        "      'mask_image': \"\",\n",
        "      'init_image_strength': 0.25,\n",
        "      'alpha_mask': False,\n",
        "      'invert_mask': False,\n",
        "      'precision': 'autocast',\n",
        "      'use_inpaint_model': False,\n",
        "      'centipede_prompts_as_init_images': False,\n",
        "      'use_depth2img': False,\n",
        "      'use_interpolation': False,\n",
        "      'num_interpolation_steps': 22,\n",
        "      'use_clip_guided_model': False,\n",
        "      'clip_guidance_scale': 571,\n",
        "      'use_cutouts': True,\n",
        "      'num_cutouts': 4,\n",
        "      'unfreeze_unet': True,\n",
        "      'unfreeze_vae': True,\n",
        "      'apply_ESRGAN_upscale': True,\n",
        "      'enlarge_scale': 1.5,\n",
        "      'face_enhance':False,\n",
        "      'display_upscaled_image': False,\n",
        "      'prompt_list': [],\n",
        "      'prompt_generator': {\n",
        "          'phrase': '',\n",
        "          'subject_detail': '',\n",
        "          'phrase_as_subject': False,\n",
        "          'amount': 10,\n",
        "          'random_artists': 2,\n",
        "          'random_styles': 1,\n",
        "          'permutate_artists': False,\n",
        "          'request_mode': 3,\n",
        "          'AI_temperature': 0.9,\n",
        "          'economy_mode': True,\n",
        "      },\n",
        "      'prompt_remixer': {\n",
        "          'seed_prompt': '',\n",
        "          'optional_about_influencer': '',\n",
        "          'amount': 10,\n",
        "          'random_artists': 2,\n",
        "          'random_styles': 1,\n",
        "          'permutate_artists': False,\n",
        "          'request_mode': 3,\n",
        "          'AI_temperature': 0.9,\n",
        "      },\n",
        "      'prompt_brainstormer': {\n",
        "          'AI_engine': 'OpenAI GPT-3',\n",
        "          'about_prompt': '',\n",
        "          'request_mode': 'Brainstorm',\n",
        "          'AI_temperature': 0.9,\n",
        "      },\n",
        "      'prompt_writer': {\n",
        "          'art_Subjects': '',\n",
        "          'by_Artists': '',\n",
        "          'art_Styles': '',\n",
        "          'amount': 10,\n",
        "          'random_artists': 2,\n",
        "          'random_styles': 1,\n",
        "          'permutate_artists': False,\n",
        "      },\n",
        "    }\n",
        "\n",
        "load_settings_file()\n",
        "version_checker()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV5d8rB5uYZC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## **‚ñ∂Ô∏è Run Stable Diffusion Deluxe** - Flet/Flutter WebUI App\n",
        "import flet\n",
        "#from flet import *\n",
        "from flet import Page, View, Column, Row, ResponsiveRow, Container, Text, Stack, TextField, Checkbox, Switch, Image, ElevatedButton, IconButton, Markdown, Tab, Tabs, AppBar, Divider, VerticalDivider, GridView, Tooltip, SnackBar, AnimatedSwitcher, ButtonStyle, FloatingActionButton, Audio, Theme, Dropdown, Slider, ListTile, ListView, TextButton, PopupMenuButton, PopupMenuItem, AlertDialog, Banner, Icon, ProgressBar, ProgressRing, GestureDetector, KeyboardEvent, FilePicker, FilePickerResultEvent, FilePickerUploadFile, FilePickerUploadEvent, UserControl, Ref\n",
        "from flet import icons, dropdown, colors, padding, margin, alignment, border_radius, theme, animation, KeyboardType, TextThemeStyle, AnimationCurve\n",
        "from flet.types import TextAlign, FontWeight, ClipBehavior, MainAxisAlignment, CrossAxisAlignment, ScrollMode, ImageFit, ThemeMode\n",
        "from flet import Image as Img\n",
        "try:\n",
        "    import PIL\n",
        "except Exception:\n",
        "    run_sp(\"pip install Pillow\", realtime=False)\n",
        "    run_sp(\"pip install image\", realtime=False)\n",
        "    import PIL\n",
        "    pass\n",
        "from PIL import Image as PILImage # Avoids flet conflict\n",
        "import random as rnd\n",
        "import io, shutil\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "if 'prefs' not in locals():\n",
        "    raise ValueError(\"Setup not initialized. Run the previous code block first and authenticate your Drive storage.\")\n",
        "status = {\n",
        "    'installed_diffusers': False,\n",
        "    'installed_txt2img': False,\n",
        "    'installed_img2img': False,\n",
        "    'installed_stability': False,\n",
        "    'installed_megapipe': False,\n",
        "    'installed_interpolation': False,\n",
        "    'installed_clip': False,\n",
        "    'installed_ESRGAN': False,\n",
        "    'installed_OpenAI': False,\n",
        "    'installed_TextSynth': False,\n",
        "    'installed_conceptualizer': False,\n",
        "    'installed_dreamfusion': False,\n",
        "    'installed_repaint': False,\n",
        "    'installed_imagic': False,\n",
        "    'installed_composable': False,\n",
        "    'installed_safe': False,\n",
        "    'installed_versatile': False,\n",
        "    'installed_depth2img': False,\n",
        "    'installed_upscale': False,\n",
        "    'finetuned_model': False,\n",
        "    'changed_settings': False,\n",
        "    'changed_installers': False,\n",
        "    'changed_parameters': False,\n",
        "    'changed_prompts': False,\n",
        "    'changed_prompt_generator': False,\n",
        "    'changed_prompt_remixer': False,\n",
        "    'changed_prompt_brainstormer': False,\n",
        "    'changed_prompt_writer': False,\n",
        "    'initialized': False,\n",
        "}\n",
        "\n",
        "def save_settings_file(page, change_icon=True):\n",
        "  if change_icon:\n",
        "    page.app_icon_save()\n",
        "  if not os.path.isfile(saved_settings_json):\n",
        "    settings_path = saved_settings_json.rpartition(slash)[0]\n",
        "    os.makedirs(settings_path, exist_ok=True)\n",
        "  with open(saved_settings_json, \"w\") as write_file:\n",
        "    json.dump(prefs, write_file, indent=4)\n",
        "\n",
        "current_tab = 0\n",
        "def tab_on_change (e):\n",
        "    t = e.control\n",
        "    global current_tab, status\n",
        "    #print (f\"tab changed from {current_tab} to: {t.selected_index}\")\n",
        "    #print(str(t.tabs[t.selected_index].text))\n",
        "    if current_tab == 0:\n",
        "      #if not status['initialized']:\n",
        "      #  initState(e.page)\n",
        "      #  status['initialized'] = True\n",
        "      if status['changed_settings']:\n",
        "        save_settings_file(e.page)\n",
        "        status['changed_settings'] = False\n",
        "        #print(len(e.page.Settings.content.controls))\n",
        "        #save_settings(e.page.Settings.content.controls)\n",
        "    if current_tab == 1:\n",
        "      if status['changed_installers']:\n",
        "        save_settings_file(e.page)\n",
        "        status['changed_installers'] = False\n",
        "        #print(\"Saving Installers\")\n",
        "      e.page.show_install_fab(False)\n",
        "    if current_tab == 2:\n",
        "      if status['changed_parameters']:\n",
        "        update_args()\n",
        "        e.page.update_prompts()\n",
        "        save_settings_file(e.page)\n",
        "        status['changed_parameters'] = False\n",
        "      e.page.show_apply_fab(False)\n",
        "    if current_tab == 3:\n",
        "      if status['changed_prompts']:\n",
        "        e.page.save_prompts()\n",
        "        save_settings_file(e.page)\n",
        "        status['changed_prompts'] = False\n",
        "      e.page.show_run_diffusion_fab(False)\n",
        "    if current_tab == 5:\n",
        "      if status['changed_prompt_generator']:\n",
        "        save_settings_file(e.page)\n",
        "        status['changed_prompt_generator'] = False\n",
        "    \n",
        "    current_tab = t.selected_index\n",
        "    if current_tab == 1:\n",
        "      refresh_installers(e.page.Installers.controls[0].content.controls)\n",
        "      e.page.show_install_fab(True)\n",
        "      #page.Installers.init_boxes()\n",
        "    if current_tab == 2:\n",
        "      update_parameters(e.page)\n",
        "      #for p in e.page.Parameters.content.controls:\n",
        "      e.page.Parameters.controls[0].content.update()\n",
        "      e.page.Parameters.update()\n",
        "      e.page.show_apply_fab(len(prompts) > 0 and status['changed_parameters'])\n",
        "    if current_tab == 3:\n",
        "      e.page.show_run_diffusion_fab(len(prompts) > 0)\n",
        "    e.page.update()\n",
        "\n",
        "def buildTabs(page):\n",
        "    page.Settings = buildSettings(page)\n",
        "    page.Installers = buildInstallers(page)\n",
        "    page.Parameters = buildParameters(page)\n",
        "    page.PromptsList = buildPromptsList(page)\n",
        "    page.PromptHelpers = buildPromptHelpers(page)\n",
        "    page.Images = buildImages(page)\n",
        "    page.StableDiffusers = buildStableDiffusers(page)\n",
        "    page.Extras = buildExtras(page)\n",
        "    \n",
        "    t = Tabs(selected_index=0, animation_duration=300, expand=1,\n",
        "        tabs=[\n",
        "            Tab(text=\"Settings\", content=page.Settings, icon=icons.SETTINGS_OUTLINED),\n",
        "            Tab(text=\"Installation\", content=page.Installers, icon=icons.INSTALL_DESKTOP),\n",
        "            Tab(text=\"Image Parameters\", content=page.Parameters, icon=icons.DISPLAY_SETTINGS),\n",
        "            Tab(text=\"Prompts List\", content=page.PromptsList, icon=icons.FORMAT_LIST_BULLETED),\n",
        "            Tab(text=\"Generate Images\", content=page.Images, icon=icons.IMAGE_OUTLINED),\n",
        "            Tab(text=\"Prompt Helpers\", content=page.PromptHelpers, icon=icons.BUBBLE_CHART_OUTLINED),\n",
        "            Tab(text=\"Stable Diffusers\", content=page.StableDiffusers, icon=icons.PALETTE),\n",
        "            Tab(text=\"Extras\", content=page.Extras, icon=icons.ALL_INBOX),\n",
        "        ],\n",
        "    )\n",
        "    page.tabs = t\n",
        "    return t\n",
        "\n",
        "def b_style():\n",
        "    return ButtonStyle(elevation=8)\n",
        "def dict_diff(dict1, dict2):\n",
        "    return {k: v for k, v in dict1.items() if k in dict2 and v != dict2[k]}\n",
        "def arg_diffs(dict1, dict2):\n",
        "    diff = dict_diff(dict1, dict2)\n",
        "    if len(diff) > 0:\n",
        "      dif = []\n",
        "      for k, v in diff.items():\n",
        "        dif.append(f'{k}: {v}')\n",
        "      return ', '.join(dif)\n",
        "    else: return None\n",
        "def get_color(color):\n",
        "    if color == \"green\": return colors.GREEN\n",
        "    elif color == \"blue\": return colors.BLUE\n",
        "    elif color == \"indigo\": return colors.INDIGO\n",
        "    elif color == \"red\": return colors.RED\n",
        "    elif color == \"purple\": return colors.DEEP_PURPLE\n",
        "    elif color == \"orange\": return colors.ORANGE\n",
        "    elif color == \"amber\": return colors.AMBER\n",
        "    elif color == \"brown\": return colors.BROWN\n",
        "    elif color == \"teal\": return colors.TEAL\n",
        "\n",
        "# Delete these after everyone's updated\n",
        "if 'install_conceptualizer' not in prefs: prefs['install_conceptualizer'] = False\n",
        "if 'use_conceptualizer' not in prefs: prefs['use_conceptualizer'] = False\n",
        "if 'concepts_model' not in prefs: prefs['concepts_model'] = 'cat-toy'\n",
        "if 'memory_optimization' not in prefs: prefs['memory_optimization'] = 'Attention Slicing'\n",
        "if 'sequential_cpu_offload' not in prefs: prefs['sequential_cpu_offload'] = False\n",
        "if 'vae_slicing' not in prefs: prefs['vae_slicing'] = False\n",
        "if 'use_inpaint_model' not in prefs: prefs['use_inpaint_model'] = False\n",
        "if 'cache_dir' not in prefs: prefs['cache_dir'] = ''\n",
        "if 'Replicate_api_key' not in prefs: prefs['Replicate_api_key'] = ''\n",
        "if 'install_dreamfusion' not in prefs: prefs['install_dreamfusion'] = False\n",
        "if 'install_repaint' not in prefs: prefs['install_repaint'] = False\n",
        "if 'finetuned_model' not in prefs: prefs['finetuned_model'] = 'Midjourney v4 style'\n",
        "if 'dreambooth_model' not in prefs: prefs['dreambooth_model'] = 'disco-diffusion-style'\n",
        "if 'custom_model' not in prefs: prefs['custom_model'] = ''\n",
        "if 'custom_models' not in prefs: prefs['custom_models'] = []\n",
        "if 'start_in_installation' not in prefs: prefs['start_in_installation'] = False\n",
        "if 'install_imagic' not in prefs: prefs['install_imagic'] = False\n",
        "if 'use_imagic' not in prefs: prefs['use_imagic'] = False\n",
        "if 'install_composable' not in prefs: prefs['install_composable'] = False\n",
        "if 'use_composable' not in prefs: prefs['use_composable'] = False\n",
        "if 'install_safe' not in prefs: prefs['install_safe'] = False\n",
        "if 'use_safe' not in prefs: prefs['use_safe'] = False\n",
        "if 'safety_config' not in prefs: prefs['safety_config'] = \"Strong\"\n",
        "if 'install_versatile' not in prefs: prefs['install_versatile'] = False\n",
        "if 'use_versatile' not in prefs: prefs['use_versatile'] = False\n",
        "if 'install_depth2img' not in prefs: prefs['install_depth2img'] = False\n",
        "if 'use_depth2img' not in prefs: prefs['use_depth2img'] = False\n",
        "if 'install_upscale' not in prefs: prefs['install_upscale'] = False\n",
        "if 'use_upscale' not in prefs: prefs['use_upscale'] = False\n",
        "if 'upscale_noise_level' not in prefs: prefs['upscale_noise_level'] = 20\n",
        "if 'alpha_mask' not in prefs: prefs['alpha_mask'] = False\n",
        "if 'invert_mask' not in prefs: prefs['invert_mask'] = False\n",
        "if 'clip_guidance_preset' not in prefs: prefs['clip_guidance_preset'] = \"FAST_BLUE\"\n",
        "\n",
        "def initState(page):\n",
        "    global status, current_tab\n",
        "    if os.path.isdir(os.path.join(root_dir, 'Real-ESRGAN')):\n",
        "      status['installed_ESRGAN'] = True\n",
        "    page.load_prompts()\n",
        "    # TODO: Try to load from assets folder\n",
        "    page.snd_alert = Audio(src=\"https://github.com/Skquark/AI-Friends/blob/main/assets/snd-alert.mp3?raw=true\", autoplay=False)\n",
        "    page.snd_delete = Audio(src=\"https://github.com/Skquark/AI-Friends/blob/main/assets/snd-delete.mp3?raw=true\", autoplay=False)\n",
        "    page.snd_error = Audio(src=\"https://github.com/Skquark/AI-Friends/blob/main/assets/snd-error.mp3?raw=true\", autoplay=False)\n",
        "    page.snd_done = Audio(src=\"https://github.com/Skquark/AI-Friends/blob/main/assets/snd-done.mp3?raw=true\", autoplay=False)\n",
        "    #page.snd_notification = Audio(src=\"https://github.com/Skquark/AI-Friends/blob/main/assets/snd-notification.mp3?raw=true\", autoplay=False)\n",
        "    page.snd_drop = Audio(src=\"https://github.com/Skquark/AI-Friends/blob/main/assets/snd-drop.mp3?raw=true\", autoplay=False)\n",
        "    page.overlay.append(page.snd_alert)\n",
        "    page.overlay.append(page.snd_delete)\n",
        "    page.overlay.append(page.snd_error)\n",
        "    page.overlay.append(page.snd_done)\n",
        "    #page.overlay.append(page.snd_notification)\n",
        "    page.overlay.append(page.snd_drop)\n",
        "    #print(\"Running Init State\")\n",
        "    if prefs['start_in_installation']:\n",
        "      page.tabs.selected_index = 1\n",
        "      page.tabs.update()\n",
        "      page.show_install_fab(True)\n",
        "      page.update()\n",
        "      current_tab = 1\n",
        "\n",
        "def buildSettings(page):\n",
        "  global prefs, status\n",
        "  def open_url(e):\n",
        "    page.launch_url(e.data)\n",
        "  def save_settings(e):\n",
        "    save_settings_file(e.page)\n",
        "    page.snack_bar = SnackBar(content=Text(f\"Saving all settings to {saved_settings_json.rpartition(slash)[2]}\"))\n",
        "    page.snack_bar.open = True\n",
        "    page.tabs.selected_index = 1\n",
        "    page.tabs.update()\n",
        "    page.update()\n",
        "  def changed(e, pref=None):\n",
        "      if pref is not None:\n",
        "        prefs[pref] = e.control.value\n",
        "      has_changed = True\n",
        "      page.update()\n",
        "      status['changed_settings'] = True\n",
        "  def change_theme_mode(e):\n",
        "    prefs['theme_mode'] = e.control.value\n",
        "    if prefs['theme_mode'].lower() == \"dark\":\n",
        "      page.dark_theme = Theme(color_scheme_seed=get_color(prefs['theme_color'].lower()))\n",
        "    else:\n",
        "      page.theme = theme.Theme(color_scheme_seed=get_color(prefs['theme_color'].lower()))\n",
        "    page.theme_mode = prefs['theme_mode'].lower()\n",
        "    page.update()\n",
        "  def change_theme_color(e):\n",
        "    prefs['theme_color'] = e.control.value\n",
        "    if prefs['theme_mode'].lower() == \"dark\":\n",
        "      page.dark_theme = Theme(color_scheme_seed=get_color(prefs['theme_color'].lower()))\n",
        "    else:\n",
        "      page.theme = theme.Theme(color_scheme_seed=get_color(prefs['theme_color'].lower()))\n",
        "    page.update()\n",
        "  def toggle_nsfw(e):\n",
        "    retry_attempts.width = 0 if e.control.value else None\n",
        "    retry_attempts.update()\n",
        "    changed(e, 'disable_nsfw_filter')\n",
        "  #haschanged = False\n",
        "  #save_to_GDrive = Checkbox(label=\"Save to Google Drive\", value=prefs['save_to_GDrive'])\n",
        "  def default_cache_dir(e):\n",
        "    default_dir = prefs['image_output'].strip()\n",
        "    if default_dir.endswith(slash):\n",
        "      default_dir = default_dir[:-1]\n",
        "    default_dir = default_dir.rpartition(slash)[0]\n",
        "    default_dir = os.path.join(default_dir, 'models')\n",
        "    prefs['cache_dir'] = default_dir\n",
        "    optional_cache_dir.value = default_dir\n",
        "    optional_cache_dir.update()\n",
        "  image_output = TextField(label=\"Image Output Path\", value=prefs['image_output'], on_change=lambda e:changed(e, 'image_output'), col={\"md\":12, \"lg\":6}, suffix=IconButton(icon=icons.FOLDER_OUTLINED))\n",
        "  optional_cache_dir = TextField(label=\"Optional Cache Directory (saves large models to GDrive)\", hint_text=\"(button on right inserts recommended folder)\", value=prefs['cache_dir'], on_change=lambda e:changed(e, 'cache_dir'), suffix=IconButton(icon=icons.ARCHIVE, tooltip=\"Insert recommended models cache path\", on_click=default_cache_dir), col={\"md\":12, \"lg\":6})\n",
        "  file_prefix = TextField(label=\"Filename Prefix\",  value=prefs['file_prefix'], width=150, height=60, on_change=lambda e:changed(e, 'file_prefix'))\n",
        "  file_suffix_seed = Checkbox(label=\"Filename Suffix Seed   \", tooltip=\"Appends -seed# to the end of the image name\", value=prefs['file_suffix_seed'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'file_suffix_seed'))\n",
        "  file_allowSpace = Checkbox(label=\"Filename Allow Space\", tooltip=\"Otherwise will replace spaces with _ underscores\", value=prefs['file_allowSpace'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'file_allowSpace'))\n",
        "  file_max_length = TextField(label=\"Filename Max Length\", tooltip=\"How long can the name taken from prompt text be? Max 250\", value=prefs['file_max_length'], keyboard_type=KeyboardType.NUMBER, width=150, height=60, on_change=lambda e:changed(e, 'file_max_length'))\n",
        "  save_image_metadata = Checkbox(label=\"Save Image Metadata in png\", tooltip=\"Embeds your Artist Name & Copyright in the file's EXIF\", value=prefs['save_image_metadata'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'save_image_metadata'))\n",
        "  meta_ArtistName = TextField(label=\"Artist Name Metadata\", value=prefs['meta_ArtistName'], keyboard_type=KeyboardType.NAME, on_change=lambda e:changed(e, 'meta_ArtistName'))\n",
        "  meta_Copyright = TextField(label=\"Copyright Metadata\", value=prefs['meta_Copyright'], keyboard_type=KeyboardType.NAME, on_change=lambda e:changed(e, 'meta_Copyright'))\n",
        "  save_config_in_metadata = Checkbox(label=\"Save Config in Metadata    \", tooltip=\"Embeds all prompt parameters in the file's EXIF to recreate\", value=prefs['save_config_in_metadata'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'save_config_in_metadata'))\n",
        "  save_config_json = Checkbox(label=\"Save Config JSON files\", tooltip=\"Creates a json text file with all prompt parameters with each image\", value=prefs['save_config_json'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'save_config_json'))\n",
        "  theme_mode = Dropdown(label=\"Theme Mode\", width=200, options=[dropdown.Option(\"Dark\"), dropdown.Option(\"Light\")], value=prefs['theme_mode'], on_change=change_theme_mode)\n",
        "  theme_color = Dropdown(label=\"Accent Color\", width=200, options=[dropdown.Option(\"Green\"), dropdown.Option(\"Blue\"), dropdown.Option(\"Red\"), dropdown.Option(\"Indigo\"), dropdown.Option(\"Purple\"), dropdown.Option(\"Orange\"), dropdown.Option(\"Amber\"), dropdown.Option(\"Brown\"), dropdown.Option(\"Teal\")], value=prefs['theme_color'], on_change=change_theme_color)\n",
        "  enable_sounds = Checkbox(label=\"Enable UI Sound Effects    \", tooltip=\"Turn on for audible errors, deletes and generation done notifications\", value=prefs['enable_sounds'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'enable_sounds'))\n",
        "  start_in_installation = Checkbox(label=\"Start in Installation Page\", tooltip=\"When launching app, switch to Installer tab. Saves time..\", value=prefs['start_in_installation'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'start_in_installation'))\n",
        "  disable_nsfw_filter = Checkbox(label=\"Disable NSFW Filters\", value=prefs['disable_nsfw_filter'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=toggle_nsfw)\n",
        "  retry_attempts = Container(NumberPicker(label=\"Retry Attempts if Not Safe\", min=0, max=8, value=prefs['retry_attempts'], on_change=lambda e:changed(e, 'retry_attempts')), padding=padding.only(left=20), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "  retry_attempts.width = 0 if prefs['disable_nsfw_filter'] else None\n",
        "  api_instructions = Container(height=152, content=Markdown(\"Get **HuggingFace API key** from https://huggingface.co/settings/tokens and accept the cards for [1.5 model](https://huggingface.co/runwayml/stable-diffusion-v1-5), [1.4 model](https://huggingface.co/CompVis/stable-diffusion-v1-4),  & [Inpainting model](https://huggingface.co/runwayml/stable-diffusion-inpainting).\\n\\nGet **Stability-API key** from https://beta.dreamstudio.ai/membership?tab=apiKeys then API key\\n\\nGet **OpenAI GPT-3 API key** from https://beta.openai.com, user menu, View API Keys\\n\\nGet **TextSynth GPT-J key** from https://TextSynth.com, login, Setup\\n\\nGet **Replicate API Token** from https://replicate.com/account, for Material Diffusion\", extension_set=\"gitHubWeb\", on_tap_link=open_url))\n",
        "  HuggingFace_api = TextField(label=\"HuggingFace API Key\", value=prefs['HuggingFace_api_key'], password=True, can_reveal_password=True, on_change=lambda e:changed(e, 'HuggingFace_api_key'))\n",
        "  Stability_api = TextField(label=\"Stability.ai API Key\", value=prefs['Stability_api_key'], password=True, can_reveal_password=True, on_change=lambda e:changed(e, 'Stability_api_key'))\n",
        "  OpenAI_api = TextField(label=\"OpenAI API Key\", value=prefs['OpenAI_api_key'], password=True, can_reveal_password=True, on_change=lambda e:changed(e, 'OpenAI_api_key'))\n",
        "  TextSynth_api = TextField(label=\"TextSynth API Key\", value=prefs['TextSynth_api_key'], password=True, can_reveal_password=True, on_change=lambda e:changed(e, 'TextSynth_api_key'))\n",
        "  Replicate_api = TextField(label=\"Replicate API Key\", value=prefs['Replicate_api_key'], password=True, can_reveal_password=True, on_change=lambda e:changed(e, 'Replicate_api_key'))\n",
        "  save_button = ElevatedButton(content=Text(value=\"üíæ  Save Settings\", size=20), on_click=save_settings, style=b_style())\n",
        "  \n",
        "  c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Text (\"‚öôÔ∏è   Deluxe Stable Diffusion Settings & Preferences\", style=TextThemeStyle.TITLE_LARGE),\n",
        "        Divider(thickness=1, height=4),\n",
        "        #save_to_GDrive,\n",
        "        ResponsiveRow([image_output, optional_cache_dir], run_spacing=2),\n",
        "        #VerticalDivider(thickness=2),\n",
        "        Row([file_prefix, file_suffix_seed]) if page.width > 500 else Column([file_prefix, file_suffix_seed]),\n",
        "        Row([file_max_length, file_allowSpace]),\n",
        "        #file_allowSpace,\n",
        "        #file_max_length,\n",
        "        #Row([disable_nsfw_filter, retry_attempts]),\n",
        "        #VerticalDivider(thickness=2, width=1),\n",
        "        save_image_metadata,\n",
        "        Row([meta_ArtistName, meta_Copyright]) if page.width > 712 else Column([meta_ArtistName, meta_Copyright]),\n",
        "        Row([save_config_in_metadata, save_config_json,]),\n",
        "        Row([theme_mode, theme_color]),\n",
        "        Row([enable_sounds, start_in_installation]),\n",
        "        #VerticalDivider(thickness=2, width=1),\n",
        "        HuggingFace_api,\n",
        "        Stability_api,\n",
        "        OpenAI_api,\n",
        "        TextSynth_api,\n",
        "        Replicate_api,\n",
        "        api_instructions,\n",
        "        #save_button,\n",
        "        Container(content=None, height=32),\n",
        "      ],  \n",
        "  ))], scroll=ScrollMode.AUTO,)\n",
        "  return c\n",
        "\n",
        "def run_process(cmd_str, cwd=None, realtime=True, page=None, close_at_end=False):\n",
        "  cmd_list = cmd_str if type(cmd_str) is list else cmd_str.split()\n",
        "  if realtime:\n",
        "    if cwd is None:\n",
        "      process = subprocess.Popen(cmd_str, shell = True, env=env, bufsize = 1, stdout=subprocess.PIPE, stderr = subprocess.STDOUT, encoding='utf-8', errors = 'replace' ) \n",
        "    else:\n",
        "      process = subprocess.Popen(cmd_str, shell = True, cwd=cwd, env=env, bufsize = 1, stdout=subprocess.PIPE, stderr = subprocess.STDOUT, encoding='utf-8', errors = 'replace' ) \n",
        "    while True:\n",
        "      realtime_output = process.stdout.readline()\n",
        "      if realtime_output == '' and process.poll() is not None:\n",
        "        break\n",
        "      if realtime_output:\n",
        "        #print(realtime_output.strip(), flush=False)\n",
        "        page.banner.content.controls.append(Text(realtime_output.strip()))\n",
        "        page.update()\n",
        "        sys.stdout.flush()\n",
        "    if close_at_end:\n",
        "      page.banner.open = False\n",
        "      page.update()\n",
        "  else:\n",
        "    if cwd is None:\n",
        "      #return subprocess.run(cmd_list, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "      return subprocess.run(cmd_list, stdout=subprocess.PIPE, env=env).stdout.decode('utf-8')\n",
        "    else:\n",
        "      return subprocess.run(cmd_list, stdout=subprocess.PIPE, env=env, cwd=cwd).stdout.decode('utf-8')\n",
        "\n",
        "def close_alert_dlg(e):\n",
        "      e.page.alert_dlg.open = False\n",
        "      e.page.update()\n",
        "def alert_msg(page, msg, content=None):\n",
        "      if prefs['enable_sounds']: page.snd_error.play()\n",
        "      okay = ElevatedButton(\"üëå  OKAY \", on_click=close_alert_dlg)\n",
        "      page.alert_dlg = AlertDialog(title=Text(msg), content=content, actions=[okay], actions_alignment=MainAxisAlignment.END)\n",
        "      page.dialog = page.alert_dlg\n",
        "      page.alert_dlg.open = True\n",
        "      page.update()\n",
        "\n",
        "def save_installers(controls):\n",
        "  for c in controls:\n",
        "    if isinstance(c, Switch):\n",
        "      #print(f\"elif c.value == '{c.label}': prefs[''] = c.value\")\n",
        "      if c.value == 'Install HuggingFace Diffusers Pipeline': prefs['install_diffusers'] = c.value\n",
        "      elif c.value == 'Install Stability-API DreamStudio Pipeline': prefs['install_Stability_api'] = c.value\n",
        "      elif c.value == 'Install Real-ESRGAN AI Upscaler': prefs['install_ESRGAN'] = c.value\n",
        "      elif c.value == 'Install OpenAI GPT-3 Text Engine': prefs['install_OpenAI'] = c.value\n",
        "      elif c.value == 'Install TextSynth GPT-J Text Engine': prefs['install_TextSynth'] = c.value\n",
        "    elif isinstance(c, Container):\n",
        "      '''try:\n",
        "        for i in c.content.controls:\n",
        "          if isinstance(i, Switch):\n",
        "            print(f\"elif i.value == '{c.label}': prefs[''] = i.value\")\n",
        "      except: continue'''\n",
        "def refresh_installers(controls):\n",
        "  for c in controls:\n",
        "    if isinstance(c, Switch):\n",
        "      c.update()\n",
        "\n",
        "def buildInstallers(page):\n",
        "  global prefs, status, model_path\n",
        "  def changed(e, pref=None):\n",
        "      if pref is not None:\n",
        "        prefs[pref] = e.control.value\n",
        "      page.update()\n",
        "      status['changed_installers'] = True\n",
        "    #has_changed = True\n",
        "    #page.update()\n",
        "  def changed_status(e, stat=None):\n",
        "      if stat is not None:\n",
        "        status[stat] = e.control.value\n",
        "  #has_changed = False\n",
        "  #save_to_GDrive = Checkbox(label=\"Save to Google Drive\", value=prefs['save_to_GDrive'])\n",
        "\n",
        "  def toggle_diffusers(e):\n",
        "      prefs['install_diffusers'] = install_diffusers.content.value\n",
        "      diffusers_settings.height=None if prefs['install_diffusers'] else 0\n",
        "      diffusers_settings.update()\n",
        "      status['changed_installers'] = True\n",
        "  install_diffusers = Tooltip(message=\"Required Libraries for most Image Generation functionality\", content=Switch(label=\"Install HuggingFace Diffusers Pipeline\", value=prefs['install_diffusers'], disabled=status['installed_diffusers'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_diffusers))\n",
        "\n",
        "  scheduler_mode = Dropdown(label=\"Scheduler/Sampler Mode\", hint_text=\"They're very similar, with minor differences in the noise\", width=200,\n",
        "            options=[\n",
        "                dropdown.Option(\"DDIM\"),\n",
        "                dropdown.Option(\"K-LMS\"),\n",
        "                dropdown.Option(\"PNDM\"),\n",
        "                #dropdown.Option(\"DDPM\"),\n",
        "                dropdown.Option(\"DPM Solver\"),\n",
        "                dropdown.Option(\"DPM Solver++\"),\n",
        "                dropdown.Option(\"K-Euler Discrete\"),\n",
        "                dropdown.Option(\"K-Euler Ancestrial\"),\n",
        "                #dropdown.Option(\"Heun Discrete\"),\n",
        "                #dropdown.Option(\"K-DPM2 Ancestral\"),\n",
        "                #dropdown.Option(\"K-DPM2 Discrete\"),\n",
        "            ], value=prefs['scheduler_mode'], autofocus=False, on_change=lambda e:changed(e, 'scheduler_mode'),\n",
        "        )\n",
        "  def changed_model_ckpt(e):\n",
        "      changed(e, 'model_ckpt')\n",
        "      model = get_model(e.control.value)\n",
        "      model_card.value = f\"  [**Model Card**](https://huggingface.co/{model['path']})\"\n",
        "      model_card.update()\n",
        "      if e.control.value.startswith(\"Stable\"):\n",
        "        custom_area.content = model_card\n",
        "      elif e.control.value == \"Community Finetuned Model\":\n",
        "        custom_area.content = Row([finetuned_model, model_card])\n",
        "      elif e.control.value == \"DreamBooth Library Model\":\n",
        "        custom_area.content = Row([dreambooth_library, model_card])\n",
        "      elif e.control.value == \"Custom Model Path\":\n",
        "        custom_area.content = Row([custom_model, model_card])\n",
        "      custom_area.update()\n",
        "  def changed_finetuned_model(e):\n",
        "      changed(e, 'finetuned_model')\n",
        "      model = get_finetuned_model(e.control.value)\n",
        "      model_card.value = f\"  [**Model Card**](https://huggingface.co/{model['path']})\"\n",
        "      model_card.update()\n",
        "  def changed_dreambooth_library(e):\n",
        "      changed(e, 'dreambooth_model')\n",
        "      model = get_dreambooth_model(e.control.value)\n",
        "      model_card.value = f\"  [**Model Card**](https://huggingface.co/{model['path']})\"\n",
        "      model_card.update()\n",
        "  def changed_custom_model(e):\n",
        "      changed(e, 'custom_model')\n",
        "      model = {'name': 'Custom Model', 'path': e.control.value, 'prefix': ''}\n",
        "      model_card.value = f\"  [**Model Card**](https://huggingface.co/{model['path']})\"\n",
        "      model_card.update()\n",
        "  def toggle_safe(e):\n",
        "      changed(e, 'install_safe')\n",
        "      safety_config.visible = e.control.value\n",
        "      safety_config.update()\n",
        "  model = get_model(prefs['model_ckpt'])\n",
        "  model_path = model['path']\n",
        "  model_ckpt = Container(Dropdown(label=\"Model Checkpoint\", width=262, options=[\n",
        "      dropdown.Option(\"Stable Diffusion v2.1 x768\"), dropdown.Option(\"Stable Diffusion v2.1 x512\"), \n",
        "      dropdown.Option(\"Stable Diffusion v2.0 x768\"), dropdown.Option(\"Stable Diffusion v2.0 x512\"), dropdown.Option(\"Stable Diffusion v1.5\"), dropdown.Option(\"Stable Diffusion v1.4\"), \n",
        "      dropdown.Option(\"Community Finetuned Model\"), dropdown.Option(\"DreamBooth Library Model\"), dropdown.Option(\"Custom Model Path\")], value=prefs['model_ckpt'], tooltip=\"Make sure you accepted the HuggingFace Model Cards first\", autofocus=False, on_change=changed_model_ckpt), col={'xs':9, 'lg':4}, width=262)\n",
        "  finetuned_model = Dropdown(label=\"Finetuned Model\", tooltip=\"Make sure you accepted the HuggingFace Model Cards first\", width=370, options=[], value=prefs['finetuned_model'], autofocus=False, on_change=changed_finetuned_model, col={'xs':10, 'lg':4})\n",
        "  model_card = Markdown(f\"  [**Model Card**](https://huggingface.co/{model['path']})\", on_tap_link=lambda e: e.page.launch_url(e.data))\n",
        "  for mod in finetuned_models:\n",
        "      finetuned_model.options.append(dropdown.Option(mod[\"name\"]))\n",
        "  dreambooth_library = Dropdown(label=\"DreamBooth Library\", hint_text=\"\", width=370, options=[], value=prefs['dreambooth_model'], autofocus=False, on_change=changed_dreambooth_library, col={'xs':10, 'md':4})\n",
        "  for db in dreambooth_models:\n",
        "      dreambooth_library.options.append(dropdown.Option(db[\"name\"]))\n",
        "  custom_model = TextField(label=\"Custom Model Path\", value=prefs['custom_model'], width=370, on_change=changed_custom_model)\n",
        "  #custom_area = AnimatedSwitcher(model_card, transition=\"scale\", duration=500, reverse_duration=200, switch_in_curve=AnimationCurve.EASE_OUT, switch_out_curve=\"easeIn\")\n",
        "  custom_area = Container(model_card, col={'xs':4, 'lg':2})\n",
        "  if prefs['model_ckpt'].startswith(\"Stable\"):\n",
        "      custom_area.content = model_card\n",
        "  elif prefs['model_ckpt'] == \"Community Finetuned Model\":\n",
        "      custom_area.content = Row([finetuned_model, model_card], col={'xs':9, 'lg':4})\n",
        "  elif prefs['model_ckpt'] == \"DreamBooth Library Model\":\n",
        "      custom_area.content = Row([dreambooth_library, model_card], col={'xs':9, 'lg':4})\n",
        "  elif prefs['model_ckpt'] == \"Custom Model Path\":\n",
        "      custom_area.content = Row([custom_model, model_card], col={'xs':9, 'lg':4})\n",
        "  model_row = ResponsiveRow([model_ckpt, custom_area], run_spacing=8)\n",
        "  memory_optimization = Dropdown(label=\"Enable Memory Optimization\", width=350, options=[dropdown.Option(\"None\"), dropdown.Option(\"Attention Slicing\"), dropdown.Option(\"Xformers Mem Efficient Attention\")], value=prefs['memory_optimization'], on_change=lambda e:changed(e, 'memory_optimization'))\n",
        "  higher_vram_mode = Checkbox(label=\"Higher VRAM Mode\", tooltip=\"Adds a bit more precision but takes longer & uses much more GPU memory. Not recommended.\", value=prefs['higher_vram_mode'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'higher_vram_mode'))\n",
        "  sequential_cpu_offload = Checkbox(label=\"Enable Sequential CPU Offload\", tooltip=\"Offloads all models to CPU using accelerate, significantly reducing memory usage.\", value=prefs['sequential_cpu_offload'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'sequential_cpu_offload'))\n",
        "  enable_attention_slicing = Checkbox(label=\"Enable Attention Slicing\", tooltip=\"Saves VRAM while creating images so you can go bigger without running out of mem.\", value=prefs['enable_attention_slicing'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'enable_attention_slicing'))\n",
        "  enable_vae_slicing = Checkbox(label=\"Enable VAE Slicing\", tooltip=\"Sliced VAE decode latents for larger batches of images with limited VRAM. Splits the input tensor in slices to compute decoding in several steps\", value=prefs['vae_slicing'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'vae_slicing'))\n",
        "  #install_megapipe = Switch(label=\"Install Stable Diffusion txt2image, img2img & Inpaint Mega Pipeline\", value=prefs['install_megapipe'], disabled=status['installed_megapipe'], on_change=lambda e:changed(e, 'install_megapipe'))\n",
        "  install_text2img = Tooltip(message=\"The best general purpose component. Create images with long prompts, weights & models\", content=Switch(label=\"Install Stable Diffusion text2image, image2image & Inpaint Pipeline (/w Long Prompt Weighting)\", value=prefs['install_text2img'], disabled=status['installed_txt2img'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e, 'install_text2img')))\n",
        "  install_img2img = Tooltip(message=\"Gets more coherant results modifying Inpaint init & mask images\", content=Switch(label=\"Install Stable Diffusion Specialized Inpainting Model for image2image & Inpaint Pipeline\", value=prefs['install_img2img'], disabled=status['installed_img2img'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e, 'install_img2img')))\n",
        "  #install_repaint = Tooltip(message=\"Without using prompts, redraw masked areas to remove and repaint.\", content=Switch(label=\"Install Stable Diffusion RePaint Pipeline\", value=prefs['install_repaint'], disabled=status['installed_repaint'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e, 'install_repaint')))\n",
        "  install_interpolation = Tooltip(message=\"Create multiple tween images between prompts latent space. Almost animation.\", content=Switch(label=\"Install Stable Diffusion Prompt Walk Interpolation Pipeline\", value=prefs['install_interpolation'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, disabled=status['installed_interpolation'], on_change=lambda e:changed(e, 'install_interpolation')))\n",
        "  #install_dreamfusion = Tooltip(message=\"Generate interesting mesh .obj, texture and preview video from a prompt.\", content=Switch(label=\"Install Stable Diffusion DreamFusion 3D Pipeline\", value=prefs['install_dreamfusion'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, disabled=status['installed_dreamfusion'], on_change=lambda e:changed(e, 'install_dreamfusion')))\n",
        "  install_imagic = Tooltip(message=\"Edit your image according to the prompted instructions like magic.\", content=Switch(label=\"Install Stable Diffusion iMagic image2image Pipeline\", value=prefs['install_imagic'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, disabled=status['installed_imagic'], on_change=lambda e:changed(e, 'install_imagic')))\n",
        "  install_depth2img = Tooltip(message=\"Uses Depth-map of init image for text-guided image to image generation.\", content=Switch(label=\"Install Stable Diffusion Depth2Image Pipeline\", value=prefs['install_depth2img'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, disabled=status['installed_depth2img'], on_change=lambda e:changed(e, 'install_depth2img')))\n",
        "  install_composable = Tooltip(message=\"Craft your prompts with precise weights and composed together components.\", content=Switch(label=\"Install Stable Diffusion Composable text2image Pipeline\", value=prefs['install_composable'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, disabled=status['installed_composable'], on_change=lambda e:changed(e, 'install_composable')))\n",
        "  install_safe = Tooltip(message=\"Use a content quality tuned safety model, providing levels of NSFW protection.\", content=Switch(label=\"Install Stable Diffusion Safe text2image Pipeline\", value=prefs['install_safe'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, disabled=status['installed_safe'], on_change=toggle_safe))\n",
        "  safety_config = Container(Dropdown(label=\"Model Safety Level\", width=350, options=[dropdown.Option(\"Weak\"), dropdown.Option(\"Medium\"), dropdown.Option(\"Strong\"), dropdown.Option(\"Max\")], value=prefs['safety_config'], on_change=lambda e:changed(e, 'safety_config')), padding=padding.only(left=32))\n",
        "  safety_config.visible = prefs['install_safe']\n",
        "  install_versatile = Tooltip(message=\"Multi-flow model that provides both image and text data streams and conditioned on both text and image.\", content=Switch(label=\"Install Versatile Diffusion text2image, Dual Guided & Image Variation Pipeline\", value=prefs['install_versatile'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, disabled=status['installed_versatile'], on_change=lambda e:changed(e, 'install_versatile')))\n",
        "  \n",
        "  def toggle_clip(e):\n",
        "      prefs['install_CLIP_guided'] = install_CLIP_guided.content.value\n",
        "      status['changed_installers'] = True\n",
        "      clip_settings.height=None if prefs['install_CLIP_guided'] else 0\n",
        "      clip_settings.update()\n",
        "  install_CLIP_guided = Tooltip(message=\"Uses alternative LAION & OpenAI ViT diffusion. Takes more VRAM, so may need to make images smaller\", content=Switch(label=\"Install Stable Diffusion CLIP-Guided Pipeline\", value=prefs['install_CLIP_guided'], disabled=status['installed_clip'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_clip))\n",
        "  clip_model_id = Dropdown(label=\"CLIP Model ID\", width=350,\n",
        "            options=[\n",
        "                dropdown.Option(\"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\"),\n",
        "                dropdown.Option(\"laion/CLIP-ViT-L-14-laion2B-s32B-b82K\"),\n",
        "                dropdown.Option(\"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"),\n",
        "                dropdown.Option(\"laion/CLIP-ViT-g-14-laion2B-s12B-b42K\"),\n",
        "                dropdown.Option(\"openai/clip-vit-base-patch32\"),\n",
        "                dropdown.Option(\"openai/clip-vit-base-patch16\"),\n",
        "                dropdown.Option(\"openai/clip-vit-large-patch14\"),\n",
        "            ], value=prefs['clip_model_id'], autofocus=False, on_change=lambda e:changed(e, 'clip_model_id'),\n",
        "        )\n",
        "  clip_settings = Container(animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE, padding=padding.only(left=32, top=4), content=Column([clip_model_id]))\n",
        "  \n",
        "  def toggle_conceptualizer(e):\n",
        "      changed(e, 'install_conceptualizer')\n",
        "      conceptualizer_settings.height = None if e.control.value else 0\n",
        "      conceptualizer_settings.update()\n",
        "  def change_concepts_model(e):\n",
        "      nonlocal concept\n",
        "      changed(e, 'concepts_model')\n",
        "      concept = get_concept(e.control.value)\n",
        "      concepts_info.value = f\"To use the concept, include keyword token **<{concept['token']}>** in your Prompts. Info at [https://huggingface.co/sd-concepts-library/{concept['name']}](https://huggingface.co/sd-concepts-library/{concept['name']})\"\n",
        "      concepts_info.update()\n",
        "  def open_url(e):\n",
        "      page.launch_url(e.data)\n",
        "  def copy_token(e):\n",
        "      nonlocal concept\n",
        "      page.set_clipboard(f\"<{concept['token']}>\")\n",
        "      page.snack_bar = SnackBar(content=Text(f\"üìã  Token <{concept['token']}> copied to clipboard... Paste as word in your Prompt Text.\"))\n",
        "      page.snack_bar.open = True\n",
        "      page.update()\n",
        "  install_conceptualizer = Tooltip(message=\"Loads specially trained concept models to include in prompt with token\", content=Switch(label=\"Install Stable Diffusion Textual-Inversion Conceptualizer Pipeline\", value=prefs['install_conceptualizer'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_conceptualizer))\n",
        "  concept = get_concept(prefs['concepts_model'])\n",
        "  concepts_model = Dropdown(label=\"SD-Concepts Library Model\", hint_text=\"Specially trained community models made with Textual-Inversion\", width=451, options=[], value=prefs['concepts_model'], on_change=change_concepts_model)\n",
        "  copy_token_btn = IconButton(icon=icons.CONTENT_COPY, tooltip=\"Copy Token to Clipboard\", on_click=copy_token)\n",
        "  concepts_row = Row([concepts_model, copy_token_btn])\n",
        "  concepts_info = Markdown(f\"To use the concept, include keyword token **<{concept['token']}>** in your Prompts. Info at [https://huggingface.co/sd-concepts-library/{concept['name']}](https://huggingface.co/sd-concepts-library/{concept['name']})\", selectable=True, on_tap_link=open_url)\n",
        "  conceptualizer_settings = Container(animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE, padding=padding.only(left=32, top=5), content=Column([concepts_row, concepts_info]))\n",
        "  conceptualizer_settings.height = None if prefs['install_conceptualizer'] else 0\n",
        "  for c in concepts: concepts_model.options.append(dropdown.Option(c['name']))\n",
        "  install_upscale = Tooltip(message=\"Allows you to enlarge images with prompts. Note: Will run out of mem for images larger than 512px, start small.\", content=Switch(label=\"Install Stable Diffusion v2 Upscale 4X Pipeline\", value=prefs['install_upscale'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, disabled=status['installed_upscale'], on_change=lambda e:changed(e, 'install_upscale')))\n",
        "\n",
        "  diffusers_settings = Container(animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE, content=\n",
        "                                 Column([Container(Column([model_row, Container(content=None, height=4), scheduler_mode, higher_vram_mode, \n",
        "                                 #memory_optimization, sequential_cpu_offload,\n",
        "                                 enable_attention_slicing, enable_vae_slicing]), padding=padding.only(left=32, top=4)),\n",
        "                                         install_text2img, install_img2img, #install_repaint, #install_megapipe, \n",
        "                                         install_interpolation, install_CLIP_guided, clip_settings, install_conceptualizer, conceptualizer_settings, install_safe, safety_config, \n",
        "                                         install_versatile, install_imagic, install_depth2img, install_composable, install_upscale]))\n",
        "  def toggle_stability(e):\n",
        "      prefs['install_Stability_api'] = install_Stability_api.content.value\n",
        "      has_changed=True\n",
        "      #print(f\"Toggle Stability {prefs['install_Stability_api']}\")\n",
        "      stability_settings.height=None if prefs['install_Stability_api'] else 0\n",
        "      stability_settings.update()\n",
        "      page.update()\n",
        "      #stability_box.content = stability_settings if prefs['install_stability'] else Container(content=None)\n",
        "      #stability_box.update()\n",
        "  install_Stability_api = Tooltip(message=\"Use DreamStudio.com servers without your GPU to create images on CPU.\", content=Switch(label=\"Install Stability-API DreamStudio Pipeline\", value=prefs['install_Stability_api'], disabled=status['installed_stability'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_stability))\n",
        "  use_Stability_api = Checkbox(label=\"Use Stability-ai API by default\", tooltip=\"Instead of using Diffusers, generate images in their cloud. Can toggle to compare batches..\", value=prefs['use_Stability_api'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e, 'use_Stability_api'))\n",
        "  model_checkpoint = Dropdown(label=\"Model Checkpoint\", hint_text=\"\", width=350, options=[dropdown.Option(\"stable-diffusion-768-v2-1\"), dropdown.Option(\"stable-diffusion-512-v2-1\"), dropdown.Option(\"stable-diffusion-768-v2-0\"), dropdown.Option(\"stable-diffusion-512-v2-0\"), dropdown.Option(\"stable-diffusion-v1-5\"), dropdown.Option(\"stable-diffusion-v1\"), dropdown.Option(\"stable-inpainting-512-v2-0\"), dropdown.Option(\"stable-inpainting-v1-0\")], value=prefs['model_checkpoint'], autofocus=False, on_change=lambda e:changed(e, 'model_checkpoint'))\n",
        "  clip_guidance_preset = Dropdown(label=\"Clip Guidance Preset\", width=350, options=[dropdown.Option(\"SIMPLE\"), dropdown.Option(\"FAST_BLUE\"), dropdown.Option(\"FAST_GREEN\"), dropdown.Option(\"SLOW\"), dropdown.Option(\"SLOWER\"), dropdown.Option(\"SLOWEST\"), dropdown.Option(\"NONE\")], value=prefs['clip_guidance_preset'], autofocus=False, on_change=lambda e:changed(e, 'clip_guidance_preset'))\n",
        "  #generation_sampler = Dropdown(label=\"Generation Sampler\", hint_text=\"\", width=350, options=[dropdown.Option(\"ddim\"), dropdown.Option(\"plms\"), dropdown.Option(\"k_euler\"), dropdown.Option(\"k_euler_ancestral\"), dropdown.Option(\"k_heun\"), dropdown.Option(\"k_dpm_2\"), dropdown.Option(\"k_dpm_2_ancestral\"), dropdown.Option(\"k_lms\")], value=prefs['generation_sampler'], autofocus=False, on_change=lambda e:changed(e, 'generation_sampler'))\n",
        "  generation_sampler = Dropdown(label=\"Generation Sampler\", hint_text=\"\", width=350, options=[dropdown.Option(\"DDIM\"), dropdown.Option(\"DDPM\"), dropdown.Option(\"K_EULER\"), dropdown.Option(\"K_EULER_ANCESTRAL\"), dropdown.Option(\"K_HEUN\"), dropdown.Option(\"K_DPMPP_2M\"), dropdown.Option(\"K_DPM_2_ANCESTRAL\"), dropdown.Option(\"K_LMS\"), dropdown.Option(\"K_DPMPP_2S_ANCESTRAL\"), dropdown.Option(\"K_DPM_2\")], value=prefs['generation_sampler'], autofocus=False, on_change=lambda e:changed(e, 'generation_sampler'))\n",
        "  #\"K_EULER\" \"K_DPM_2\" \"K_LMS\" \"K_DPMPP_2S_ANCESTRAL\" \"K_DPMPP_2M\" \"DDIM\" \"DDPM\" \"K_EULER_ANCESTRAL\" \"K_HEUN\" \"K_DPM_2_ANCESTRAL\"\n",
        "  stability_settings = Container(animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE, padding=padding.only(left=32), content=Column([use_Stability_api, model_checkpoint, generation_sampler, clip_guidance_preset]))\n",
        "  \n",
        "  install_ESRGAN = Tooltip(message=\"Recommended to enlarge & sharpen all images as they're made.\", content=Switch(label=\"Install Real-ESRGAN AI Upscaler\", value=prefs['install_ESRGAN'], disabled=status['installed_ESRGAN'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e, 'install_ESRGAN')))\n",
        "  install_OpenAI = Tooltip(message=\"Use advanced AI to help make creative prompts. Also enables DALL-E 2 generation.\", content=Switch(label=\"Install OpenAI GPT-3 Text Engine\", value=prefs['install_OpenAI'], disabled=status['installed_OpenAI'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e, 'install_OpenAI')))\n",
        "  install_TextSynth = Tooltip(message=\"Alternative Text AI for brainstorming & rewriting your prompts. Pretty smart..\", content=Switch(label=\"Install TextSynth GPT-J Text Engine\", value=prefs['install_TextSynth'], disabled=status['installed_TextSynth'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e, 'install_TextSynth')))\n",
        "  diffusers_settings.height = None if prefs['install_diffusers'] else 0\n",
        "  stability_settings.height = None if prefs['install_Stability_api'] else 0\n",
        "  clip_settings.height = None if prefs['install_CLIP_guided'] else 0\n",
        "  \n",
        "  \n",
        "  def run_installers(e):\n",
        "      def console_clear():\n",
        "        page.banner.content.controls = []\n",
        "        page.update()\n",
        "      def console_msg(msg, clear=True, show_progress=True):\n",
        "        if not page.banner.open:\n",
        "          page.banner.open = True\n",
        "        if clear:\n",
        "          page.banner.content.controls = []\n",
        "        if show_progress:\n",
        "          page.banner.content.controls.append(Row([Stack([Icon(icons.DOWNLOADING, color=colors.AMBER, size=48), Container(content=ProgressRing(), padding=padding.only(top=6, left=6), alignment=alignment.center)]), Container(content=Text(\"  \" + msg.strip() , weight=FontWeight.BOLD, color=colors.ON_SECONDARY_CONTAINER, size=18), alignment=alignment.bottom_left, padding=padding.only(top=6)) ]))\n",
        "          #page.banner.content.controls.append(Stack([Container(content=Text(msg.strip() + \"  \", weight=FontWeight.BOLD, color=colors.ON_SECONDARY_CONTAINER, size=18), alignment=alignment.bottom_left, padding=padding.only(top=6)), Container(content=ProgressRing(), alignment=alignment.center if page.width > 768 else alignment.center_right)]))\n",
        "          #page.banner.content.controls.append(Stack([Container(content=Text(msg.strip() + \"  \", weight=FontWeight.BOLD, color=colors.ON_SECONDARY_CONTAINER, size=18), alignment=alignment.bottom_left, padding=padding.only(top=6)), Container(content=ProgressRing(), alignment=alignment.center)]))\n",
        "          #page.banner.content.controls.append(Row([Text(msg.strip() + \"  \", weight=FontWeight.BOLD, color=colors.GREEN_600), ProgressRing()]))\n",
        "        else:\n",
        "          page.banner.content.controls.append(Text(msg.strip(), weight=FontWeight.BOLD, color=colors.GREEN_600))\n",
        "        page.update()\n",
        "      page.console_msg = console_msg\n",
        "      if status['changed_installers']:\n",
        "        save_settings_file(page, change_icon=False)\n",
        "        status['changed_installers'] = False\n",
        "      # Temporary until I get Xformers to work\n",
        "      prefs['memory_optimization'] = 'Attention Slicing' if prefs['enable_attention_slicing'] else 'None'\n",
        "      if prefs['install_diffusers'] and not bool(prefs['HuggingFace_api_key']):\n",
        "        alert_msg(e.page, \"You must provide your HuggingFace API Key to use Diffusers.\")\n",
        "        return\n",
        "      if prefs['install_Stability_api'] and not bool(prefs['Stability_api_key']):\n",
        "        alert_msg(e.page, \"You must have your DreamStudio.ai Stability-API Key to use Stability.  Note that it will use your tokens.\")\n",
        "        return\n",
        "      if prefs['install_OpenAI'] and not bool(prefs['OpenAI_api_key']):\n",
        "        alert_msg(e.page, \"You must have your OpenAI API Key to use GPT-3 Text AI.\")\n",
        "        return\n",
        "      if prefs['install_TextSynth'] and not bool(prefs['TextSynth_api_key']):\n",
        "        alert_msg(e.page, \"You must have your TextSynth API Key to use GPT-J Text AI.\")\n",
        "        return\n",
        "      page.banner.content = Column([], scroll=ScrollMode.AUTO, auto_scroll=True, tight=True, spacing=0, alignment=MainAxisAlignment.END)\n",
        "      page.banner.open = True\n",
        "      page.update()\n",
        "      if prefs['install_diffusers']:\n",
        "        console_msg(\"Installing Hugging Face Diffusers Pipeline...\")\n",
        "        get_diffusers(page)\n",
        "        status['installed_diffusers'] = True\n",
        "      if prefs['install_text2img'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Downloading Stable Diffusion Text2Image, Image2Image & Inpaint Pipeline...\")\n",
        "        #with io.StringIO() as buf, redirect_stdout(buf):\n",
        "        #print('redirected')\n",
        "        get_text2image(page)\n",
        "        #output = buf.getvalue()\n",
        "        #page.banner.content.controls.append(Text(output.strip()))\n",
        "        status['installed_txt2img'] = True\n",
        "        page.img_block.height = None\n",
        "        page.img_block.update()\n",
        "        page.update()\n",
        "      if prefs['install_img2img'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Downloading Stable Diffusion Inpaint Model & Image2Image Pipeline...\")\n",
        "        get_image2image(page)\n",
        "        status['installed_img2img'] = True\n",
        "        page.img_block.height = None\n",
        "        page.img_block.update()\n",
        "        page.use_inpaint_model.visible = True\n",
        "        page.use_inpaint_model.update()\n",
        "        if not status['installed_txt2img']:\n",
        "          prefs['use_inpaint_model'] = True\n",
        "      '''if prefs['install_megapipe'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Downloading Stable Diffusion Unified Mega Pipeline...\")\n",
        "        get_text2image(page)\n",
        "        status['installed_megapipe'] = True\n",
        "        page.img_block.height = None\n",
        "        page.img_block.update()'''\n",
        "      if prefs['install_interpolation'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Downloading Stable Diffusion Walk Interpolation Pipeline...\")\n",
        "        get_interpolation(page)\n",
        "        status['installed_interpolation'] = True\n",
        "        page.interpolation_block.visible = True\n",
        "        page.interpolation_block.update()\n",
        "      if prefs['install_CLIP_guided'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Downloading Stable Diffusion CLIP-Guided Pipeline...\")\n",
        "        get_clip(page)\n",
        "        status['installed_clip'] = True\n",
        "        page.use_clip_guided_model.visible = True\n",
        "        page.use_clip_guided_model.update()\n",
        "        page.clip_block.height = None if prefs['use_clip_guided_model'] else 0\n",
        "        page.clip_block.update()\n",
        "        if prefs['use_clip_guided_model']:\n",
        "          page.img_block.height = 0\n",
        "          page.img_block.update()\n",
        "      if prefs['install_conceptualizer'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Installing SD Concepts Library Textual Inversion Pipeline...\")\n",
        "        get_conceptualizer(page)\n",
        "        page.use_conceptualizer_model.visible = True\n",
        "        page.use_conceptualizer_model.update()\n",
        "        if prefs['use_conceptualizer']:\n",
        "          page.img_block.height = 0\n",
        "          page.img_block.update()\n",
        "        status['installed_conceptualizer'] = True\n",
        "      if prefs['install_repaint'] and not status['installed_repaint'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Installing Stable Diffusion RePaint Pipeline...\")\n",
        "        get_repaint(page)\n",
        "        status['installed_repaint'] = True\n",
        "      if prefs['install_depth2img'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Installing Stable Diffusion 2 Depth2Image Pipeline...\")\n",
        "        get_depth2img(page)\n",
        "        status['installed_depth2img'] = True\n",
        "        if not status['installed_txt2img']:\n",
        "          page.img_block.height = None\n",
        "          page.img_block.update()\n",
        "        page.use_depth2img.visible = True\n",
        "        page.use_depth2img.update()\n",
        "      if prefs['install_imagic'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Installing Stable Diffusion iMagic image2image Pipeline...\")\n",
        "        get_imagic(page)\n",
        "        status['installed_imagic'] = True\n",
        "        if not status['installed_txt2img']:\n",
        "          page.img_block.height = None\n",
        "          page.img_block.update()\n",
        "        page.use_imagic.visible = True\n",
        "        page.use_imagic.update()\n",
        "      if prefs['install_composable'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Installing Stable Diffusion Composable text2image Pipeline...\")\n",
        "        get_composable(page)\n",
        "        status['installed_composable'] = True\n",
        "        page.use_composable.visible = True\n",
        "        page.use_composable.update()\n",
        "      if prefs['install_versatile'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Installing Stable Diffusion Versatile text2image, Variation & Inpaint Pipeline...\")\n",
        "        get_versatile(page)\n",
        "        status['installed_versatile'] = True\n",
        "        if not status['installed_txt2img']:\n",
        "          page.img_block.height = None\n",
        "          page.img_block.update()\n",
        "        page.use_versatile.visible = True\n",
        "        page.use_versatile.update()\n",
        "      if prefs['install_safe'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Installing Stable Diffusion Safe text2image Pipeline...\")\n",
        "        get_safe(page)\n",
        "        status['installed_safe'] = True\n",
        "        page.use_safe.visible = True\n",
        "        page.use_safe.update()\n",
        "      if prefs['install_upscale'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Installing Stable Diffusion 4X Upscale Pipeline...\")\n",
        "        get_upscale(page)\n",
        "        status['installed_upscale'] = True\n",
        "        page.use_upscale.visible = True\n",
        "        page.use_upscale.update()\n",
        "      if prefs['install_dreamfusion'] and not status['installed_dreamfusion'] and prefs['install_diffusers']:\n",
        "        console_msg(\"Installing Stable Diffusion DreamFusion 3D Pipeline...\")\n",
        "        get_dreamfusion(page)\n",
        "        status['installed_dreamfusion'] = True\n",
        "      if prefs['install_Stability_api']:\n",
        "        console_msg(\"Installing Stability-API DreamStudio.ai Pipeline...\")\n",
        "        get_stability(page)\n",
        "        status['installed_stability'] = True\n",
        "      if prefs['install_ESRGAN'] and not status['installed_ESRGAN']:\n",
        "        if not os.path.isdir(os.path.join(dist_dir, 'Real-ESRGAN')):\n",
        "          get_ESRGAN(page)\n",
        "          console_msg(\"Installing Real-ESRGAN Upscaler...\")\n",
        "        status['installed_ESRGAN'] = True\n",
        "        page.ESRGAN_block.height = None\n",
        "        page.ESRGAN_block_material.height = None\n",
        "        page.ESRGAN_block_dalle.height = None\n",
        "        page.ESRGAN_block_kandinsky.height = None\n",
        "        page.ESRGAN_block.update()\n",
        "        page.ESRGAN_block_material.update()\n",
        "        page.ESRGAN_block_dalle.update()\n",
        "        page.ESRGAN_block_kandinsky.update()\n",
        "      if prefs['install_OpenAI'] and not status['installed_OpenAI']:\n",
        "        try:\n",
        "          import openai\n",
        "        except ImportError as e:\n",
        "          console_msg(\"Installing OpenAI GPT-3 Libraries...\")\n",
        "          run_process(\"pip install openai -qq\", page=page)\n",
        "          pass\n",
        "        status['installed_OpenAI'] = True\n",
        "      if prefs['install_TextSynth'] and not status['installed_TextSynth']:\n",
        "        try:\n",
        "          from textsynthpy import TextSynth, Complete\n",
        "        except ImportError as e:\n",
        "          console_msg(\"Installing TextSynth GPT-J Libraries...\")\n",
        "          run_process(\"pip install textsynthpy -qq\", page=page)\n",
        "          pass\n",
        "        status['installed_TextSynth'] = True\n",
        "      #print('Done Installing...')\n",
        "      if prefs['enable_sounds']: page.snd_done.play()\n",
        "      console_clear()\n",
        "      page.banner.open = False\n",
        "      page.banner.update()\n",
        "      page.update()\n",
        "      install_diffusers.update()\n",
        "      #install_text2img.update()\n",
        "      #install_img2img.update()\n",
        "      install_Stability_api.update()\n",
        "      install_CLIP_guided.update()\n",
        "      install_ESRGAN.update()\n",
        "      install_OpenAI.update()\n",
        "      install_TextSynth.update()\n",
        "      update_parameters(page)\n",
        "      page.Parameters.controls[0].content.update()\n",
        "      #page.Parameters.updater()\n",
        "      page.Installers.controls[0].content.update()\n",
        "      page.Installers.update()\n",
        "      page.show_install_fab(False)\n",
        "      page.tabs.selected_index = 2\n",
        "      page.tabs.update()\n",
        "      page.update()\n",
        "  def show_install_fab(show = True):\n",
        "    if show:\n",
        "      page.floating_action_button = FloatingActionButton(icon=icons.FILE_DOWNLOAD, text=\"Run Installations\", on_click=run_installers)\n",
        "      page.update()\n",
        "    else:\n",
        "      if page.floating_action_button is not None:\n",
        "        page.floating_action_button = None\n",
        "        page.update()\n",
        "  page.show_install_fab = show_install_fab\n",
        "  install_button = ElevatedButton(content=Text(value=\"‚è¨   Run Installations \", size=20), on_click=run_installers)\n",
        "  \n",
        "  #image_output = TextField(label=\"Image Output Path\", value=prefs['image_output'], on_change=changed)\n",
        "  c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "                content=Column([\n",
        "        Text (\"üì•  Stable Diffusion Required & Optional Installers\", style=TextThemeStyle.TITLE_LARGE),\n",
        "        Divider(thickness=1, height=4),\n",
        "        install_diffusers,\n",
        "        diffusers_settings,\n",
        "        #install_text2img,\n",
        "        #install_img2img,\n",
        "        install_Stability_api,\n",
        "        stability_settings,\n",
        "        #install_CLIP_guided,\n",
        "        #clip_settings,\n",
        "        install_ESRGAN,\n",
        "        install_OpenAI,\n",
        "        install_TextSynth,\n",
        "        #install_button,\n",
        "        Container(content=None, height=32),\n",
        "      ],\n",
        "  ))], scroll=ScrollMode.AUTO)\n",
        "  def init_boxes():\n",
        "    diffusers_settings.height = None if prefs['install_diffusers'] else 0\n",
        "    stability_settings.height = None if prefs['install_Stability_api'] else 0\n",
        "    clip_settings.height = None if prefs['install_CLIP_guided'] else 0\n",
        "    diffusers_settings.update()\n",
        "    stability_settings.update()\n",
        "    clip_settings.update()\n",
        "    page.update()\n",
        "  #init_boxes()\n",
        "  return c\n",
        "\n",
        "def update_parameters(page):\n",
        "  #page.img_block.height = None if status['installed_img2img'] or status['installed_megapipe'] or status['installed_stability'] else 0\n",
        "  page.img_block.height = None if (status['installed_txt2img'] or status['installed_stability']) and not (status['installed_clip'] and prefs['use_clip_guided_model']) else 0\n",
        "  page.clip_block.height = None if status['installed_clip']  and prefs['use_clip_guided_model'] else 0\n",
        "  page.ESRGAN_block.height = None if status['installed_ESRGAN'] else 0\n",
        "  page.img_block.update()\n",
        "  page.clip_block.update()\n",
        "  page.ESRGAN_block.update()\n",
        "  page.Parameters.update()\n",
        "  #print(\"Updated Parameters\")\n",
        "\n",
        "if is_Colab:\n",
        "    from google.colab import files\n",
        "def buildParameters(page):\n",
        "  global prefs, status, args\n",
        "  def changed(e, pref=None, asInt=False):\n",
        "      if pref is not None:\n",
        "        prefs[pref] = e.control.value if not asInt else int(e.control.value)\n",
        "      if page.floating_action_button is None:\n",
        "        show_apply_fab(len(prompts) > 0)\n",
        "      #if apply_changes_button.visible != (len(prompts) > 0): #status['changed_parameters']:\n",
        "      #  apply_changes_button.visible = len(prompts) > 0\n",
        "      #  apply_changes_button.update()\n",
        "      status['changed_parameters'] = True\n",
        "      #page.update()\n",
        "  def run_parameters(e):\n",
        "      save_parameters()\n",
        "      #page.tabs.current_tab = 3\n",
        "      page.show_apply_fab(False)\n",
        "      page.tabs.selected_index = 3\n",
        "      page.tabs.update()\n",
        "      page.update()\n",
        "  def save_parameters():\n",
        "      update_args()\n",
        "      page.update_prompts()\n",
        "      save_settings_file(page)\n",
        "      status['changed_parameters'] = False\n",
        "  def apply_to_prompts(e):\n",
        "      update_args()\n",
        "      page.apply_changes(e)\n",
        "      save_settings_file(page)\n",
        "      show_apply_fab(False)\n",
        "      #apply_changes_button.visible = False\n",
        "      #apply_changes_button.update()\n",
        "  def pick_files_result(e: FilePickerResultEvent):\n",
        "      # TODO: This is not working on Colab, maybe it can get_upload_url on other platform?\n",
        "      if e.files:\n",
        "        img = e.files\n",
        "        uf = []\n",
        "        fname = img[0]\n",
        "        print(\", \".join(map(lambda f: f.name, e.files)))\n",
        "        #print(os.path.join(fname.path, fname.name))\n",
        "        #src_path = os.path.join(fname.path, fname.name)\n",
        "        #for f in pick_files_dialog.result.files:\n",
        "        src_path = page.get_upload_url(fname.name, 600)\n",
        "        uf.append(FilePickerUploadFile(fname.name, upload_url=src_path))\n",
        "        pick_files_dialog.upload(uf)\n",
        "        print(str(src_path))\n",
        "        #src_path = ''.join(src_path)\n",
        "        print(str(uf[0]))\n",
        "        dst_path = os.path.join(root_dir, fname.name)\n",
        "        print(f'Copy {src_path} to {dst_path}')\n",
        "        #shutil.copy(src_path, dst_path)\n",
        "        # TODO: is init or mask?\n",
        "        init_image.value = dst_path\n",
        "      #selected_files.value = (\", \".join(map(lambda f: f.name, e.files)) if e.files else \"Cancelled!\")\n",
        "      #selected_files.update()\n",
        "\n",
        "  pick_files_dialog = FilePicker(on_result=pick_files_result)\n",
        "  page.overlay.append(pick_files_dialog)\n",
        "  #selected_files = Text()\n",
        "\n",
        "  def file_picker_result(e: FilePickerResultEvent):\n",
        "      if e.files != None:\n",
        "        upload_files(e)\n",
        "  def on_upload_progress(e: FilePickerUploadEvent):\n",
        "    nonlocal pick_type\n",
        "    if e.progress == 1:\n",
        "      fname = os.path.join(root_dir, e.file_name)\n",
        "      if pick_type == \"init\":\n",
        "        init_image.value = fname\n",
        "        init_image.update()\n",
        "        prefs['init_image'] = fname\n",
        "      elif pick_type == \"mask\":\n",
        "        mask_image.value = fname\n",
        "        mask_image.update()\n",
        "        prefs['mask_image'] = fname\n",
        "      page.update()\n",
        "  file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "  def upload_files(e):\n",
        "      uf = []\n",
        "      if file_picker.result != None and file_picker.result.files != None:\n",
        "          for f in file_picker.result.files:\n",
        "              uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "          file_picker.upload(uf)\n",
        "  page.overlay.append(file_picker)\n",
        "  pick_type = \"\"\n",
        "  #page.overlay.append(pick_files_dialog)\n",
        "  def pick_init(e):\n",
        "      nonlocal pick_type\n",
        "      pick_type = \"init\"\n",
        "      file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Init Image File\")\n",
        "  def pick_mask(e):\n",
        "      nonlocal pick_type\n",
        "      pick_type = \"mask\"\n",
        "      file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Black & White Mask Image\")\n",
        "  def toggle_ESRGAN(e):\n",
        "      ESRGAN_settings.height = None if e.control.value else 0\n",
        "      prefs['apply_ESRGAN_upscale'] = e.control.value\n",
        "      ESRGAN_settings.update()\n",
        "      has_changed = True\n",
        "  def toggle_clip(e):\n",
        "      if e.control.value:\n",
        "        page.img_block.height = 0\n",
        "        page.clip_block.height = None if status['installed_clip'] else 0\n",
        "      else:\n",
        "        page.img_block.height = None if status['installed_txt2img'] or status['installed_stability'] else 0\n",
        "        page.clip_block.height = 0\n",
        "      page.img_block.update()\n",
        "      page.clip_block.update()\n",
        "      changed(e, 'use_clip_guided_model')\n",
        "  def change_use_cutouts(e):\n",
        "      num_cutouts.visible = e.control.value\n",
        "      num_cutouts.update()\n",
        "      changed(e, 'use_cutouts')\n",
        "  def change_guidance(e):\n",
        "      guidance_value.value = f\" {e.control.value}\"\n",
        "      guidance_value.update()\n",
        "      #guidance.controls[1].value = f\" {e.control.value}\"\n",
        "      guidance.update()\n",
        "      changed(e, 'guidance_scale')\n",
        "  def change_width(e):\n",
        "      width_slider.controls[1].value = f\" {int(e.control.value)}px\"\n",
        "      width_slider.update()\n",
        "      changed(e, 'width', asInt=True)\n",
        "  def change_height(e):\n",
        "      height_slider.controls[1].value = f\" {int(e.control.value)}px\"\n",
        "      height_slider.update()\n",
        "      changed(e, 'height', asInt=True)\n",
        "  def toggle_interpolation(e):\n",
        "      interpolation_steps_slider.height = None if e.control.value else 0\n",
        "      interpolation_steps_slider.update()\n",
        "      if e.control.value: page.img_block.height = 0\n",
        "      else: page.img_block.height = None if status['installed_txt2img'] or status['installed_stability'] else 0\n",
        "      page.img_block.update()\n",
        "      changed(e, 'use_interpolation')\n",
        "  def change_interpolation_steps(e):\n",
        "      interpolation_steps_value.value = f\" {int(e.control.value)} steps\"\n",
        "      interpolation_steps_value.update()\n",
        "      changed(e, 'num_interpolation_steps', asInt=True)\n",
        "  def change_enlarge_scale(e):\n",
        "      enlarge_scale_slider.controls[1].value = f\" {float(e.control.value)}x\"\n",
        "      enlarge_scale_slider.update()\n",
        "      changed(e, 'enlarge_scale')\n",
        "  def change_strength(e):\n",
        "      strength_value.value = f\" {int(e.control.value * 100)}\"\n",
        "      strength_value.update()\n",
        "      guidance.update()\n",
        "      changed(e, 'init_image_strength')\n",
        "  def toggle_conceptualizer(e):\n",
        "      if e.control.value:\n",
        "        page.img_block.height = 0\n",
        "      else:\n",
        "        page.img_block.height = None if status['installed_txt2img'] or status['installed_stability'] else 0\n",
        "      page.img_block.update()\n",
        "      changed(e, 'use_conceptualizer')\n",
        "  def toggle_centipede(e):\n",
        "      changed(e,'centipede_prompts_as_init_images')\n",
        "      image_pickers.height = None if not e.control.value else 0\n",
        "      image_pickers.update()\n",
        "  has_changed = False\n",
        "  batch_folder_name = TextField(label=\"Batch Folder Name\", value=prefs['batch_folder_name'], on_change=lambda e:changed(e,'batch_folder_name'))\n",
        "  batch_size = TextField(label=\"Batch Size\", value=prefs['batch_size'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'batch_size'))\n",
        "  n_iterations = TextField(label=\"Number of Iterations\", value=prefs['n_iterations'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'n_iterations'))\n",
        "  steps = TextField(label=\"Steps\", value=prefs['steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'steps', asInt=True))\n",
        "  eta = TextField(label=\"DDIM ETA\", value=prefs['eta'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'eta'))\n",
        "  seed = TextField(label=\"Seed\", value=prefs['seed'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'seed'))\n",
        "  param_rows = Row([Column([batch_folder_name, batch_size, n_iterations]), Column([steps, eta, seed])])\n",
        "  guidance_scale = Slider(min=0, max=50, divisions=100, label=\"{value}\", value=prefs['guidance_scale'], on_change=change_guidance, expand=True)\n",
        "  guidance_value = Text(f\" {prefs['guidance_scale']}\", weight=FontWeight.BOLD)\n",
        "  guidance = Row([Text(\"Guidance Scale: \"), guidance_value, guidance_scale])\n",
        "  width = Slider(min=256, max=1280, divisions=64, label=\"{value}px\", value=prefs['width'], on_change=change_width, expand=True)\n",
        "  width_value = Text(f\" {int(prefs['width'])}px\", weight=FontWeight.BOLD)\n",
        "  width_slider = Row([Text(f\"Width: \"), width_value, width])\n",
        "  height = Slider(min=256, max=1280, divisions=64, label=\"{value}px\", value=prefs['height'], on_change=change_height, expand=True)\n",
        "  height_value = Text(f\" {int(prefs['height'])}px\", weight=FontWeight.BOLD)\n",
        "  height_slider = Row([Text(f\"Height: \"), height_value, height])\n",
        "\n",
        "  init_image = TextField(label=\"Init Image\", value=prefs['init_image'], on_change=lambda e:changed(e,'init_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_init))\n",
        "  mask_image = TextField(label=\"Mask Image\", value=prefs['mask_image'], on_change=lambda e:changed(e,'mask_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD_OUTLINED, on_click=pick_mask))\n",
        "  alpha_mask = Checkbox(label=\"Alpha Mask\", value=prefs['alpha_mask'], tooltip=\"Use Transparent Alpha Channel of Init as Mask\", fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'alpha_mask'))\n",
        "  invert_mask = Checkbox(label=\"Invert Mask\", value=prefs['invert_mask'], tooltip=\"Reverse Black & White of Image Mask\", fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'invert_mask'))\n",
        "  image_pickers = Container(content=ResponsiveRow([Row([init_image, alpha_mask], col={\"lg\":6}), Row([mask_image, invert_mask], col={\"lg\":6})]), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "  image_pickers.height = None if not prefs['centipede_prompts_as_init_images'] else 0\n",
        "  init_image_strength = Slider(min=0.1, max=0.9, divisions=16, label=\"{value}%\", value=prefs['init_image_strength'], on_change=change_strength, expand=True)\n",
        "  strength_value = Text(f\" {int(prefs['init_image_strength'] * 100)}%\", weight=FontWeight.BOLD)\n",
        "  strength_slider = Row([Text(\"Init Image Strength: \"), strength_value, init_image_strength])\n",
        "  page.use_inpaint_model = Tooltip(message=\"When using init_image and/or mask, use the newer pipeline for potentially better results\", content=Switch(label=\"Use Specialized Inpaint Model Instead\", tooltip=\"When using init_image and/or mask, use the newer pipeline for potentially better results\", value=prefs['use_inpaint_model'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e,'use_inpaint_model')))\n",
        "  page.use_inpaint_model.visible = status['installed_img2img']\n",
        "  page.use_versatile = Tooltip(message=\"Dual Guided between prompt & image, or create Image Variation\", content=Switch(label=\"Use Versatile Pipeline Model Instead\", value=prefs['use_versatile'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e,'use_versatile')))\n",
        "  page.use_versatile.visible = status['installed_versatile']\n",
        "  centipede_prompts_as_init_images = Tooltip(message=\"Feeds each image to the next prompt sequentially down the line\", content=Switch(label=\"Centipede Prompts as Init Images\", tooltip=\"Feeds each image to the next prompt sequentially down the line\", value=prefs['centipede_prompts_as_init_images'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_centipede))\n",
        "  use_interpolation = Tooltip(message=\"Creates animation frames transitioning, but it's not always perfect.\", content=Switch(label=\"Use Interpolation to Walk Latent Space between Prompts\", tooltip=\"Creates animation frames transitioning, but it's not always perfect.\", value=prefs['use_interpolation'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_interpolation))\n",
        "  interpolation_steps = Slider(min=1, max=100, divisions=99, label=\"{value}\", value=prefs['num_interpolation_steps'], on_change=change_interpolation_steps, expand=True)\n",
        "  interpolation_steps_value = Text(f\" {int(prefs['num_interpolation_steps'])} steps\", weight=FontWeight.BOLD)\n",
        "  interpolation_steps_slider = Container(Row([Text(f\"Number of Interpolation Steps between Prompts: \"), interpolation_steps_value, interpolation_steps]), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "  Row([Text(f\"Number of Interpolation Steps between Prompts: \"), interpolation_steps_value, interpolation_steps])\n",
        "  if not bool(prefs['use_interpolation']):\n",
        "    interpolation_steps_slider.height = 0\n",
        "  page.interpolation_block = Column([use_interpolation, interpolation_steps_slider])\n",
        "  page.img_block = Container(Column([image_pickers, strength_slider, page.use_inpaint_model, centipede_prompts_as_init_images, Divider(height=9, thickness=2)]), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "  if not status['installed_interpolation']:\n",
        "    page.interpolation_block.visible = False\n",
        "  elif bool(prefs['use_interpolation']):\n",
        "    page.img_block.height = 0\n",
        "  page.use_clip_guided_model = Tooltip(message=\"Uses more VRAM, so you'll probably need to make image size smaller\", content=Switch(label=\"Use CLIP-Guided Model\", tooltip=\"Uses more VRAM, so you'll probably need to make image size smaller\", value=prefs['use_clip_guided_model'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_clip))\n",
        "  clip_guidance_scale = Slider(min=1, max=5000, divisions=4999, label=\"{value}\", value=prefs['clip_guidance_scale'], on_change=lambda e:changed(e,'clip_guidance_scale'), expand=True)\n",
        "  clip_guidance_scale_slider = Row([Text(\"CLIP Guidance Scale: \"), clip_guidance_scale])\n",
        "  use_cutouts = Checkbox(label=\"Use Cutouts\", value=bool(prefs['use_cutouts']), fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=change_use_cutouts)\n",
        "  num_cutouts = NumberPicker(label=\"    Number of Cutouts: \", min=1, max=10, value=prefs['num_cutouts'], on_change=lambda e: changed(e, 'num_cutouts', asInt=True))\n",
        "  num_cutouts.visible = bool(prefs['use_cutouts'])\n",
        "  #num_cutouts = TextField(label=\"Number of Cutouts\", value=prefs['num_cutouts'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'num_cutouts', asInt=True))\n",
        "  unfreeze_unet = Checkbox(label=\"Unfreeze UNET\", value=prefs['unfreeze_unet'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'unfreeze_unet'))\n",
        "  unfreeze_vae = Checkbox(label=\"Unfreeze VAE\", value=prefs['unfreeze_vae'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'unfreeze_vae'))\n",
        "  page.clip_block = Container(Column([clip_guidance_scale_slider, Row([use_cutouts, num_cutouts], expand=False), unfreeze_unet, unfreeze_vae, Divider(height=9, thickness=2)]), padding=padding.only(left=32), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "  page.use_conceptualizer_model = Tooltip(message=\"Use Textual-Inversion Community Model Concepts\", content=Switch(label=\"Use Custom Conceptualizer Model\", tooltip=\"Use Textual-Inversion Community Model\", value=prefs['use_conceptualizer'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_conceptualizer))\n",
        "  page.use_conceptualizer_model.visible = bool(status['installed_conceptualizer'])\n",
        "  page.use_depth2img = Tooltip(message=\"To use, provide init_image with a good composition and prompts to approximate same depth.\", content=Switch(label=\"Use Depth2Image Pipeline for img2img init image generation\", value=prefs['use_depth2img'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e,'use_depth2img')))\n",
        "  page.use_depth2img.visible = bool(status['installed_depth2img'])\n",
        "  page.use_imagic = Tooltip(message=\"Allows you to edit an image with prompt text.\", content=Switch(label=\"Use iMagic for img2img init image editing\", value=prefs['use_imagic'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e,'use_imagic')))\n",
        "  page.use_imagic.visible = bool(status['installed_imagic'])\n",
        "  page.use_composable = Tooltip(message=\"Allows conjunction and negation operators for compositional generation with conditional diffusion models\", content=Switch(label=\"Use Composable Prompts for txt2img Weight | Segments\", value=prefs['use_composable'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e,'use_composable')))\n",
        "  page.use_composable.visible = bool(status['installed_composable'])\n",
        "  page.use_safe = Tooltip(message=\"Models trained only on Safe images\", content=Switch(label=\"Use Safe Diffusion Pipeline instead\", value=prefs['use_safe'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e,'use_safe')))\n",
        "  page.use_safe.visible = bool(status['installed_safe'])\n",
        "  page.use_upscale = Tooltip(message=\"Enlarges your Image Generations guided by the same Prompt.\", content=Switch(label=\"Upscale 4X with Stable Diffusion 2\", value=prefs['use_upscale'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=lambda e:changed(e,'use_upscale')))\n",
        "  page.use_upscale.visible = bool(status['installed_upscale'])\n",
        "  apply_ESRGAN_upscale = Switch(label=\"Apply ESRGAN Upscale\", value=prefs['apply_ESRGAN_upscale'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_ESRGAN)\n",
        "  enlarge_scale_value = Text(f\" {float(prefs['enlarge_scale'])}x\", weight=FontWeight.BOLD)\n",
        "  enlarge_scale = Slider(min=1, max=4, divisions=6, label=\"{value}x\", value=prefs['enlarge_scale'], on_change=change_enlarge_scale, expand=True)\n",
        "  enlarge_scale_slider = Row([Text(\"Enlarge Scale: \"), enlarge_scale_value, enlarge_scale])\n",
        "  face_enhance = Checkbox(label=\"Use Face Enhance GPFGAN\", value=prefs['face_enhance'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'face_enhance'))\n",
        "  display_upscaled_image = Checkbox(label=\"Display Upscaled Image\", value=prefs['display_upscaled_image'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'display_upscaled_image'))\n",
        "  ESRGAN_settings = Container(Column([enlarge_scale_slider, face_enhance, display_upscaled_image], spacing=0), padding=padding.only(left=32), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "  page.ESRGAN_block = Container(Column([apply_ESRGAN_upscale, ESRGAN_settings]), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "  page.img_block.height = None if status['installed_txt2img'] or status['installed_stability'] else 0\n",
        "  page.use_clip_guided_model.visible = status['installed_clip']\n",
        "  page.clip_block.height = None if status['installed_clip'] and prefs['use_clip_guided_model'] else 0\n",
        "  page.ESRGAN_block.height = None if status['installed_ESRGAN'] else 0\n",
        "  if not prefs['apply_ESRGAN_upscale']:\n",
        "    ESRGAN_settings.height = 0\n",
        "  parameters_button = ElevatedButton(content=Text(value=\"üìú   Continue to Image Prompts\", size=20), on_click=run_parameters)\n",
        "  #apply_changes_button = ElevatedButton(content=Text(value=\"üîÄ   Apply Changes to Current Prompts\", size=20), on_click=apply_to_prompts)\n",
        "  #apply_changes_button.visible = len(prompts) > 0 and status['changed_parameters']\n",
        "  def show_apply_fab(show = True):\n",
        "    if show:\n",
        "      page.floating_action_button = FloatingActionButton(icon=icons.TRANSFORM, text=\"Apply Changes to Current Prompts\", on_click=apply_to_prompts)\n",
        "      page.update()\n",
        "    else:\n",
        "      if page.floating_action_button is not None:\n",
        "        page.floating_action_button = None\n",
        "        page.update()\n",
        "  show_apply_fab(len(prompts) > 0 and status['changed_parameters'])\n",
        "  page.show_apply_fab = show_apply_fab\n",
        "  parameters_row = Row([parameters_button], alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "  def updater():\n",
        "      #parameters.update()\n",
        "      c.update()\n",
        "      page.update()\n",
        "      #print(\"Updated Parameters Page\")\n",
        "\n",
        "  c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10), content=Column([\n",
        "        Text (\"üìù  Stable Diffusion Image Parameters\", style=TextThemeStyle.TITLE_LARGE),\n",
        "        Divider(thickness=1, height=4),\n",
        "        param_rows, guidance, width_slider, height_slider, #Divider(height=9, thickness=2), \n",
        "        page.interpolation_block, page.use_safe, page.img_block, page.use_clip_guided_model, page.clip_block, page.use_versatile, page.use_conceptualizer_model, page.use_imagic, page.use_depth2img, page.use_composable, page.use_upscale, page.ESRGAN_block,\n",
        "        #(img_block if status['installed_img2img'] or status['installed_stability'] else Container(content=None)), (clip_block if prefs['install_CLIP_guided'] else Container(content=None)), (ESRGAN_block if prefs['install_ESRGAN'] else Container(content=None)), \n",
        "        #parameters_row,\n",
        "      ],\n",
        "  ))], scroll=ScrollMode.AUTO)#batch_folder_name, batch_size, n_iterations, steps, eta, seed, \n",
        "  return c\n",
        "\n",
        "prompts = []\n",
        "args = {}\n",
        "\n",
        "def update_args():\n",
        "    global args\n",
        "    args = {\n",
        "        \"batch_size\":int(prefs['batch_size']),\n",
        "        \"n_iterations\":int(prefs['n_iterations']),\n",
        "        \"steps\":int(prefs['steps']),\n",
        "        \"eta\":float(prefs['eta']), \n",
        "        \"width\":int(prefs['width']),\n",
        "        \"height\":int(prefs['height']),\n",
        "        \"guidance_scale\":float(prefs['guidance_scale']),\n",
        "        \"seed\":int(prefs['seed']),\n",
        "        \"precision\":prefs['precision'],\n",
        "        \"init_image\": prefs['init_image'],\n",
        "        \"init_image_strength\": prefs['init_image_strength'],\n",
        "        \"mask_image\": prefs['mask_image'],\n",
        "        \"alpha_mask\": prefs['alpha_mask'],\n",
        "        \"invert_mask\": prefs['invert_mask'],\n",
        "        \"prompt2\": None, \"tweens\": 10,\n",
        "        \"negative_prompt\": None,\n",
        "        \"use_clip_guided_model\": prefs['use_clip_guided_model'],\n",
        "        \"clip_prompt\": \"\",\n",
        "        \"clip_guidance_scale\": float(prefs['clip_guidance_scale']),\n",
        "        \"use_cutouts\": bool(prefs['use_cutouts']),\n",
        "        \"num_cutouts\": int(prefs['num_cutouts']),\n",
        "        \"unfreeze_unet\": prefs['unfreeze_unet'],\n",
        "        \"unfreeze_vae\": prefs['unfreeze_vae'],\n",
        "        \"use_Stability\": False,\n",
        "        \"use_conceptualizer\": False} \n",
        "\n",
        "update_args()\n",
        "\n",
        "class Dream: \n",
        "    def __init__(self, prompt, **kwargs):\n",
        "        self.prompt = prompt\n",
        "        self.arg = args.copy()\n",
        "        for key, value in kwargs.items():\n",
        "          if key=='arg': self.arg = value\n",
        "          elif key==\"batch_size\": self.arg[key] = int(value)\n",
        "          elif key==\"n_iterations\": self.arg[key] = int(value)\n",
        "          elif key==\"steps\": self.arg[key] = int(value)\n",
        "          elif key==\"eta\": self.arg[key] = float(value)\n",
        "          elif key==\"width\": self.arg[key] = int(value)\n",
        "          elif key==\"height\": self.arg[key] = int(value)\n",
        "          elif key==\"guidance_scale\": self.arg[key] = float(value)\n",
        "          elif key==\"seed\": self.arg[key] = int(value)\n",
        "          elif key==\"precision\": self.arg[key] = value\n",
        "          elif key==\"init_image\": self.arg[key] = value\n",
        "          elif key==\"init_image_strength\": self.arg[key] = value\n",
        "          elif key==\"mask_image\": self.arg[key] = value\n",
        "          elif key==\"alpha_mask\": self.arg[key] = value\n",
        "          elif key==\"invert_mask\": self.arg[key] = value\n",
        "          elif key==\"prompt2\": self.arg[key] = value\n",
        "          elif key==\"tweens\": self.arg[key] = int(value)\n",
        "          elif key==\"negative_prompt\": self.arg[key] = value\n",
        "          elif key==\"clip_prompt\": self.arg[key] = value\n",
        "          elif key==\"use_clip_guided_model\": self.arg[key] = value\n",
        "          elif key==\"clip_guidance_scale\": self.arg[key] = float(value)\n",
        "          elif key==\"use_cutouts\": self.arg[key] = value\n",
        "          elif key==\"num_cutouts\": self.arg[key] = int(value)\n",
        "          elif key==\"unfreeze_unet\": self.arg[key] = value\n",
        "          elif key==\"unfreeze_vae\": self.arg[key] = value\n",
        "          elif key==\"use_Stability\": self.arg[key] = value\n",
        "          elif key==\"use_conceptualizer\": self.arg[key] = value\n",
        "          elif key==\"prompt\": self.prompt = value\n",
        "          else: print(f\"Unknown argument: {key} = {value}\")\n",
        "        #self.arg = arg\n",
        "    #arg = args\n",
        "#print(str(args))\n",
        "import string\n",
        "from collections import ChainMap\n",
        "def format_filename(s):\n",
        "    valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n",
        "    filename = ''.join(c for c in s if c in valid_chars)\n",
        "    if not prefs['file_allowSpace']: filename = filename.replace(' ','_')\n",
        "    return filename[:int(prefs['file_max_length'])]\n",
        "\n",
        "def merge_dict(*dicts):\n",
        "    all_keys  = set(k for d in dicts for k in d.keys())\n",
        "    chain_map = ChainMap(*reversed(dicts))\n",
        "    return {k: chain_map[k] for k in all_keys}\n",
        "import copy\n",
        "\n",
        "def buildPromptsList(page):\n",
        "  parameter = Ref[ListTile]()\n",
        "  global prompts, args, prefs\n",
        "  def changed(e):\n",
        "      status['changed_prompts'] = True\n",
        "      page.update()\n",
        "  \n",
        "  def edit_prompt(e):\n",
        "      idx = prompts.index(e.control.data)\n",
        "      open_dream = e.control.data\n",
        "      def changed_tweening(e):\n",
        "          status['changed_prompts'] = True\n",
        "          tweening_params.height = None if e.control.value else 0\n",
        "          tweening_params.update()\n",
        "          #prompt2.visible = e.control.value\n",
        "          #tweens.visible = e.control.value\n",
        "          prompt_tweening = e.control.value\n",
        "          page.update()\n",
        "      def changed_tweens(e):\n",
        "          prefs['tweens'] = int(e.control.value)\n",
        "      def close_dlg(e):\n",
        "          dlg_modal.open = False\n",
        "          page.update()\n",
        "      def save_dlg(e):\n",
        "          dream = open_dream #e.control.data\n",
        "          dream.prompt = edit_text.value\n",
        "          arg['batch_size'] = int(batch_size.value)\n",
        "          arg['n_iterations'] = int(n_iterations.value)\n",
        "          arg['steps'] = int(steps.value)\n",
        "          arg['eta'] = float(eta.value)\n",
        "          arg['seed'] = int(seed.value)\n",
        "          arg['guidance_scale'] = float(guidance_scale.value)\n",
        "          arg['width'] = int(width.value)\n",
        "          arg['height'] = int(height.value)\n",
        "          arg['init_image'] = init_image.value\n",
        "          arg['mask_image'] = mask_image.value\n",
        "          arg['init_image_strength'] = float(init_image_strength.value)\n",
        "          arg['alpha_mask'] = alpha_mask.value\n",
        "          arg['invert_mask'] = invert_mask.value\n",
        "          arg['prompt2'] = prompt2.value if bool(use_prompt_tweening.value) else None\n",
        "          arg['tweens'] = int(tweens.value)\n",
        "          arg['negative_prompt'] = negative_prompt.value if bool(negative_prompt.value) else None\n",
        "          arg['use_clip_guided_model'] = use_clip_guided_model.content.value\n",
        "          arg['clip_guidance_scale'] = float(clip_guidance_scale.value)\n",
        "          arg['use_cutouts'] = use_cutouts.value\n",
        "          arg['num_cutouts'] = int(num_cutouts.value)\n",
        "          arg['unfreeze_unet'] = unfreeze_unet.value\n",
        "          arg['unfreeze_vae'] = unfreeze_vae.value\n",
        "          dream.arg = arg\n",
        "          diffs = arg_diffs(arg, args)\n",
        "          if bool(diffs):\n",
        "            prompts_list.controls[idx].subtitle = Text(\"    \" + diffs)\n",
        "          else:\n",
        "            prompts_list.controls[idx].subtitle = None\n",
        "          prompts_list.controls[idx].title.value = dream.prompt # = Text(edit_text.value)\n",
        "          status['changed_prompts'] = True\n",
        "          dlg_modal.open = False\n",
        "          page.update()\n",
        "      def file_picker_result(e: FilePickerResultEvent):\n",
        "          if e.files != None:\n",
        "            upload_files(e)\n",
        "      def on_upload_progress(e: FilePickerUploadEvent):\n",
        "        nonlocal pick_type\n",
        "        if e.progress == 1:\n",
        "          fname = os.path.join(root_dir, e.file_name)\n",
        "          if pick_type == \"init\":\n",
        "            init_image.value = fname\n",
        "            init_image.update()\n",
        "            prefs['init_image'] = fname\n",
        "          elif pick_type == \"mask\":\n",
        "            mask_image.value = fname\n",
        "            mask_image.update()\n",
        "            prefs['mask_image'] = fname\n",
        "          page.update()\n",
        "      file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "      def upload_files(e):\n",
        "          uf = []\n",
        "          if file_picker.result != None and file_picker.result.files != None:\n",
        "              for f in file_picker.result.files:\n",
        "                  uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "              file_picker.upload(uf)\n",
        "      page.overlay.append(file_picker)\n",
        "      pick_type = \"\"\n",
        "      #page.overlay.append(pick_files_dialog)\n",
        "      def pick_init(e):\n",
        "          nonlocal pick_type\n",
        "          pick_type = \"init\"\n",
        "          file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Init Image File\")\n",
        "      def pick_mask(e):\n",
        "          nonlocal pick_type\n",
        "          pick_type = \"mask\"\n",
        "          file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Black & White Mask Image\")\n",
        "      def toggle_clip(e):\n",
        "          if e.control.value:\n",
        "            img_block.height = 0\n",
        "            clip_block.height = None if status['installed_clip'] else 0\n",
        "          else:\n",
        "            img_block.height = None if status['installed_txt2img'] or status['installed_stability'] else 0\n",
        "            clip_block.height = 0\n",
        "          img_block.update()\n",
        "          clip_block.update()\n",
        "          changed(e)\n",
        "      arg = open_dream.arg #e.control.data.arg\n",
        "      edit_text = TextField(label=\"Composable | Prompt | Text\" if prefs['use_composable'] and status['installed_composable'] else \"Prompt Text\", expand=3, value=open_dream.prompt, multiline=True)\n",
        "      negative_prompt = TextField(label=\"Segmented Weights 1 | -0.7 | 1.2\" if prefs['use_composable'] and status['installed_composable'] else \"Negative Prompt Text\", expand=1, value=str((arg['negative_prompt'] or '') if 'negative_prompt' in arg else ''), on_change=changed)\n",
        "      #batch_folder_name = TextField(label=\"Batch Folder Name\", value=arg['batch_folder_name'], on_change=changed)\n",
        "      #print(str(arg))\n",
        "      prompt_tweening = bool(arg['prompt2']) if 'prompt2' in arg else False\n",
        "      use_prompt_tweening = Switch(label=\"Prompt Tweening\", value=prompt_tweening, active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=changed_tweening)\n",
        "      prompt2 = TextField(label=\"Prompt 2 Transition Text\", expand=True, value=arg['prompt2'] if 'prompt2' in arg else '', on_change=changed)\n",
        "      tweens = TextField(label=\"# of Tweens\", value=str(arg['tweens'] if 'tweens' in arg else 8), keyboard_type=KeyboardType.NUMBER, on_change=changed, width = 90)\n",
        "      #tweens =  NumberPicker(label=\"# of Tweens: \", min=2, max=300, value=int(arg['tweens'] if 'tweens' in arg else 8), on_change=changed_tweens),\n",
        "      #prompt2.visible = prompt_tweening\n",
        "      #tweens.visible = prompt_tweening\n",
        "      tweening_params = Container(Row([Container(content=None, width=8), prompt2, tweens]), padding=padding.only(top=4, bottom=3), animate_size=animation.Animation(1000, AnimationCurve.EASE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "      tweening_params.height = None if prompt_tweening else 0\n",
        "      tweening_row = Row([use_prompt_tweening, ])#tweening_params\n",
        "\n",
        "      batch_size = TextField(label=\"Batch Size\", value=str(arg['batch_size']), keyboard_type=KeyboardType.NUMBER, on_change=changed)\n",
        "      n_iterations = TextField(label=\"Number of Iterations\", value=str(arg['n_iterations']), keyboard_type=KeyboardType.NUMBER, on_change=changed)\n",
        "      steps = TextField(label=\"Steps\", value=str(arg['steps']), keyboard_type=KeyboardType.NUMBER, on_change=changed)\n",
        "      eta = TextField(label=\"DDIM ETA\", value=str(arg['eta']), keyboard_type=KeyboardType.NUMBER, hint_text=\"Amount of Noise (only with DDIM sampler)\", on_change=changed)\n",
        "      seed = TextField(label=\"Seed\", value=str(arg['seed']), keyboard_type=KeyboardType.NUMBER, hint_text=\"0 or -1 picks a Random seed\", on_change=changed)\n",
        "      guidance_scale = TextField(label=\"Guidance Scale\", value=str(arg['guidance_scale']), keyboard_type=KeyboardType.NUMBER, on_change=changed)\n",
        "      param_columns = Row([Column([batch_size, n_iterations, steps]), Column([guidance_scale, seed, eta])])\n",
        "      #guidance_scale = Slider(min=0, max=50, divisions=100, label=\"{value}\", value=arg['guidance_scale'], expand=True)\n",
        "      #guidance = Row([Text(\"Guidance Scale: \"), guidance_scale])\n",
        "      width = Slider(min=256, max=1280, divisions=64, label=\"{value}px\", value=float(arg['width']), expand=True)\n",
        "      width_slider = Row([Text(\"Width: \"), width])\n",
        "      height = Slider(min=256, max=1280, divisions=64, label=\"{value}px\", value=float(arg['height']), expand=True)\n",
        "      height_slider = Row([Text(\"Height: \"), height])\n",
        "      init_image = TextField(label=\"Init Image\", value=arg['init_image'], expand=1, on_change=changed, height=60, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_init))\n",
        "      mask_image = TextField(label=\"Mask Image\", value=arg['mask_image'], expand=1, on_change=changed, height=60, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD_OUTLINED, on_click=pick_mask))\n",
        "      alpha_mask = Checkbox(label=\"Alpha Mask\", value=arg['alpha_mask'], tooltip=\"Use Transparent Alpha Channel of Init as Mask\", fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=changed)\n",
        "      invert_mask = Checkbox(label=\"Invert Mask\", value=arg['invert_mask'], tooltip=\"Reverse Black & White of Image Mask\", fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=changed)\n",
        "      image_row = ResponsiveRow([Row([init_image, alpha_mask], col={\"lg\":6}), Row([mask_image, invert_mask], col={\"lg\":6})])\n",
        "      init_image_strength = Slider(min=0.1, max=0.9, divisions=16, label=\"{value}%\", value=float(arg['init_image_strength']), expand=True)\n",
        "      strength_slider = Row([Text(\"Init Image Strength: \"), init_image_strength])\n",
        "      img_block = Container(content=Column([image_row, strength_slider]), padding=padding.only(top=4, bottom=3), animate_size=animation.Animation(1000, AnimationCurve.EASE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "      img_block.height = None if (status['installed_txt2img'] or status['installed_stability']) else 0\n",
        "      use_clip_guided_model = Tooltip(message=\"Uses more VRAM, so you'll probably need to make image size smaller\", content=Switch(label=\"Use CLIP-Guided Model\", tooltip=\"Uses more VRAM, so you'll probably need to make image size smaller\", value=arg['use_clip_guided_model'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_clip))\n",
        "      clip_guidance_scale = Slider(min=1, max=5000, divisions=4999, label=\"{value}\", value=arg['clip_guidance_scale'], on_change=changed, expand=True)\n",
        "      clip_guidance_scale_slider = Row([Text(\"CLIP Guidance Scale: \"), clip_guidance_scale])\n",
        "      use_cutouts = Checkbox(label=\"Use Cutouts\", value=bool(arg['use_cutouts']), fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=changed)\n",
        "      num_cutouts = NumberPicker(label=\"    Number of Cutouts: \", min=1, max=10, value=arg['num_cutouts'], on_change=changed)\n",
        "      #num_cutouts.visible = bool(prefs['use_cutouts'])\n",
        "      #num_cutouts = TextField(label=\"Number of Cutouts\", value=prefs['num_cutouts'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'num_cutouts', asInt=True))\n",
        "      unfreeze_unet = Checkbox(label=\"Unfreeze UNET\", value=arg['unfreeze_unet'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=changed)\n",
        "      unfreeze_vae = Checkbox(label=\"Unfreeze VAE\", value=arg['unfreeze_vae'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=changed)\n",
        "      clip_block = Container(Column([clip_guidance_scale_slider, Row([use_cutouts, num_cutouts], expand=False), unfreeze_unet, unfreeze_vae, Divider(height=9, thickness=2)]), padding=padding.only(left=32), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "      if not status['installed_clip']:\n",
        "        use_clip_guided_model.visible = False\n",
        "        clip_block.height = 0\n",
        "      elif not arg['use_clip_guided_model']:\n",
        "        clip_block.height = 0\n",
        "      dlg_modal = AlertDialog(modal=False, title=Text(\"üìù  Edit Prompt Dream Parameters\"), content=Container(Column([\n",
        "            Container(content=None, height=7),\n",
        "            Row([\n",
        "              edit_text,\n",
        "              negative_prompt,\n",
        "            ]),\n",
        "            #Text(\"Override any Default Parameters\"),\n",
        "            tweening_row,\n",
        "            tweening_params,\n",
        "            #batch_size, n_iterations, steps, eta, seed, guidance, \n",
        "            param_columns, \n",
        "            width_slider, height_slider, img_block,\n",
        "            use_clip_guided_model, clip_block,\n",
        "            #Row([Column([batch_size, n_iterations, steps, eta, seed,]), Column([guidance, width_slider, height_slider, Divider(height=9, thickness=2), (img_block if prefs['install_img2img'] else Container(content=None))])],),\n",
        "          ], alignment=MainAxisAlignment.START, tight=True, width=page.width - 200, height=page.height - 100, scroll=ScrollMode.AUTO), width=page.width - 200, height=page.height - 100), actions=[TextButton(\"Cancel\", on_click=close_dlg), ElevatedButton(content=Text(value=emojize(\":floppy_disk:\") + \"  Save Prompt \", size=19, weight=FontWeight.BOLD), on_click=save_dlg)], actions_alignment=MainAxisAlignment.END)\n",
        "      e.page.dialog = dlg_modal\n",
        "      dlg_modal.open = True\n",
        "      e.page.update()\n",
        "  def prompt_help(e):\n",
        "      def close_help_dlg(e):\n",
        "        nonlocal prompt_help_dlg\n",
        "        prompt_help_dlg.open = False\n",
        "        page.update()\n",
        "      prompt_help_dlg = AlertDialog(title=Text(\"üíÅ   Help with Prompt Creations\"), content=Column([\n",
        "          Text(\"You can keep your text prompts simple, or get really complex with it. Just describe the image you want it to dream up with as many details as you can think of. Add artists, styles, colors, adjectives and get creative...\"),\n",
        "          Text('Now you can add prompt weighting, so you can emphasize the strength of certain words between parentheses, and de-emphasize words between brackets. For example: \"A (hyper realistic) painting of (magical:1.8) owl with the face of a cat, without [tail], in a [twisted:0.6] tree, by Thomas Kinkade\"'),\n",
        "          Text('After adding your prompts, click on a prompt line to edit all the parameters of it. There you can add negative prompts like \"lowres, bad_anatomy, error_body, bad_fingers, missing_fingers, error_lighting, jpeg_artifacts, signature, watermark, username, blurry\" or anything else you don\\'t want'),\n",
        "          Text('Then you can override all the parameters for each individual prompt, playing with variations of sizes, steps, guidance scale, init & mask image, seeds, etc.  In the prompts list, you can press the ... options button to duplicate, delete and move prompts in the batch queue.  When ready, Run Diffusion on Prompts...')\n",
        "        ], scroll=ScrollMode.AUTO), actions=[TextButton(\"üòÄ  Very nice... \", on_click=close_help_dlg)], actions_alignment=MainAxisAlignment.END)\n",
        "      page.dialog = prompt_help_dlg\n",
        "      prompt_help_dlg.open = True\n",
        "      page.update()\n",
        "  def paste_prompts(e):\n",
        "      def save_prompts_list(e):\n",
        "        plist = enter_text.value.strip()\n",
        "        prompts_list = plist.split('\\n')\n",
        "        for pr in prompts_list:\n",
        "          if bool(pr.strip()):\n",
        "            add_to_prompts(pr.strip())\n",
        "        close_dlg(e)\n",
        "      def close_dlg(e):\n",
        "          dlg_paste.open = False\n",
        "          page.update()\n",
        "      enter_text = TextField(label=\"Enter Prompts List with multiple lines\", expand=True, multiline=True)\n",
        "      dlg_paste = AlertDialog(modal=False, title=Text(\"üìù  Paste or Write Prompts List from Simple Text\"), content=Container(Column([enter_text], alignment=MainAxisAlignment.START, tight=True, width=page.width - 180, height=page.height - 100, scroll=\"none\"), width=page.width - 180, height=page.height - 100), actions=[TextButton(\"Cancel\", on_click=close_dlg), ElevatedButton(content=Text(value=emojize(\":floppy_disk:\") + \"  Save to Prompts List \", size=19, weight=FontWeight.BOLD), on_click=save_prompts_list)], actions_alignment=MainAxisAlignment.END)\n",
        "      page.dialog = dlg_paste\n",
        "      dlg_paste.open = True\n",
        "      page.update()\n",
        "  def delete_prompt(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      idx = prompts.index(e.control.data)\n",
        "      prompts.pop(idx)\n",
        "      prompts_list.controls.pop(idx)\n",
        "      prompts_list.update()\n",
        "      status['changed_prompts'] = True\n",
        "  def duplicate_prompt(e):\n",
        "      #print(\"Duplicate \" + str(e.control))\n",
        "      open_dream = e.control.data\n",
        "      add_to_prompts(open_dream.prompt, open_dream.arg)\n",
        "      '''idx = prompts.index(e.control.data)\n",
        "      new_dream = copy.copy(e.control.data)\n",
        "      prompts.insert(idx, new_dream)\n",
        "      diffs = arg_diffs(e.control.data.arg, args)\n",
        "      subtitle = None\n",
        "      if bool(diffs): subtitle = Text(\"    \" + diffs)\n",
        "      prompts_list.controls.insert(idx, ListTile(title=Text(new_dream.prompt, max_lines=3, style=TextThemeStyle.BODY_LARGE), dense=True, data=new_dream, subtitle=subtitle, on_click=edit_prompt, trailing=PopupMenuButton(icon=icons.MORE_VERT,\n",
        "          items=[\n",
        "              PopupMenuItem(icon=icons.EDIT, text=\"Edit Prompt\", on_click=edit_prompt, data=new_dream),\n",
        "              PopupMenuItem(icon=icons.DELETE, text=\"Delete Prompt\", on_click=delete_prompt, data=new_dream),\n",
        "              PopupMenuItem(icon=icons.CONTROL_POINT_DUPLICATE, text=\"Duplicate Prompt\", on_click=duplicate_prompt, data=new_dream),\n",
        "              PopupMenuItem(icon=icons.CONTROL_POINT_DUPLICATE, text=\"Duplicate Multiple\", on_click=duplicate_multiple, data=new_dream),\n",
        "              PopupMenuItem(icon=icons.ARROW_UPWARD, text=\"Move Up\", on_click=move_up, data=new_dream),\n",
        "              PopupMenuItem(icon=icons.ARROW_DOWNWARD, text=\"Move Down\", on_click=move_down, data=new_dream),\n",
        "          ],\n",
        "      )))\n",
        "      prompts_list.update()\n",
        "      status['changed_prompts'] = True'''\n",
        "  def duplicate_multiple(e):\n",
        "      open_dream = e.control.data\n",
        "      num_times = 2\n",
        "      def close_dlg(e):\n",
        "          duplicate_modal.open = False\n",
        "          page.update()\n",
        "      def save_dlg(e):\n",
        "          for i in range(num_times):\n",
        "            add_to_prompts(open_dream.prompt, open_dream.arg)\n",
        "          duplicate_modal.open = False\n",
        "          page.update()\n",
        "      def change_num(e):\n",
        "          nonlocal num_times\n",
        "          num_times = int(e.control.value)\n",
        "      duplicate_modal = AlertDialog(modal=False, title=Text(\"üåÄ  Duplicate Prompt Multiple Times\"), content=Container(Column([\n",
        "            Container(content=None, height=7),\n",
        "            NumberPicker(label=\"Number of Copies: \", min=1, max=99, value=num_times, on_change=change_num),\n",
        "          ], alignment=MainAxisAlignment.START, tight=True, scroll=ScrollMode.AUTO)), actions=[TextButton(\"Cancel\", on_click=close_dlg), ElevatedButton(content=Text(value=emojize(\":bowling:\") + \"  Duplicate Prompt \", size=19, weight=FontWeight.BOLD), on_click=save_dlg)], actions_alignment=MainAxisAlignment.END)\n",
        "      e.page.dialog = duplicate_modal\n",
        "      duplicate_modal.open = True\n",
        "      e.page.update()\n",
        "  def move_down(e):\n",
        "      idx = prompts.index(e.control.data)\n",
        "      if idx < (len(prompts) - 1):\n",
        "        d = prompts.pop(idx)\n",
        "        prompts.insert(idx+1, d)\n",
        "        dr = prompts_list.controls.pop(idx)\n",
        "        prompts_list.controls.insert(idx+1, dr)\n",
        "        prompts_list.update()\n",
        "  def move_up(e):\n",
        "      idx = prompts.index(e.control.data)\n",
        "      if idx > 0:\n",
        "        d = prompts.pop(idx)\n",
        "        prompts.insert(idx-1, d)\n",
        "        dr = prompts_list.controls.pop(idx)\n",
        "        prompts_list.controls.insert(idx-1, dr)\n",
        "        prompts_list.update()\n",
        "  def add_prompt(e):\n",
        "      positive_prompt = prompt_text.value\n",
        "      negative_prompt = negative_prompt_text.value\n",
        "      if '_' in positive_prompt:\n",
        "        positive_prompt = nsp_parse(positive_prompt)\n",
        "      if bool(negative_prompt):\n",
        "        if '_' in negative_prompt:\n",
        "          negative_prompt = nsp_parse(negative_prompt)\n",
        "        add_to_prompts(positive_prompt, {'negative_prompt': negative_prompt})\n",
        "      else:\n",
        "        add_to_prompts(positive_prompt)\n",
        "  def add_to_prompts(p, arg=None):\n",
        "      global prompts\n",
        "      dream = Dream(p)\n",
        "      if arg is not None:\n",
        "        if 'prompt' in arg: del arg['prompt']\n",
        "        arg = merge_dict(args, arg)\n",
        "        dream.arg = arg\n",
        "      prompts.append(dream)\n",
        "      prompts_list.controls.append(ListTile(title=Text(p, max_lines=3, style=TextThemeStyle.BODY_LARGE), dense=True, data=dream, on_click=edit_prompt, trailing=PopupMenuButton(icon=icons.MORE_VERT,\n",
        "          items=[\n",
        "              PopupMenuItem(icon=icons.EDIT, text=\"Edit Prompt\", on_click=edit_prompt, data=dream),\n",
        "              PopupMenuItem(icon=icons.DELETE, text=\"Delete Prompt\", on_click=delete_prompt, data=dream),\n",
        "              PopupMenuItem(icon=icons.CONTROL_POINT_DUPLICATE, text=\"Duplicate Prompt\", on_click=duplicate_prompt, data=dream),\n",
        "              PopupMenuItem(icon=icons.CONTROL_POINT_DUPLICATE_SHARP, text=\"Duplicate Multiple\", on_click=duplicate_multiple, data=dream),\n",
        "              PopupMenuItem(icon=icons.ARROW_UPWARD, text=\"Move Up\", on_click=move_up, data=dream),\n",
        "              PopupMenuItem(icon=icons.ARROW_DOWNWARD, text=\"Move Down\", on_click=move_down, data=dream),\n",
        "          ],\n",
        "      )))\n",
        "      #prompts_list.controls.append(Text(\"Prompt 1 added to the list of prompts\"))\n",
        "      prompts_list.update()\n",
        "      if prompts_buttons.visible==False:\n",
        "          prompts_buttons.visible=True\n",
        "          prompts_buttons.update()\n",
        "          if current_tab == 3:\n",
        "            show_run_diffusion_fab(True)\n",
        "      if arg is not None:\n",
        "        update_prompts()\n",
        "      else:\n",
        "        prompt_text.focus()\n",
        "      page.update()\n",
        "      status['changed_prompts'] = True\n",
        "  page.add_to_prompts = add_to_prompts\n",
        "\n",
        "  def save_prompts():\n",
        "      if len(prompts) > 0:\n",
        "          #print(\"Saving your Prompts List\")\n",
        "          prompts_prefs = []\n",
        "          for d in prompts:\n",
        "            a = d.arg.copy()\n",
        "            a['prompt'] = d.prompt\n",
        "            if 'batch_size' in a: del a['batch_size']\n",
        "            if 'n_iterations' in a: del a['n_iterations']\n",
        "            if 'precision' in a: del a['precision']\n",
        "            #a['prompt'] = pr[0] if type(pr) == list else pr\n",
        "            a['sampler'] = prefs['generation_sampler'] if prefs['use_Stability_api'] else prefs['scheduler_mode']\n",
        "            if prefs['use_Stability_api']: del a['eta']\n",
        "            if 'use_Stability' in a: del a['use_Stability']\n",
        "            if 'negative_prompt' in a:\n",
        "              if not bool(a['negative_prompt']): del a['negative_prompt']\n",
        "            if 'prompt2' in a:\n",
        "              if not bool(a['prompt2']):\n",
        "                del a['prompt2']\n",
        "                del a['tweens']\n",
        "            if 'init_image' in a:\n",
        "              if not bool(a['init_image']):\n",
        "                del a['init_image']\n",
        "                del a['init_image_strength']\n",
        "                del a['invert_mask']\n",
        "              elif bool(a['mask_image']):\n",
        "                del a['alpha_mask']\n",
        "            if 'mask_image' in a:\n",
        "              if not bool(a['mask_image']):\n",
        "                del a['mask_image']\n",
        "            if 'use_clip_guided_model' in a:\n",
        "              if not bool(a['use_clip_guided_model']):\n",
        "                del a[\"use_clip_guided_model\"]\n",
        "                del a[\"clip_prompt\"]\n",
        "                del a[\"clip_guidance_scale\"]\n",
        "                del a[\"num_cutouts\"]\n",
        "                del a[\"use_cutouts\"]\n",
        "                del a[\"unfreeze_unet\"]\n",
        "                del a[\"unfreeze_vae\"]\n",
        "              else:\n",
        "                a[\"clip_model_id\"] = prefs['clip_model_id']\n",
        "            if 'use_conceptualizer' in a:\n",
        "              if not bool(a['use_conceptualizer']):\n",
        "                del a['use_conceptualizer']\n",
        "            prompts_prefs.append(a)\n",
        "            #j = json.dumps(a)\n",
        "          prefs['prompt_list'] = prompts_prefs\n",
        "  page.save_prompts = save_prompts\n",
        "  def load_prompts():\n",
        "      saved_prompts = prefs['prompt_list']\n",
        "      if len(saved_prompts) > 1:\n",
        "          for d in saved_prompts:\n",
        "            #print(f'Loading {d}')\n",
        "            if 'prompt' not in d: continue\n",
        "            #dream = Dream(d['prompt'])\n",
        "            p = d['prompt']\n",
        "            #del d['prompt']\n",
        "            page.add_to_prompts(p, d)\n",
        "            #dream.arg = d\n",
        "            #prompts.append(dream)\n",
        "            #prompts_list.controls.append(ListTile(title=Text(dream.prompt, max_lines=3, style=TextThemeStyle.BODY_LARGE), dense=True, data=dream, on_click=edit_prompt, trailing=PopupMenuButton(icon=icons.MORE_VERT,\n",
        "            #  items=[\n",
        "            #      PopupMenuItem(icon=icons.EDIT, text=\"Edit Prompt\", on_click=edit_prompt, data=dream),\n",
        "            #      PopupMenuItem(icon=icons.DELETE, text=\"Delete Prompt\", on_click=delete_prompt, data=dream),\n",
        "            #      PopupMenuItem(icon=icons.CONTROL_POINT_DUPLICATE, text=\"Duplicate Prompt\", on_click=duplicate_prompt, data=dream),\n",
        "            #  ],\n",
        "            #)))\n",
        "          #prompts_list.update()\n",
        "          #prompts_buttons.visible=True\n",
        "          #prompts_buttons.update()\n",
        "          #update_prompts()\n",
        "          page.update()\n",
        "\n",
        "  page.load_prompts = load_prompts\n",
        "\n",
        "  def update_prompts():\n",
        "      #print(\"Update prompts\")\n",
        "      if len(prompts_list.controls) > 0:\n",
        "        for p in prompts_list.controls:\n",
        "          diffs = arg_diffs(p.data.arg, args)\n",
        "          if bool(diffs):\n",
        "            subtitle = Text(\"    \" + diffs)\n",
        "          else: subtitle = None\n",
        "          p.subtitle = subtitle\n",
        "          p.update()\n",
        "        prompts_list.update()\n",
        "  page.update_prompts = update_prompts\n",
        "  def apply_changes(e):\n",
        "      global prompts\n",
        "      if len(prompts_list.controls) > 0:\n",
        "        i = 0\n",
        "        for p in prompts_list.controls:\n",
        "          prompts[i].arg = merge_dict(prompts[i].arg, args)\n",
        "          p.data = prompts[i]\n",
        "          i += 1\n",
        "        update_prompts()\n",
        "\n",
        "  page.apply_changes = apply_changes\n",
        "  def clear_prompt(e):\n",
        "      prompt_text.value = \"\"\n",
        "      prompt_text.update()\n",
        "  def clear_negative_prompt(e):\n",
        "      negative_prompt_text.value = \"\"\n",
        "      negative_prompt_text.update()\n",
        "  def clear_list(e):\n",
        "      global prompts\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      prompts_list.controls = []\n",
        "      prompts_list.update()\n",
        "      prompts = []\n",
        "      prefs['prompt_list'] = []\n",
        "      prompts_buttons.visible=False\n",
        "      prompts_buttons.update()\n",
        "      show_run_diffusion_fab(False)\n",
        "      e.page.save_prompts()\n",
        "      save_settings_file(e.page)\n",
        "      #status['changed_prompts'] = True\n",
        "  def on_keyboard (e: KeyboardEvent):\n",
        "      if e.key == \"Escape\":\n",
        "        if current_tab == 3:\n",
        "          clear_prompt(None)\n",
        "  page.on_keyboard_event = on_keyboard\n",
        "  def run_diffusion(e):\n",
        "      if not status['installed_diffusers'] and not status['installed_stability']:\n",
        "        alert_msg(e.page, \"You must Install the required Diffusers or Stability api first...\")\n",
        "        return\n",
        "      if prefs['use_interpolation'] and prefs['install_interpolation'] and not status['installed_interpolation']:\n",
        "        alert_msg(e.page, \"You must Install Walk Interpolation Pipeline first...\")\n",
        "        return\n",
        "      page.tabs.selected_index = 4\n",
        "      page.tabs.update()\n",
        "      page.show_run_diffusion_fab(False)\n",
        "      if status['changed_prompts']:\n",
        "        page.save_prompts()\n",
        "        save_settings_file(page)\n",
        "        status['changed_prompts'] = False\n",
        "      page.update()\n",
        "      start_diffusion(page)\n",
        "  has_changed = False\n",
        "  prompts_list = Column([],spacing=1)\n",
        "  prompt_text = TextField(label=\"Prompt Text\", suffix=IconButton(icons.CLEAR, on_click=clear_prompt), autofocus=True, on_submit=add_prompt, col={'lg':9})\n",
        "  negative_prompt_text = TextField(label=\"Segmented Weights 1 | -0.7 | 1.2\" if prefs['use_composable'] and status['installed_composable'] else \"Negative Prompt Text\", suffix=IconButton(icons.CLEAR, on_click=clear_negative_prompt), col={'lg':3})\n",
        "  add_prompt_button = ElevatedButton(content=Text(value=\"‚ûï  Add\" + (\" Prompt\" if page.width > 720 else \"\"), size=17, weight=FontWeight.BOLD), on_click=add_prompt)\n",
        "  prompt_help_button = IconButton(icons.HELP_OUTLINE, tooltip=\"Help with Prompt Creation\", on_click=prompt_help)\n",
        "  paste_prompts_button = IconButton(icons.CONTENT_PASTE, tooltip=\"Create Prompts from Plain-Text List\", on_click=paste_prompts)\n",
        "  prompt_row = Row([ResponsiveRow([prompt_text, negative_prompt_text], expand=True), add_prompt_button])\n",
        "  #diffuse_prompts_button = ElevatedButton(content=Text(value=\"‚ñ∂Ô∏è    Run Diffusion on Prompts \", size=20), on_click=run_diffusion)\n",
        "  clear_prompts_button = ElevatedButton(\"‚ùå   Clear Prompts List\", on_click=clear_list)\n",
        "  prompts_buttons = Row([clear_prompts_button], alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "  def show_run_diffusion_fab(show = True):\n",
        "    if show:\n",
        "      page.floating_action_button = FloatingActionButton(icon=icons.PLAY_ARROW, text=\"Run Diffusion on Prompts\", on_click=run_diffusion)\n",
        "      page.update()\n",
        "    else:\n",
        "      if page.floating_action_button is not None:\n",
        "        page.floating_action_button = None\n",
        "        page.update()\n",
        "  page.show_run_diffusion_fab = show_run_diffusion_fab\n",
        "  show_run_diffusion_fab(len(prompts_list.controls) > 0)\n",
        "  #page.load_prompts()\n",
        "  if len(prompts_list.controls) < 1:\n",
        "    prompts_buttons.visible=False\n",
        "  c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10), content=Column([\n",
        "        Row([Text(\"üóíÔ∏è   List of Prompts to Diffuse\", style=TextThemeStyle.TITLE_LARGE), Row([prompt_help_button, paste_prompts_button])], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Divider(thickness=1, height=4),\n",
        "        #add_prompt_button,\n",
        "        prompt_row,\n",
        "        prompts_list,\n",
        "        prompts_buttons,\n",
        "      ],\n",
        "  ))], scroll=ScrollMode.AUTO)\n",
        "  return c\n",
        "\n",
        "def buildImages(page):\n",
        "    auto_scroll = True\n",
        "    def auto_scrolling(auto):\n",
        "      page.imageColumn.auto_scroll = auto\n",
        "      page.imageColumn.update()\n",
        "      c.update()\n",
        "    page.auto_scrolling = auto_scrolling\n",
        "    page.imageColumn = Column([Text(\"‚ñ∂Ô∏è   Get ready to make your images, run from Prompts List\", style=TextThemeStyle.TITLE_LARGE), Divider(thickness=1, height=4)], scroll=ScrollMode.AUTO, auto_scroll=True)\n",
        "    c = Container(padding=padding.only(18, 12, 0, 0), content=page.imageColumn)\n",
        "    return c\n",
        "\n",
        "def buildPromptHelpers(page):\n",
        "    def changed(e, pref=None):\n",
        "      if pref is not None:\n",
        "        prefs[pref] = e.control.value\n",
        "      status['changed_prompt_helpers'] = True\n",
        "    page.generator = buildPromptGenerator(page)\n",
        "    page.remixer = buildPromptRemixer(page)\n",
        "    page.brainstormer = buildPromptBrainstormer(page)\n",
        "    page.writer = buildPromptWriter(page)\n",
        "    promptTabs = Tabs(\n",
        "        selected_index=0,\n",
        "        animation_duration=300,\n",
        "        tabs=[\n",
        "            Tab(text=\"Prompt Writer\", content=page.writer, icon=icons.CLOUD_CIRCLE),\n",
        "            Tab(text=\"Prompt Generator\", content=page.generator, icon=icons.CLOUD),\n",
        "            Tab(text=\"Prompt Remixer\", content=page.remixer, icon=icons.CLOUD_SYNC_ROUNDED),\n",
        "            Tab(text=\"Prompt Brainstormer\", content=page.brainstormer, icon=icons.CLOUDY_SNOWING),\n",
        "        ],\n",
        "        expand=1,\n",
        "        #on_change=tab_on_change\n",
        "    )\n",
        "    return promptTabs\n",
        "\n",
        "def buildPromptGenerator(page):\n",
        "    def changed(e, pref=None):\n",
        "      if pref is not None:\n",
        "        prefs['prompt_generator'][pref] = e.control.value\n",
        "      status['changed_prompt_generator'] = True\n",
        "    page.prompt_generator_list = Column([], spacing=0)\n",
        "    def add_to_prompt_list(p):\n",
        "      page.add_to_prompts(p)\n",
        "      if prefs['enable_sounds']: page.snd_drop.play()\n",
        "    def add_to_prompt_generator(p):\n",
        "      page.prompt_generator_list.controls.append(ListTile(title=Text(p, max_lines=3, style=TextThemeStyle.BODY_LARGE), dense=True, on_click=lambda _: add_to_prompt_list(p)))\n",
        "      page.prompt_generator_list.update()\n",
        "      generator_list_buttons.visible = True\n",
        "      generator_list_buttons.update()\n",
        "    page.add_to_prompt_generator = add_to_prompt_generator\n",
        "    def click_prompt_generator(e):\n",
        "      if status['installed_OpenAI']:\n",
        "        run_prompt_generator(page)\n",
        "      else:\n",
        "        alert_msg(page, \"You must Install OpenAI GPT-3 Library first before using...\")\n",
        "    def add_to_list(e):\n",
        "      if prefs['enable_sounds']: page.snd_drop.play()\n",
        "      for p in page.prompt_generator_list.controls:\n",
        "        page.add_to_prompts(p.title.value)\n",
        "    def clear_prompts(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      page.prompt_generator_list.controls = []\n",
        "      page.prompt_generator_list.update()\n",
        "      prompts = []\n",
        "      generator_list_buttons.visible = False\n",
        "      generator_list_buttons.update()\n",
        "    def changed_request(e):\n",
        "      request_slider.label = generator_request_modes[int(request_slider.value)]\n",
        "      request_slider.update()\n",
        "      changed(e, 'request_mode')\n",
        "    request_slider = Slider(label=\"{value}\", min=0, max=7, divisions=7, expand=True, value=prefs['prompt_generator']['request_mode'], on_change=changed_request)\n",
        "    generator_list_buttons = Row([ElevatedButton(content=Text(\"‚ûï  Add All Prompts to List\", size=18), on_click=add_to_list),\n",
        "        ElevatedButton(content=Text(\"‚ùå   Clear Prompts\"), on_click=clear_prompts),\n",
        "    ], alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "    if len(page.prompt_generator_list.controls) < 1:\n",
        "      generator_list_buttons.visible = False\n",
        "      #generator_list_buttons.update()\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Text(\"üß†  OpenAI Prompt Genenerator\", style=TextThemeStyle.TITLE_LARGE),\n",
        "        Text(\"Enter a phrase each prompt should start with and the amount of prompts to generate. 'Subject Details' is optional to influence the output. 'Phase as subject' makes it about phrase and subject detail. 'Request mode' is the way it asks for the visual description. Just experiment, AI will continue to surprise.\", style=\"titleSmall\"),\n",
        "        Divider(thickness=1, height=5),\n",
        "        Row([TextField(label=\"Subject Phrase\", expand=True, value=prefs['prompt_generator']['phrase'], on_change=lambda e: changed(e, 'phrase')), TextField(label=\"Subject Detail\", expand=True, hint_text=\"Optional about detail\", value=prefs['prompt_generator']['subject_detail'], on_change=lambda e: changed(e, 'subject_detail')), Checkbox(label=\"Phrase as Subject\", value=prefs['prompt_generator']['phrase_as_subject'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e: changed(e, 'phrase_as_subject'))]),\n",
        "        ResponsiveRow([\n",
        "          Row([NumberPicker(label=\"Amount: \", min=1, max=20, value=prefs['prompt_generator']['amount'], on_change=lambda e: changed(e, 'amount')),\n",
        "              NumberPicker(label=\"Random Artists: \", min=0, max=10, value=prefs['prompt_generator']['random_artists'], on_change=lambda e: changed(e, 'random_artists')),], col={'lg':6}, alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "          Row([NumberPicker(label=\"Random Styles: \", min=0, max=10, value=prefs['prompt_generator']['random_styles'], on_change=lambda e: changed(e, 'random_styles')),\n",
        "              Checkbox(label=\"Permutate Artists\", value=prefs['prompt_generator']['permutate_artists'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e: changed(e, 'permutate_artists'))], col={'lg':6}, alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        ]),\n",
        "        ResponsiveRow([\n",
        "          Row([Text(\"Request Mode:\"), request_slider,], col={'lg':6}),\n",
        "          Row([Text(\" AI Temperature:\"), Slider(label=\"{value}\", min=0, max=1, divisions=10, expand=True, value=prefs['prompt_generator']['AI_temperature'], on_change=lambda e: changed(e, 'AI_temperature'))], col={'lg':6}),\n",
        "        ]),\n",
        "        ElevatedButton(content=Text(\"üí≠   Generate Prompts\", size=18), on_click=click_prompt_generator),\n",
        "        page.prompt_generator_list,\n",
        "        generator_list_buttons,\n",
        "      ],\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "def buildPromptRemixer(page):\n",
        "    def changed(e, pref=None):\n",
        "      if pref is not None:\n",
        "        prefs['prompt_remixer'][pref] = e.control.value\n",
        "      status['changed_prompt_remixer'] = True\n",
        "    page.prompt_remixer_list = Column([], spacing=0)\n",
        "    def click_prompt_remixer(e):\n",
        "      if status['installed_OpenAI']:\n",
        "        run_prompt_remixer(page)\n",
        "      else:\n",
        "        alert_msg(page, \"You must Install OpenAI GPT-3 Library first before using...\")\n",
        "    def add_to_prompt_list(p):\n",
        "      page.add_to_prompts(p)\n",
        "      if prefs['enable_sounds']: page.snd_drop.play()\n",
        "    def add_to_prompt_remixer(p):\n",
        "      page.prompt_remixer_list.controls.append(ListTile(title=Text(p, max_lines=3, style=TextThemeStyle.BODY_LARGE), dense=True, on_click=lambda _: add_to_prompt_list(p)))\n",
        "      page.prompt_remixer_list.update()\n",
        "      remixer_list_buttons.visible = True\n",
        "      remixer_list_buttons.update()\n",
        "    page.add_to_prompt_remixer = add_to_prompt_remixer\n",
        "    def add_to_list(e):\n",
        "      if prefs['enable_sounds']: page.snd_drop.play()\n",
        "      for p in page.prompt_remixer_list.controls:\n",
        "        page.add_to_prompts(p.title.value)\n",
        "    def clear_prompts(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      page.prompt_remixer_list.controls = []\n",
        "      page.prompt_remixer_list.update()\n",
        "      remixer_list_buttons.visible = False\n",
        "      remixer_list_buttons.update()\n",
        "    def changed_request(e):\n",
        "      request_slider.label = remixer_request_modes[int(request_slider.value)]\n",
        "      request_slider.update()\n",
        "      changed(e, 'request_mode')\n",
        "    request_slider = Slider(label=\"{value}\", min=0, max=8, divisions=8, expand=True, value=prefs['prompt_remixer']['request_mode'], on_change=changed_request)\n",
        "    remixer_list_buttons = Row([ElevatedButton(content=Text(\"Add All Prompts to List\", size=18), on_click=add_to_list),\n",
        "        ElevatedButton(content=Text(\"‚ùå   Clear Prompts\"), on_click=clear_prompts),\n",
        "    ], alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "    if len(page.prompt_remixer_list.controls) < 1:\n",
        "      remixer_list_buttons.visible = False\n",
        "    \n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Row([Text(\"üîÑ  Prompt Remixer - GPT-3 AI Helper\", style=TextThemeStyle.TITLE_LARGE), ElevatedButton(content=Text(\"üçú  NSP Instructions\", size=18), on_click=lambda _: NSP_instructions(page))], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Text(\"Enter a complete prompt you've written that is well worded and descriptive, and get variations of it with our AI friend. Experiment.\", style=\"titleSmall\"),\n",
        "        Divider(thickness=1, height=5),\n",
        "        Row([TextField(label=\"Seed Prompt\", expand=True, value=prefs['prompt_remixer']['seed_prompt'], on_change=lambda e: changed(e, 'seed_prompt')), TextField(label=\"Optional About Detail\", expand=True, hint_text=\"Optional about detail\", value=prefs['prompt_remixer']['optional_about_influencer'], on_change=lambda e: changed(e, 'optional_about_influencer'))]),\n",
        "        ResponsiveRow([\n",
        "          Row([NumberPicker(label=\"Amount: \", min=1, max=20, value=prefs['prompt_remixer']['amount'], on_change=lambda e: changed(e, 'amount')),\n",
        "              NumberPicker(label=\"Random Artists: \", min=0, max=10, value=prefs['prompt_remixer']['random_artists'], on_change=lambda e: changed(e, 'random_artists')),], col={'lg':6}, alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "          Row([NumberPicker(label=\"Random Styles: \", min=0, max=10, value=prefs['prompt_remixer']['random_styles'], on_change=lambda e: changed(e, 'random_styles')),\n",
        "              Checkbox(label=\"Permutate Artists\", value=prefs['prompt_remixer']['permutate_artists'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e: changed(e, 'permutate_artists'))], col={'lg':6}, alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        ]),\n",
        "        ResponsiveRow([\n",
        "          Row([Text(\"Request Mode:\"), request_slider,], col={'lg':6}),\n",
        "          Row([Text(\" AI Temperature:\"), Slider(label=\"{value}\", min=0, max=1, divisions=10, expand=True, value=prefs['prompt_remixer']['AI_temperature'], on_change=lambda e: changed(e, 'AI_temperature'))], col={'lg':6}),\n",
        "        ]),\n",
        "        ElevatedButton(content=Text(\"üçπ   Remix Prompts\", size=18), on_click=click_prompt_remixer),\n",
        "        page.prompt_remixer_list,\n",
        "        remixer_list_buttons,\n",
        "      ],\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "def buildPromptBrainstormer(page):\n",
        "    def changed(e, pref=None):\n",
        "      if pref is not None:\n",
        "        prefs['prompt_brainstormer'][pref] = e.control.value\n",
        "      status['changed_prompt_brainstormer'] = True\n",
        "    def click_prompt_brainstormer(e):\n",
        "      if prefs['prompt_brainstormer']['AI_engine'] == \"OpenAI GPT-3\":\n",
        "        if status['installed_OpenAI']:\n",
        "          run_prompt_brainstormer(page)\n",
        "        else: alert_msg(page, \"You must Install OpenAI GPT-3 Library first before using this Request Mode...\")\n",
        "      elif prefs['prompt_brainstormer']['AI_engine'] == \"TextSynth GPT-J\":\n",
        "        if status['installed_TextSynth']:\n",
        "          run_prompt_brainstormer(page)\n",
        "        else: alert_msg(page, \"You must Install TextSynth GPT-J Library first before using this Request Mode...\")\n",
        "      elif prefs['prompt_brainstormer']['AI_engine'] == \"HuggingFace Bloom 176B\":\n",
        "        if bool(prefs['HuggingFace_api_key']):\n",
        "          run_prompt_brainstormer(page)\n",
        "        else: alert_msg(page, \"You must provide your HuggingFace API Key in settings first before using this Request Mode...\")\n",
        "      elif prefs['prompt_brainstormer']['AI_engine'] == \"HuggingFace Flan-T5 XXL\":\n",
        "        if bool(prefs['HuggingFace_api_key']):\n",
        "          run_prompt_brainstormer(page)\n",
        "        else: alert_msg(page, \"You must provide your HuggingFace API Key in settings first before using this Request Mode...\")\n",
        "    page.prompt_brainstormer_list = Column([], spacing=0)\n",
        "    def add_to_prompt_brainstormer(p):\n",
        "      page.prompt_brainstormer_list.controls.append(Text(p, max_lines=3, style=TextThemeStyle.BODY_LARGE, selectable=True))\n",
        "      page.prompt_brainstormer_list.update()\n",
        "      brainstormer_list_buttons.visible = True\n",
        "      brainstormer_list_buttons.update()\n",
        "    page.add_to_prompt_brainstormer = add_to_prompt_brainstormer\n",
        "    def add_to_prompts(e):\n",
        "      page.add_to_prompts(new_prompt_text.value)\n",
        "    def clear_prompts(e):\n",
        "      page.prompt_brainstormer_list.controls = []\n",
        "      page.prompt_brainstormer_list.update()\n",
        "      brainstormer_list_buttons.visible = False\n",
        "      brainstormer_list_buttons.update()\n",
        "    def clear_prompt_text(e):\n",
        "      new_prompt_text.value = \"\"\n",
        "      new_prompt_text.update()\n",
        "\n",
        "    new_prompt_text = TextField(label=\"New Prompt Text\", expand=True, suffix=IconButton(icons.CLEAR, on_click=clear_prompt_text), autofocus=True, on_submit=add_to_prompts)\n",
        "    add_to_prompts_button = ElevatedButton(\"‚ûï  Add to Prompts\", on_click=add_to_prompts)#, icon=icons.ADD_ROUNDED\n",
        "    brainstormer_list_buttons = Row([\n",
        "        new_prompt_text, add_to_prompts_button,\n",
        "        ElevatedButton(content=Text(\"‚ùå   Clear Brainstorms\"), on_click=clear_prompts),\n",
        "    ], alignment=MainAxisAlignment.END)\n",
        "    \n",
        "    if len(page.prompt_brainstormer_list.controls) < 1:\n",
        "      brainstormer_list_buttons.visible = False\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Row([Text(\"ü§î  Prompt Brainstormer - TextSynth GPT-J-6B, OpenAI GPT-3 & HuggingFace Bloom AI\", style=TextThemeStyle.TITLE_LARGE), ElevatedButton(content=Text(\"üçú  NSP Instructions\", size=18), on_click=lambda _: NSP_instructions(page))], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Text(\"Enter a complete prompt you've written that is well worded and descriptive, and get variations of it with our AI friends. Experiment, each has different personalities.\", style=\"titleSmall\"),\n",
        "        Divider(thickness=1, height=5),\n",
        "        Row([Dropdown(label=\"AI Engine\", width=250, options=[dropdown.Option(\"TextSynth GPT-J\"), dropdown.Option(\"OpenAI GPT-3\"), dropdown.Option(\"HuggingFace Bloom 176B\"), dropdown.Option(\"HuggingFace Flan-T5 XXL\")], value=prefs['prompt_brainstormer']['AI_engine'], on_change=lambda e: changed(e, 'AI_engine')),\n",
        "          Dropdown(label=\"Request Mode\", width=250, options=[dropdown.Option(\"Brainstorm\"), dropdown.Option(\"Write\"), dropdown.Option(\"Rewrite\"), dropdown.Option(\"Edit\"), dropdown.Option(\"Story\"), dropdown.Option(\"Description\"), dropdown.Option(\"Picture\"), dropdown.Option(\"Raw Request\")], value=prefs['prompt_brainstormer']['request_mode'], on_change=lambda e: changed(e, 'request_mode')),\n",
        "        ], alignment=MainAxisAlignment.START),\n",
        "        Row([TextField(label=\"About Prompt\", expand=True, value=prefs['prompt_brainstormer']['about_prompt'], on_change=lambda e: changed(e, 'about_prompt')),]),\n",
        "        ElevatedButton(content=Text(\"‚õàÔ∏è    Brainstorm Prompt\", size=18), on_click=lambda _: run_prompt_brainstormer(page)),\n",
        "        page.prompt_brainstormer_list,\n",
        "        brainstormer_list_buttons,\n",
        "      ],\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "def buildPromptWriter(page):\n",
        "    def changed(e, pref=None):\n",
        "      if pref is not None:\n",
        "        prefs['prompt_writer'][pref] = e.control.value\n",
        "      status['changed_prompt_writer'] = True\n",
        "    page.prompt_writer_list = Column([], spacing=0)\n",
        "    def add_to_prompt_list(p):\n",
        "      page.add_to_prompts(p)\n",
        "      if prefs['enable_sounds']: page.snd_drop.play()\n",
        "    def add_to_prompt_writer(p):\n",
        "      page.prompt_writer_list.controls.append(ListTile(title=Text(p, max_lines=3, style=TextThemeStyle.BODY_LARGE), dense=True, on_click=lambda _: add_to_prompt_list(p)))\n",
        "      page.prompt_writer_list.update()\n",
        "      writer_list_buttons.visible = True\n",
        "      writer_list_buttons.update()\n",
        "    page.add_to_prompt_writer = add_to_prompt_writer\n",
        "\n",
        "    def add_to_list(e):\n",
        "      if prefs['enable_sounds']: page.snd_drop.play()\n",
        "      for p in page.prompt_writer_list.controls:\n",
        "        page.add_to_prompts(p.title.value)\n",
        "    def clear_prompts(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      page.prompt_writer_list.controls = []\n",
        "      page.prompt_writer_list.update()\n",
        "      writer_list_buttons.visible = False\n",
        "      writer_list_buttons.update()\n",
        "    writer_list_buttons = Row([ElevatedButton(content=Text(\"‚ûï  Add All Prompts to List\", size=18), on_click=add_to_list),\n",
        "        ElevatedButton(content=Text(\"‚ùå   Clear Prompts\"), on_click=clear_prompts),\n",
        "    ], alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "    if len(page.prompt_writer_list.controls) < 1:\n",
        "      writer_list_buttons.visible = False\n",
        "\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Row([Text(\"üìú Advanced Prompt Writer with Noodle Soup Prompt random variables \", style=TextThemeStyle.TITLE_LARGE), ElevatedButton(content=Text(\"üçú  NSP Instructions\", size=18), on_click=lambda _: NSP_instructions(page)),], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Text(\"Construct your Stable Diffusion Art descriptions easier, with all the extras you need to engineer perfect prompts faster. Note, you don't have to use any randoms if you rather do all custom.\", style=\"titleSmall\"),\n",
        "        Divider(thickness=1, height=5),\n",
        "        TextField(label=\"Arts Subjects\", value=prefs['prompt_writer']['art_Subjects'], on_change=lambda e: changed(e, 'art_Subjects')),\n",
        "        Row([TextField(label=\"by Artists\", value=prefs['prompt_writer']['by_Artists'], on_change=lambda e: changed(e, 'by_Artists')),\n",
        "             TextField(label=\"Art Styles\", value=prefs['prompt_writer']['art_Styles'], on_change=lambda e: changed(e, 'art_Styles')),]),\n",
        "        ResponsiveRow([\n",
        "          Row([NumberPicker(label=\"Amount: \", min=1, max=20, value=prefs['prompt_writer']['amount'], on_change=lambda e: changed(e, 'amount')),\n",
        "              NumberPicker(label=\"Random Artists: \", min=0, max=10, value=prefs['prompt_writer']['random_artists'], on_change=lambda e: changed(e, 'random_artists')),], col={'lg':6}, alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "          Row([NumberPicker(label=\"Random Styles: \", min=0, max=10, value=prefs['prompt_writer']['random_styles'], on_change=lambda e: changed(e, 'random_styles')),\n",
        "              Checkbox(label=\"Permutate Artists\", value=prefs['prompt_writer']['permutate_artists'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e: changed(e, 'permutate_artists'))], col={'lg':6}, alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        ]),\n",
        "        ElevatedButton(content=Text(\"‚úçÔ∏è   Write Prompts\", size=18), on_click=lambda _: run_prompt_writer(page)),\n",
        "        page.prompt_writer_list,\n",
        "        writer_list_buttons,\n",
        "      ],\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "def NSP_instructions(page):\n",
        "    def open_url(e):\n",
        "        if e.data.startswith('http'):\n",
        "          page.launch_url(e.data)\n",
        "        else:\n",
        "          page.set_clipboard(e.data)\n",
        "          page.snack_bar = SnackBar(content=Text(f\"üìã   NSP variable {e.data} copied to clipboard...\"))\n",
        "          page.snack_bar.open = True\n",
        "          page.update()\n",
        "    NSP_markdown = '''To use a term database, simply use any of the keys below in sentence. Copy to Clipboard with click. \n",
        "\n",
        "For example if you wanted beauty adjective, you would write `_adj-beauty_` in your prompt. \n",
        "\n",
        "## Terminology Keys (by [@WAS](https://rebrand.ly/easy-diffusion))\n",
        "\n",
        "### Adjective Types\n",
        "   - [\\_adj-architecture\\_](_adj-architecture_) - A list of architectural adjectives and styles\n",
        "   - [\\_adj-beauty\\_](_adj-beauty_) - A list of beauty adjectives for people (maybe things?)\n",
        "   - [\\_adj-general\\_](_adj-general_) - A list of general adjectives for people/things.\n",
        "   - [\\_adj-horror\\_](_adj-horror_) - A list of horror adjectives\n",
        "### Art Types\n",
        "   - [\\_artist\\_](_artist_) - A comprehensive list of artists by [**MisterRuffian**](https://docs.google.com/spreadsheets/d/1_jgQ9SyvUaBNP1mHHEzZ6HhL_Es1KwBKQtnpnmWW82I/edit) (Discord _Misterruffian#2891_)\n",
        "   - [\\_color\\_](_color_) - A comprehensive list of colors\n",
        "   - [\\_portrait-type\\_](_portrait-type_) - A list of common portrait types/poses\n",
        "   - [\\_style\\_](_style_) - A list of art styles and mediums\n",
        "### Computer Graphics Types\n",
        "   - [\\_3d-terms\\_](_3d-terms_) - A list of 3D graphics terminology\n",
        "   - [\\_color-palette\\_](_color-palette_) - A list of computer and video game console color palettes\n",
        "   - [\\_hd\\_](_hd_) - A list of high definition resolution terms\n",
        "### Miscellaneous Types\n",
        "   - [\\_details\\_](_details_) - A list of detail descriptors\n",
        "   - [\\_site\\_](_site_) - A list of websites to query\n",
        "   - [\\_gen-modififer\\_](_gen-modififer_) - A list of general modifiers adopted from [Weird Wonderful AI Art](https://weirdwonderfulai.art/)\n",
        "   - [\\_neg-weight\\_](_neg-weight_) - A lsit of negative weight ideas\n",
        "   - [\\_punk\\_](_punk_) - A list of punk modifier (eg. cyberpunk)\n",
        "   - [ _pop-culture\\_](_pop-culture_) - A list of popular culture movies, shows, etc\n",
        "   - [\\_pop-location\\_](_pop-location_) - A list of popular tourist locations\n",
        "   - [\\_fantasy-setting\\_](_fantasy-setting_) - A list of fantasy location settings\n",
        "   - [\\_fantasy-creature\\_](_fantasy-creature_) - A list of fantasy creatures\n",
        "   - [\\_animals\\_](_animals_) - A list of modern animals\n",
        "### Noun Types\n",
        "   - [\\_noun-beauty\\_](_noun-beauty_) - A list of beauty related nouns\n",
        "   - [\\_noun-emote\\_](_noun-emote_) - A list of emotions and expressions\n",
        "   - [\\_noun-fantasy\\_](_noun-fantasy_) - A list of fantasy nouns\n",
        "   - [\\_noun-general\\_](_noun-general_) - A list of general nouns\n",
        "   - [\\_noun-horror\\_](_noun-horror_) - A list of horror nouns\n",
        "### People Types\n",
        "   - [\\_bodyshape\\_](_bodyshape_) - A list of body shapes\n",
        "   - [\\_celeb\\_](_celeb_) - A list of celebrities\n",
        "   - [\\_eyecolor\\_](_eyecolor_) - A list of eye colors\n",
        "   - [\\_hair\\_](_hair_) - A list of hair types\n",
        "   - [\\_nationality\\_](_nationality_) - A list of nationalities\n",
        "   - [\\_occputation\\_](_occputation_) A list of occupation types\n",
        "   - [\\_skin-color\\_](_skin-color_) - A list of skin tones\n",
        "   - [\\_identity-young\\_](_identity-young_) A list of young identifiers\n",
        "   - [\\_identity-adult\\_](_identity-adult_) A list of adult identifiers\n",
        "   - [\\_identity\\_](_identity_) A list of general identifiers\n",
        "### Photography / Image / Film Types\n",
        "   - [\\_aspect-ratio\\_](_aspect-ratio_) - A list of common aspect ratios\n",
        "   - [\\_cameras\\_](_cameras_) - A list of camera models *(including manufactuerer)*\n",
        "   - [\\_camera-manu\\_](_camera-manu_) - A list of camera manufacturers\n",
        "   - [\\_f-stop\\_](_f-stop_) - A list of camera aperture f-stop\n",
        "   - [\\_focal-length\\_](_focal-length_) - A list of focal length ranges\n",
        "   - [\\_photo-term\\_](_photo-term_) - A list of photography terms relating to photos\n",
        "\n",
        "So in Subject try something like: `A _color_ _noun-general_ that is _adj-beauty_ and _adj-general_ with a _noun-emote_ _noun-fantasy_`\n",
        "'''\n",
        "    def close_NSP_dlg(e):\n",
        "      instruction_alert.open = False\n",
        "      page.update()\n",
        "    instruction_alert = AlertDialog(title=Text(\"üçú  Noodle Soup Prompt Variables Instructions\"), content=Column([Markdown(NSP_markdown, extension_set=\"gitHubWeb\", on_tap_link=open_url)], scroll=ScrollMode.AUTO), actions=[TextButton(\"üç≤  Good Soup! \", on_click=close_NSP_dlg)], actions_alignment=MainAxisAlignment.END,)\n",
        "    page.dialog = instruction_alert\n",
        "    instruction_alert.open = True\n",
        "    page.update()\n",
        "\n",
        "def buildStableDiffusers(page):\n",
        "    page.DanceDiffusion = buildDanceDiffusion(page)\n",
        "    page.RePainter = buildRepainter(page)\n",
        "    page.ImageVariation = buildImageVariation(page)\n",
        "    page.CLIPstyler = buildCLIPstyler(page)\n",
        "    page.MaterialDiffusion = buildMaterialDiffusion(page)\n",
        "    page.MaskMaker = buildDreamMask(page)\n",
        "    page.DreamFusion = buildDreamFusion(page)\n",
        "    page.DreamBooth = buildDreamBooth(page)\n",
        "    page.TexualInversion = buildTextualInversion(page)\n",
        "    diffusersTabs = Tabs(\n",
        "        selected_index=0,\n",
        "        animation_duration=300,\n",
        "        tabs=[\n",
        "            Tab(text=\"DreamBooth\", content=page.DreamBooth, icon=icons.PHOTO),\n",
        "            Tab(text=\"Texual-Inversion\", content=page.TexualInversion, icon=icons.PHOTO_ALBUM),\n",
        "            Tab(text=\"Image Variation\", content=page.ImageVariation, icon=icons.FORMAT_COLOR_FILL),\n",
        "            Tab(text=\"RePainter\", content=page.RePainter, icon=icons.FORMAT_PAINT),\n",
        "            Tab(text=\"CLIP-Styler\", content=page.CLIPstyler, icon=icons.STYLE),\n",
        "            Tab(text=\"Material Diffusion\", content=page.MaterialDiffusion, icon=icons.TEXTURE),\n",
        "            Tab(text=\"DreamFusion 3D\", content=page.DreamFusion, icon=icons.THREED_ROTATION),\n",
        "            Tab(text=\"HarmonAI Dance Diffusion\", content=page.DanceDiffusion, icon=icons.QUEUE_MUSIC),\n",
        "            #Tab(text=\"Dream Mask Maker\", content=page.MaskMaker, icon=icons.GRADIENT),\n",
        "        ],\n",
        "        expand=1,\n",
        "        #on_change=tab_on_change\n",
        "    )\n",
        "    return diffusersTabs\n",
        "\n",
        "def buildExtras(page):\n",
        "    page.ESRGAN_upscaler = buildESRGANupscaler(page)\n",
        "    page.RetrievePrompts = buildRetrievePrompts(page)\n",
        "    page.InitFolder = buildInitFolder(page)\n",
        "    page.CachedModelManager = buildCachedModelManager(page)\n",
        "    page.Image2Text = buildImage2Text(page)\n",
        "    page.DallE2 = buildDallE2(page)\n",
        "    page.Kandinsky = buildKandinsky(page)\n",
        "    extrasTabs = Tabs(\n",
        "        selected_index=0,\n",
        "        animation_duration=300,\n",
        "        tabs=[\n",
        "            Tab(text=\"Real-ESRGAN Batch Upscaler\", content=page.ESRGAN_upscaler, icon=icons.PHOTO_SIZE_SELECT_LARGE),\n",
        "            Tab(text=\"Retrieve Prompt from Image\", content=page.RetrievePrompts, icon=icons.PHOTO_LIBRARY_OUTLINED),\n",
        "            Tab(text=\"Init Images from Folder\", content=page.InitFolder, icon=icons.FOLDER_SPECIAL),\n",
        "            Tab(text=\"Cache Manager\", content=page.CachedModelManager, icon=icons.CACHED),\n",
        "            Tab(text=\"Image2Text Interrogator\", content=page.Image2Text, icon=icons.WRAP_TEXT),\n",
        "            Tab(text=\"OpenAI Dall-E 2\", content=page.DallE2, icon=icons.BLUR_CIRCULAR),\n",
        "            Tab(text=\"Kandinsky 2\", content=page.Kandinsky, icon=icons.AC_UNIT),\n",
        "        ],\n",
        "        expand=1,\n",
        "        #on_change=tab_on_change\n",
        "    )\n",
        "    return extrasTabs\n",
        "\n",
        "ESRGAN_prefs = {\n",
        "    'enlarge_scale': 1.5,\n",
        "    'face_enhance': False,\n",
        "    'image_path': '',\n",
        "    'save_to_GDrive': True,\n",
        "    'upload_file': False,\n",
        "    'download_locally': False,\n",
        "    'display_image': False,\n",
        "    'dst_image_path': '',\n",
        "    'filename_suffix': '',\n",
        "    'split_image_grid': False,\n",
        "    'rows': 3,\n",
        "    'cols': 3,\n",
        "}\n",
        "def buildESRGANupscaler(page):\n",
        "    def changed(e, pref=None):\n",
        "      if pref is not None:\n",
        "        ESRGAN_prefs[pref] = e.control.value\n",
        "    def add_to_ESRGAN_output(o):\n",
        "      ESRGAN_output.controls.append(o)\n",
        "      ESRGAN_output.update()\n",
        "      if clear_button.visible == False:\n",
        "        clear_button.visible = True\n",
        "        clear_button.update()\n",
        "      #generator_list_buttons.visible = True\n",
        "      #generator_list_buttons.update()\n",
        "    page.add_to_ESRGAN_output = add_to_ESRGAN_output\n",
        "    enlarge_scale_value = Text(f\" {float(ESRGAN_prefs['enlarge_scale'])}x\", weight=FontWeight.BOLD)\n",
        "    def change_enlarge_scale(e):\n",
        "        enlarge_scale_value.value = f\" {int(e.control.value) if e.control.value.is_integer() else float(e.control.value)}x\"\n",
        "        enlarge_scale_slider.update()\n",
        "        changed(e, 'enlarge_scale')\n",
        "    def toggle_split(e):\n",
        "      split_container.height = None if e.control.value else 0\n",
        "      changed(e, 'split_image_grid')\n",
        "      split_container.update()\n",
        "    def clear_output(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      ESRGAN_output.controls = []\n",
        "      ESRGAN_output.update()\n",
        "      clear_button.visible = False\n",
        "      clear_button.update()\n",
        "    page.clear_ESRGAN_output = clear_output\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "          upload_files(e)\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "      if e.progress == 1:\n",
        "        fname = os.path.join(root_dir, e.file_name)\n",
        "        image_path.value = fname\n",
        "        image_path.update()\n",
        "        ESRGAN_prefs['image_path'] = fname\n",
        "        page.update()\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def pick_path(e):\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\", \"jpg\", \"jpeg\"], dialog_title=\"Pick Image File to Enlarge\")\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    def pick_destination(e):\n",
        "        alert_msg(page, \"Switch to Colab tab and press Files button on the Left & Find the Path you want to Save Images into, Right Click and Copy Path, then Paste here\")\n",
        "    page.overlay.append(file_picker)\n",
        "    enlarge_scale = Slider(min=1, max=4, divisions=6, label=\"{value}x\", value=ESRGAN_prefs['enlarge_scale'], on_change=change_enlarge_scale, expand=True)\n",
        "    enlarge_scale_slider = Row([Text(\"Enlarge Scale: \"), enlarge_scale_value, enlarge_scale])\n",
        "    face_enhance = Checkbox(label=\"Use Face Enhance GPFGAN\", value=ESRGAN_prefs['face_enhance'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'face_enhance'))\n",
        "    image_path = TextField(label=\"Image File or Folder Path\", value=ESRGAN_prefs['image_path'], on_change=lambda e:changed(e,'image_path'), suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_path), expand=1)\n",
        "    dst_image_path = TextField(label=\"Destination Image Path\", value=ESRGAN_prefs['dst_image_path'], on_change=lambda e:changed(e,'dst_image_path'), suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD_OUTLINED, on_click=pick_destination), expand=1)\n",
        "    filename_suffix = TextField(label=\"Optional Filename Suffix\", hint_text=\"-big\", value=ESRGAN_prefs['filename_suffix'], on_change=lambda e:changed(e,'filename_suffix'), width=260)\n",
        "    download_locally = Checkbox(label=\"Download Images Locally\", value=ESRGAN_prefs['download_locally'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'download_locally'))\n",
        "    display_image = Checkbox(label=\"Display Upscaled Image\", value=ESRGAN_prefs['display_image'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'display_image'))\n",
        "    split_image_grid = Switch(label=\"Split Image Grid\", value=ESRGAN_prefs['split_image_grid'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_split)\n",
        "    rows = NumberPicker(label=\"Rows: \", min=1, max=8, value=ESRGAN_prefs['rows'], on_change=lambda e: changed(e, 'rows'))\n",
        "    cols = NumberPicker(label=\"Columns: \", min=1, max=8, value=ESRGAN_prefs['cols'], on_change=lambda e: changed(e, 'cols'))\n",
        "    split_container = Container(Row([rows, Container(content=None, width=25), cols]), animate_size=animation.Animation(800, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE, padding=padding.only(left=28), height=0)\n",
        "    ESRGAN_output = Column([])\n",
        "    clear_button = Row([ElevatedButton(content=Text(\"‚ùå   Clear Output\"), on_click=clear_output)], alignment=MainAxisAlignment.END)\n",
        "    clear_button.visible = len(ESRGAN_output.controls) > 0\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Text(\"‚ÜïÔ∏è   Real-ESRGAN AI Upscale Enlarging\", style=TextThemeStyle.TITLE_LARGE),\n",
        "        Text(\"Select one or more files, or give path to image or folder. Save to your Google Drive and/or Download.\"),\n",
        "        Divider(thickness=1, height=5),\n",
        "        enlarge_scale_slider,\n",
        "        face_enhance,\n",
        "        Row([# I can't get them to stretch without crashing!\n",
        "        image_path,\n",
        "        dst_image_path,], width=page.width - 80),\n",
        "        filename_suffix,\n",
        "        download_locally,\n",
        "        display_image,\n",
        "        #Divider(thickness=2, height=4),\n",
        "        split_image_grid,\n",
        "        split_container,\n",
        "        ElevatedButton(content=Text(\"üêò  Run AI Upscaling\", size=18), on_click=lambda _: run_upscaling(page)),\n",
        "        ESRGAN_output,\n",
        "        clear_button,\n",
        "      ],\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "retrieve_prefs = {\n",
        "    'image_path': '',\n",
        "    'add_to_prompts': True,\n",
        "    'display_full_metadata': False,\n",
        "    'display_image': False,\n",
        "    'upload_file': False,\n",
        "}\n",
        "def buildRetrievePrompts(page):\n",
        "    def changed(e, pref=None):\n",
        "        if pref is not None:\n",
        "          retrieve_prefs[pref] = e.control.value\n",
        "    def add_to_retrieve_output(o):\n",
        "      retrieve_output.controls.append(o)\n",
        "      retrieve_output.update()\n",
        "    def clear_output(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      retrieve_output.controls = []\n",
        "      retrieve_output.update()\n",
        "      clear_button.visible = False\n",
        "      clear_button.update()\n",
        "    def pick_image(e):\n",
        "        alert_msg(page, \"Switch to Colab tab and press Files button on the Left & Find the Path you want to Retrieve, Right Click and Copy Path, then Paste here\")\n",
        "    page.add_to_retrieve_output = add_to_retrieve_output\n",
        "    image_path = TextField(label=\"Image File or Folder Path\", value=retrieve_prefs['image_path'], on_change=lambda e:changed(e,'image_path'), suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_image))\n",
        "    add_to_prompts = Checkbox(label=\"Add to Prompts\", value=retrieve_prefs['add_to_prompts'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'add_to_prompts'))\n",
        "    display_full_metadata = Checkbox(label=\"Display Full Metadata\", value=retrieve_prefs['display_full_metadata'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'display_full_metadata'))\n",
        "    display_image = Checkbox(label=\"Display Image\", value=retrieve_prefs['display_image'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'display_image'))\n",
        "    retrieve_output = Column([])\n",
        "    clear_button = Row([ElevatedButton(content=Text(\"‚ùå   Clear Output\"), on_click=clear_output)], alignment=MainAxisAlignment.END)\n",
        "    clear_button.visible = len(retrieve_output.controls) > 0\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Text(\"üì∞  Retrieve Dream Prompts from Image Metadata\", style=TextThemeStyle.TITLE_LARGE),\n",
        "        Text(\"Give it images made here and gives you all parameters used to recreate it. Either upload png file(s) or paste path to image or folder or config.json to revive your dreams..\"),\n",
        "        Divider(thickness=1, height=5),\n",
        "        image_path,\n",
        "        add_to_prompts,\n",
        "        display_full_metadata,\n",
        "        display_image,\n",
        "        ElevatedButton(content=Text(\"üò¥  Retrieve Dream\", size=18), on_click=lambda _: run_retrieve(page)),\n",
        "        retrieve_output,\n",
        "        clear_button,\n",
        "      ],\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "initfolder_prefs = {\n",
        "    'prompt_string': '',\n",
        "    'init_folder': '',\n",
        "    'include_strength': True,\n",
        "    'image_strength': 0.5,\n",
        "}\n",
        "def buildInitFolder(page):\n",
        "    def changed(e, pref=None):\n",
        "        if pref is not None:\n",
        "          initfolder_prefs[pref] = e.control.value\n",
        "    def add_to_initfolder_output(o):\n",
        "      initfolder_output.controls.append(o)\n",
        "      initfolder_output.update()\n",
        "    def clear_output(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      initfolder_output.controls = []\n",
        "      initfolder_output.update()\n",
        "      clear_button.visible = False\n",
        "      clear_button.update()\n",
        "    def pick_init(e):\n",
        "        alert_msg(page, \"Switch to Colab tab and press Files button on the Left & Find the Path you want to use as Init Folder, Right Click and Copy Path, then Paste here\")\n",
        "    def toggle_strength(e):\n",
        "      changed(e,'include_strength')\n",
        "      strength_row.visible = e.control.value\n",
        "      strength_row.update()\n",
        "    page.add_to_initfolder_output = add_to_initfolder_output\n",
        "    prompt_string = TextField(label=\"Prompt Text\", value=initfolder_prefs['prompt_string'], on_change=lambda e:changed(e,'prompt_string'))\n",
        "    init_folder = TextField(label=\"Init Image Folder Path\", value=initfolder_prefs['init_folder'], on_change=lambda e:changed(e,'init_folder'), suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_init))\n",
        "    include_strength = Checkbox(label=\"Include Strength\", value=initfolder_prefs['include_strength'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=toggle_strength)\n",
        "    image_strength = Slider(min=0.1, max=0.9, divisions=16, label=\"{value}%\", value=float(initfolder_prefs['image_strength']), expand=True)\n",
        "    strength_row = Row([Text(\"Image Strength:\"), image_strength])\n",
        "    strength_row.visible = initfolder_prefs['include_strength']\n",
        "    strength_container = Container(Row([Text(\"Init Image Strength: \"), image_strength]))\n",
        "    initfolder_output = Column([])\n",
        "    clear_button = Row([ElevatedButton(content=Text(\"‚ùå   Clear Output\"), on_click=clear_output)], alignment=MainAxisAlignment.END)\n",
        "    clear_button.visible = len(initfolder_output.controls) > 0\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Text(\"üìÇ Generate Prompts from Folder as Init Images\", style=TextThemeStyle.TITLE_LARGE),\n",
        "        Text(\"Provide a Folder with a collection of images that you want to automatically add to prompts list with init_image overides...\"),\n",
        "        Divider(thickness=1, height=4),\n",
        "        init_folder,\n",
        "        prompt_string,\n",
        "        include_strength,\n",
        "        strength_row,\n",
        "        ElevatedButton(content=Text(\"‚ûï  Add to Prompts\", size=18), on_click=lambda _: run_initfolder(page)),\n",
        "        initfolder_output,\n",
        "        clear_button,\n",
        "      ]\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "image2text_prefs = {\n",
        "    'mode': 'best',\n",
        "    'folder_path': '',\n",
        "    'image_path': '',\n",
        "    'max_size': 768,\n",
        "    'save_csv': False,\n",
        "    'images': [],\n",
        "}\n",
        "\n",
        "def buildImage2Text(page):\n",
        "    global prefs, image2text_prefs\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "      if pref is not None:\n",
        "        if ptype == \"int\":\n",
        "          image2text_prefs[pref] = int(e.control.value)\n",
        "        elif ptype == \"float\":\n",
        "          image2text_prefs[pref] = float(e.control.value)\n",
        "        else:\n",
        "          image2text_prefs[pref] = e.control.value\n",
        "    def add_to_image2text_output(o):\n",
        "      page.image2text_output.controls.append(o)\n",
        "      page.image2text_output.update()\n",
        "    def clear_output(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      page.image2text_output.controls = []\n",
        "      page.image2text_output.update()\n",
        "      save_dir = os.path.join(root_dir, 'image2text')\n",
        "      if os.path.exists(save_dir):\n",
        "        for f in os.listdir(save_dir):\n",
        "            os.remove(os.path.join(save_dir, f))\n",
        "        os.rmdir(save_dir)\n",
        "      page.image2text_file_list.controls = []\n",
        "      page.image2text_file_list.update()\n",
        "      image2text_list_buttons.visible = False\n",
        "      image2text_list_buttons.update()\n",
        "    def i2t_help(e):\n",
        "      def close_i2t_dlg(e):\n",
        "        nonlocal i2t_help_dlg\n",
        "        i2t_help_dlg.open = False\n",
        "        page.update()\n",
        "      i2t_help_dlg = AlertDialog(title=Text(\"üíÅ   Help with Image2Text CLIP Interrogator\"), content=Column([\n",
        "          Text(\"\"),\n",
        "        ], scroll=ScrollMode.AUTO), actions=[TextButton(\"üò™  Okay then... \", on_click=close_i2t_dlg)], actions_alignment=MainAxisAlignment.END)\n",
        "      page.dialog = i2t_help_dlg\n",
        "      i2t_help_dlg.open = True\n",
        "      page.update()\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "          upload_files(e)\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "      if e.progress == 1:\n",
        "        save_dir = os.path.join(root_dir, 'image2text')\n",
        "        if not os.path.exists(save_dir):\n",
        "          os.mkdir(save_dir)\n",
        "        image2text_prefs['folder_path'] = save_dir\n",
        "        fname = os.path.join(root_dir, e.file_name)\n",
        "        fpath = os.path.join(save_dir, e.file_name)\n",
        "        original_img = PILImage.open(fname)\n",
        "        width, height = original_img.size\n",
        "        width, height = scale_dimensions(width, height, image2text_prefs['max_size'])\n",
        "        original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "        original_img.save(fpath)\n",
        "        shutil.move(fname, fpath)\n",
        "        page.image2text_file_list.controls.append(ListTile(title=Text(fpath), dense=True))\n",
        "        page.image2text_file_list.update()\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def pick_path(e):\n",
        "        file_picker.pick_files(allow_multiple=True, allowed_extensions=[\"png\", \"PNG\", \"jpg\", \"jpeg\"], dialog_title=\"Pick Image File to Enlarge\")\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    page.overlay.append(file_picker)\n",
        "    def add_image(e):\n",
        "        save_dir = os.path.join(root_dir, 'image2text')\n",
        "        if not os.path.exists(save_dir):\n",
        "          os.mkdir(save_dir)\n",
        "        image2text_prefs['folder_path'] = save_dir\n",
        "        if image_path.value.startswith('http'):\n",
        "          import requests\n",
        "          from io import BytesIO\n",
        "          response = requests.get(image_path.value)\n",
        "          fpath = os.path.join(save_dir, image_path.value.rpartition(slash)[2])\n",
        "          original_img = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "          width, height = original_img.size\n",
        "          width, height = scale_dimensions(width, height, image2text_prefs['max_size'])\n",
        "          original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "          original_img.save(fpath)\n",
        "          page.image2text_file_list.controls.append(ListTile(title=Text(fpath), dense=True))\n",
        "          page.image2text_file_list.update()\n",
        "        elif os.path.isfile(image_path.value):\n",
        "          fpath = os.path.join(save_dir, image_path.value.rpartition(slash)[2])\n",
        "          original_img = PILImage.open(image_path.value)\n",
        "          width, height = original_img.size\n",
        "          width, height = scale_dimensions(width, height, image2text_prefs['max_size'])\n",
        "          original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "          original_img.save(fpath)\n",
        "          #shutil.copy(image_path.value, fpath)\n",
        "          page.image2text_file_list.controls.append(ListTile(title=Text(fpath), dense=True))\n",
        "          page.image2text_file_list.update()\n",
        "        elif os.path.isdir(image_path.value):\n",
        "          for f in os.listdir(image_path.value):\n",
        "            file_path = os.path.join(image_path.value, f)\n",
        "            if os.path.isdir(file_path): continue\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "              fpath = os.path.join(save_dir, f)\n",
        "              original_img = PILImage.open(file_path)\n",
        "              width, height = original_img.size\n",
        "              width, height = scale_dimensions(width, height, image2text_prefs['max_size'])\n",
        "              original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "              original_img.save(fpath)\n",
        "              #shutil.copy(file_path, fpath)\n",
        "              page.image2text_file_list.controls.append(ListTile(title=Text(fpath), dense=True))\n",
        "              page.image2text_file_list.update()\n",
        "        else:\n",
        "          if bool(image_path.value):\n",
        "            alert_msg(page, \"Couldn't find a valid File, Path or URL...\")\n",
        "          else:\n",
        "            pick_path(e)\n",
        "          return\n",
        "        image_path.value = \"\"\n",
        "        image_path.update()\n",
        "    page.image2text_list = Column([], spacing=0)\n",
        "    def add_to_prompt_list(p):\n",
        "      page.add_to_prompts(p)\n",
        "      if prefs['enable_sounds']: page.snd_drop.play()\n",
        "    def add_to_image2text(p):\n",
        "      page.image2text_list.controls.append(ListTile(title=Text(p, max_lines=3, style=TextThemeStyle.BODY_LARGE), dense=True, on_click=lambda _: add_to_prompt_list(p)))\n",
        "      page.image2text_list.update()\n",
        "      image2text_list_buttons.visible = True\n",
        "      image2text_list_buttons.update()\n",
        "    page.add_to_image2text = add_to_image2text\n",
        "    def add_to_list(e):\n",
        "      if prefs['enable_sounds']: page.snd_drop.play()\n",
        "      for p in page.image2text_list.controls:\n",
        "        page.add_to_prompts(p.title.value)\n",
        "    def clear_prompts(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      page.image2text_list.controls = []\n",
        "      page.image2text_list.update()\n",
        "      prompts = []\n",
        "      image2text_list_buttons.visible = False\n",
        "      image2text_list_buttons.update()\n",
        "    image2text_list_buttons = Row([ElevatedButton(content=Text(\"‚ûï  Add All Prompts to List\", size=18), on_click=add_to_list),\n",
        "        ElevatedButton(content=Text(\"‚ùå   Clear Prompts\"), on_click=clear_prompts),\n",
        "    ], alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "    if len(page.image2text_list.controls) < 1:\n",
        "      image2text_list_buttons.visible = False\n",
        "\n",
        "    mode = Dropdown(label=\"Interrogation Mode\", width=250, options=[dropdown.Option(\"best\"), dropdown.Option(\"classic\"), dropdown.Option(\"fast\")], value=image2text_prefs['mode'], on_change=lambda e: changed(e, 'mode'))\n",
        "    max_size = Slider(min=256, max=1024, divisions=12, label=\"{value}px\", value=float(image2text_prefs['max_size']), expand=True, on_change=lambda e:changed(e,'max_size', ptype='int'))\n",
        "    save_csv = Checkbox(label=\"Save CSV file of Prompts\", tooltip=\"\", value=image2text_prefs['save_csv'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'save_csv'))\n",
        "    max_row = Row([Text(\"Max Resolution Size: \"), max_size])\n",
        "    image_path = TextField(label=\"Image File or Folder Path or URL to Train\", value=image2text_prefs['image_path'], on_change=lambda e:changed(e,'image_path'), suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_path), expand=1)\n",
        "    add_image_button = ElevatedButton(content=Text(\"Add File or Folder\"), on_click=add_image)\n",
        "    page.image2text_file_list = Column([], tight=True, spacing=0)\n",
        "    page.image2text_output = Column([])\n",
        "    #clear_button = Row([ElevatedButton(content=Text(\"‚ùå   Clear Output\"), on_click=clear_output)], alignment=MainAxisAlignment.END)\n",
        "    #clear_button.visible = len(page.image2text_output.controls) > 0\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Row([Text(\"üò∂‚Äçüå´Ô∏è  Image2Text CLIP-Interrogator\", style=TextThemeStyle.TITLE_LARGE), IconButton(icon=icons.HELP, tooltip=\"Help with Image2Text Interrogator\", on_click=i2t_help)], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Text(\"Create prompts by describing input images...\"),\n",
        "        Divider(thickness=1, height=4),\n",
        "        mode,\n",
        "        max_row,\n",
        "        Row([image_path, add_image_button]),\n",
        "        page.image2text_file_list,\n",
        "        page.image2text_list,\n",
        "        image2text_list_buttons,\n",
        "        ElevatedButton(content=Text(\"üë®‚Äçüé®Ô∏è  Get Prompts from Images\", size=18), on_click=lambda _: run_image2text(page)),\n",
        "        page.image2text_output,\n",
        "      ],\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "dance_prefs = {\n",
        "    'dance_model': 'maestro-150k',\n",
        "    'installed_model': None,\n",
        "    'inference_steps': 50,\n",
        "    'batch_size': 1,\n",
        "    'seed': 0,\n",
        "    'audio_length_in_s': 4.5,\n",
        "    'community_model': 'LCD Soundsystem',\n",
        "}\n",
        "community_models = [\n",
        "    {'name': 'LCD Soundsystem', 'download': 'https://drive.google.com/uc?id=1WX8nL4_x49h0OJE5iGrjXJnIJ0yvsTxI', 'ckpt':'lcd-soundsystem-200k.ckpt'},\n",
        "    {'name': 'Vague phrases', 'download': 'https://drive.google.com/uc?id=1nUn2qydqU7hlDUT-Skq_Ionte_8-Vdjr', 'ckpt': 'SingingInFepoch=1028-step=195500-pruned.ckpt'}, \n",
        "    {'name': 'Gesaffelstein', 'download': 'https://drive.google.com/uc?id=1-BuDzz4ajX-ufVByEX_fCkOtB00DVygB', 'ckpt':'Gesaffelstein_epoch=2537-step=445000.ckpt'},\n",
        "    {'name': 'Smash Mouth Vocals', 'download': 'https://drive.google.com/uc?id=1h3fkJnByw3mKpXUiNPWKoYtzmpeg1QEt', 'ckpt':'epoch=773-step=191500.ckpt'},\n",
        "    {'name': 'Daft Punk', 'download': 'https://drive.google.com/uc?id=1CZjWIcL528zbZa6GrS_triob0hUy6KEs', 'ckpt':'daft-punk-241.5k.ckpt'},\n",
        "]\n",
        "dance_pipe = None\n",
        "def buildDanceDiffusion(page):\n",
        "    global dance_pipe, dance_prefs\n",
        "    def changed(e, pref=None, isInt=False):\n",
        "        if pref is not None:\n",
        "          if isInt:\n",
        "            dance_prefs[pref] = int(e.control.value)\n",
        "          else:\n",
        "            dance_prefs[pref] = e.control.value\n",
        "    def changed_model(e):\n",
        "      dance_prefs['dance_model'] = e.control.value\n",
        "      if e.control.value == 'Community':\n",
        "        community_model.visible = True\n",
        "        community_model.update()\n",
        "      else:\n",
        "        if community_model.visible:\n",
        "          community_model.visible = False\n",
        "          community_model.update()\n",
        "    dance_model = Dropdown(label=\"Dance Model\", width=250, options=[dropdown.Option(\"maestro-150k\"), dropdown.Option(\"glitch-440k\"), dropdown.Option(\"jmann-small-190k\"), dropdown.Option(\"jmann-large-580k\"), dropdown.Option(\"unlocked-250k\"), dropdown.Option(\"honk-140k\"), dropdown.Option(\"gwf-440k\"), dropdown.Option(\"Community\")], value=dance_prefs['dance_model'], on_change=changed_model)\n",
        "    community_model = Dropdown(label=\"Community Model\", width=250, options=[], value=dance_prefs['community_model'], on_change=lambda e: changed(e, 'community_model'))\n",
        "    for c in community_models:\n",
        "      community_model.options.append(dropdown.Option(c['name']))\n",
        "    if not dance_prefs['dance_model'] == 'Community':\n",
        "      community_model.visible = False\n",
        "    inference_steps = Slider(min=10, max=200, divisions=190, label=\"{value}\", value=float(dance_prefs['inference_steps']), expand=True)\n",
        "    inference_row = Row([Text(\"Number of Inference Steps: \"), inference_steps])\n",
        "    batch_size = TextField(label=\"Batch Size\", value=dance_prefs['batch_size'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'batch_size', isInt=True), width = 90)\n",
        "    seed = TextField(label=\"Random Seed\", value=dance_prefs['seed'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'seed', isInt=True), width = 110)\n",
        "    audio_length_in_s = TextField(label=\"Audio Length in Seconds\", value=dance_prefs['audio_length_in_s'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'audio_length_in_s'), width = 190)\n",
        "    number_row = Row([batch_size, seed, audio_length_in_s])\n",
        "    page.dance_output = Column([])\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Text(\"üëØ Create experimental music or sounds with HarmonAI trained audio models\", style=TextThemeStyle.TITLE_LARGE),\n",
        "        Text(\"Tools to train a generative model on arbitrary audio samples...\"),\n",
        "        Divider(thickness=1, height=4),\n",
        "        Row([dance_model, community_model]),\n",
        "        inference_row,\n",
        "        number_row,\n",
        "        ElevatedButton(content=Text(\"üéµ  Run Dance Diffusion\", size=18), on_click=lambda _: run_dance_diffusion(page)),\n",
        "        page.dance_output,\n",
        "      ]\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "dreamfusion_prefs = {\n",
        "    'prompt_text': '', \n",
        "    'training_iters': 5000,\n",
        "    'learning_rate': 0.001,\n",
        "    'training_nerf_resolution': 64,\n",
        "    'seed': 0,\n",
        "    'lambda_entropy': 0.0001,\n",
        "    'max_steps': 512,\n",
        "    'checkpoint': 'latest',\n",
        "    'workspace': 'trial',\n",
        "}\n",
        "\n",
        "def buildDreamFusion(page):\n",
        "    global prefs, dreamfusion_prefs\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "      if pref is not None:\n",
        "        if ptype == \"int\":\n",
        "          dreamfusion_prefs[pref] = int(e.control.value)\n",
        "        elif ptype == \"float\":\n",
        "          dreamfusion_prefs[pref] = float(e.control.value)\n",
        "        else:\n",
        "          dreamfusion_prefs[pref] = e.control.value\n",
        "    def add_to_dreamfusion_output(o):\n",
        "      page.dreamfusion_output.controls.append(o)\n",
        "      page.dreamfusion_output.update()\n",
        "    def clear_output(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      page.dreamfusion_output.controls = []\n",
        "      page.dreamfusion_output.update()\n",
        "      clear_button.visible = False\n",
        "      clear_button.update()\n",
        "    def df_help(e):\n",
        "      def close_df_dlg(e):\n",
        "        nonlocal df_help_dlg\n",
        "        df_help_dlg.open = False\n",
        "        page.update()\n",
        "      df_help_dlg = AlertDialog(title=Text(\"üíÅ   Help with DreamFusion\"), content=Column([\n",
        "          Text(\"It's difficult to explain exactly what all these parameters do, but keep it close to defaults, keep prompt simple, or experiment to see what's what, we don't know.\"),\n",
        "          Text('It takes about 0.7s per training step, so the default 5000 training steps take around 1 hour to finish. A larger Training_iters usually leads to better results.'),\n",
        "          Text('If CUDA OOM, try to decrease Max_steps and Training_nerf_resolution.'),\n",
        "          Text('If the NeRF fails to learn anything (empty scene, only background), try to decrease Lambda_entropy which regularizes the learned opacity.')\n",
        "        ], scroll=ScrollMode.AUTO), actions=[TextButton(\"üòä  So Exciting... \", on_click=close_df_dlg)], actions_alignment=MainAxisAlignment.END)\n",
        "      page.dialog = df_help_dlg\n",
        "      df_help_dlg.open = True\n",
        "      page.update()\n",
        "    prompt_text = TextField(label=\"Prompt Text\", value=dreamfusion_prefs['prompt_text'], on_change=lambda e:changed(e,'prompt_text'))\n",
        "    training_iters = TextField(label=\"Training Iterations\", value=dreamfusion_prefs['training_iters'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'training_iters', ptype='int'), width = 160)\n",
        "    learning_rate = TextField(label=\"Learning Rate\", value=dreamfusion_prefs['learning_rate'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'learning_rate', ptype='float'), width = 160)\n",
        "    training_nerf_resolution = TextField(label=\"Training NERF Res\", value=dreamfusion_prefs['training_nerf_resolution'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'training_nerf_resolution', ptype='int'), width = 160)\n",
        "    seed = TextField(label=\"Seed\", value=dreamfusion_prefs['seed'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'seed', ptype='int'), width = 160)\n",
        "    lambda_entropy = TextField(label=\"Lambda Entropy\", value=dreamfusion_prefs['lambda_entropy'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'lambda_entropy', ptype='float'), width = 160)\n",
        "    max_steps = TextField(label=\"Max Steps\", value=dreamfusion_prefs['max_steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'max_steps', ptype='int'), width = 160)\n",
        "    workspace = TextField(label=\"Workspace Folder\", value=dreamfusion_prefs['workspace'], on_change=lambda e:changed(e,'workspace'))\n",
        "    page.dreamfusion_output = Column([])\n",
        "    clear_button = Row([ElevatedButton(content=Text(\"‚ùå   Clear Output\"), on_click=clear_output)], alignment=MainAxisAlignment.END)\n",
        "    clear_button.visible = len(page.dreamfusion_output.controls) > 0\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Row([Text(\"üóø  Create experimental DreamFusion 3D Model and Video\", style=TextThemeStyle.TITLE_LARGE), IconButton(icon=icons.HELP, tooltip=\"Help with DreamFusion Settings\", on_click=df_help)], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Text(\"Provide a prompt to render a model. Warning: May take over an hour to run the training...\"),\n",
        "        Divider(thickness=1, height=4),\n",
        "        prompt_text,\n",
        "        Row([training_iters,learning_rate, lambda_entropy]),\n",
        "        Row([seed, training_nerf_resolution, max_steps]),\n",
        "        Row([workspace]),\n",
        "        ElevatedButton(content=Text(\"üî®  Run DreamFusion\", size=18), on_click=lambda _: run_dreamfusion(page)),\n",
        "        page.dreamfusion_output,\n",
        "        clear_button,\n",
        "      ]\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "repaint_prefs = {\n",
        "    'original_image': '',\n",
        "    'mask_image': '',\n",
        "    'num_inference_steps': 500,\n",
        "    'eta': 0.0,\n",
        "    'jump_length': 10,\n",
        "    'jump_n_sample': 10,\n",
        "    'seed': 0,\n",
        "    'file_name': '',\n",
        "    'max_size': 1024,\n",
        "    'invert_mask': False,\n",
        "}\n",
        "def buildRepainter(page):\n",
        "    global repaint_prefs, prefs, pipe_repaint\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "      if pref is not None:\n",
        "        if ptype == \"int\":\n",
        "          repaint_prefs[pref] = int(e.control.value)\n",
        "        elif ptype == \"float\":\n",
        "          repaint_prefs[pref] = float(e.control.value)\n",
        "        else:\n",
        "          repaint_prefs[pref] = e.control.value\n",
        "    def add_to_repaint_output(o):\n",
        "      page.repaint_output.controls.append(o)\n",
        "      page.repaint_output.update()\n",
        "      if not clear_button.visible:\n",
        "        clear_button.visible = True\n",
        "        clear_button.update()\n",
        "    def clear_output(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      page.repaint_output.controls = []\n",
        "      page.repaint_output.update()\n",
        "      clear_button.visible = False\n",
        "      clear_button.update()\n",
        "    def repaint_help(e):\n",
        "      def close_repaint_dlg(e):\n",
        "        nonlocal repaint_help_dlg\n",
        "        repaint_help_dlg.open = False\n",
        "        page.update()\n",
        "      repaint_help_dlg = AlertDialog(title=Text(\"üíÅ   Help with Repainter\"), content=Column([\n",
        "          Text(\"It's difficult to explain exactly what all these parameters do, but keep it close to defaults, keep prompt simple, or experiment to see what's what, we don't know.\"),\n",
        "        ], scroll=ScrollMode.AUTO), actions=[TextButton(\"üò™  Okay then... \", on_click=close_repaint_dlg)], actions_alignment=MainAxisAlignment.END)\n",
        "      page.dialog = repaint_help_dlg\n",
        "      repaint_help_dlg.open = True\n",
        "      page.update()\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "          upload_files(e)\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "      nonlocal pick_type\n",
        "      if e.progress == 1:\n",
        "        repaint_prefs['file_name'] = e.file_name.rpartition('.')[0]\n",
        "        fname = os.path.join(root_dir, e.file_name)\n",
        "        if pick_type == \"original\":\n",
        "          original_image.value = fname\n",
        "          original_image.update()\n",
        "          repaint_prefs['original_image'] = fname\n",
        "        elif pick_type == \"mask\":\n",
        "          mask_image.value = fname\n",
        "          mask_image.update()\n",
        "          repaint_prefs['mask_image'] = fname\n",
        "        page.update()\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    page.overlay.append(file_picker)\n",
        "    pick_type = \"\"\n",
        "    #page.overlay.append(pick_files_dialog)\n",
        "    def pick_original(e):\n",
        "        nonlocal pick_type\n",
        "        pick_type = \"original\"\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\", \"jpg\", \"jpeg\"], dialog_title=\"Pick Original Image File\")\n",
        "    def pick_mask(e):\n",
        "        nonlocal pick_type\n",
        "        pick_type = \"mask\"\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\", \"jpg\", \"jpeg\"], dialog_title=\"Pick Black & White Mask Image\")\n",
        "    original_image = TextField(label=\"Original Image\", value=repaint_prefs['original_image'], expand=1, on_change=lambda e:changed(e,'original_image'), height=60, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_original))\n",
        "    mask_image = TextField(label=\"Mask Image\", value=repaint_prefs['mask_image'], expand=1, on_change=lambda e:changed(e,'mask_image'), height=60, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD_OUTLINED, on_click=pick_mask))\n",
        "    invert_mask = Checkbox(label=\"Invert\", tooltip=\"Swaps the Black & White of your Mask Image\", value=repaint_prefs['invert_mask'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'invert_mask'))\n",
        "    jump_length = TextField(label=\"Jump Length\", tooltip=\"The number of steps taken forward in time before going backward in time for a single jump\", value=repaint_prefs['jump_length'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'jump_length', ptype='int'))\n",
        "    jump_n_sample = TextField(label=\"Jump Number of Sample\", tooltip=\"The number of times we will make forward time jump for a given chosen time sample.\", value=repaint_prefs['jump_n_sample'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'jump_n_sample', ptype='int'))\n",
        "    seed = TextField(label=\"Seed\", value=str(repaint_prefs['seed']), keyboard_type=KeyboardType.NUMBER, tooltip=\"0 or -1 picks a Random seed\", on_change=lambda e:changed(e,'seed', ptype='int'))\n",
        "    #num_inference_steps = TextField(label=\"Inference Steps\", value=str(repaint_prefs['num_inference_steps']), keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'num_inference_steps', ptype='int'))\n",
        "    num_inference_steps = Slider(min=10, max=3000, divisions=2990, label=\"{value}\", value=float(repaint_prefs['num_inference_steps']), tooltip=\"The number of denoising steps. More denoising steps usually lead to a higher quality image at the expense of slower inference.\", expand=True, on_change=lambda e:changed(e,'num_inference_steps', ptype='int'))\n",
        "    num_inference_row = Row([Text(\"Number of Inference Steps: \"), num_inference_steps])\n",
        "    #eta = TextField(label=\"ETA\", value=str(repaint_prefs['eta']), keyboard_type=KeyboardType.NUMBER, hint_text=\"Amount of Noise\", on_change=lambda e:changed(e,'eta', ptype='float'))\n",
        "    eta = Slider(min=0.0, max=1.0, divisions=20, label=\"{value}\", value=float(repaint_prefs['eta']), tooltip=\"The weight of noise for added noise in a diffusion step. Its value is between 0.0 and 1.0 - 0.0 is DDIM and 1.0 is DDPM scheduler respectively.\", expand=True, on_change=lambda e:changed(e,'eta', ptype='float'))\n",
        "    eta_row = Row([Text(\"ETA:    DDIM\"), eta, Text(\"DDPM\")])\n",
        "    max_size = Slider(min=256, max=1280, divisions=64, label=\"{value}px\", value=float(repaint_prefs['max_size']), expand=True, on_change=lambda e:changed(e,'max_size', ptype='int'))\n",
        "    max_row = Row([Text(\"Max Resolution Size: \"), max_size])\n",
        "    page.repaint_output = Column([])\n",
        "    clear_button = Row([ElevatedButton(content=Text(\"‚ùå   Clear Output\"), on_click=clear_output)], alignment=MainAxisAlignment.END)\n",
        "    clear_button.visible = len(page.repaint_output.controls) > 0\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Row([Text(\"üíÖ  Repaint masked areas of an image\", style=TextThemeStyle.TITLE_LARGE), IconButton(icon=icons.HELP, tooltip=\"Help with Repainter Settings\", on_click=repaint_help)], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Text(\"Fills in areas of picture with what it thinks it should be, without a prompt...\"),\n",
        "        Divider(thickness=1, height=4),\n",
        "        Row([original_image, mask_image, invert_mask]),\n",
        "        num_inference_row,\n",
        "        eta_row,\n",
        "        max_row,\n",
        "        Row([jump_length, jump_n_sample, seed]),\n",
        "        ElevatedButton(content=Text(\"üñåÔ∏è  Run Repainter\", size=18), on_click=lambda _: run_repainter(page)),\n",
        "        page.repaint_output,\n",
        "        clear_button,\n",
        "      ]\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "image_variation_prefs = {\n",
        "    'init_image': '',\n",
        "    'guidance_scale': 7.5,\n",
        "    'num_inference_steps': 50,\n",
        "    'eta': 0.4,\n",
        "    'seed': 0,\n",
        "    'num_images': 1,\n",
        "    'file_name': '',\n",
        "    'max_size': 1024,\n",
        "    'width': 960,\n",
        "    'height': 512,\n",
        "}\n",
        "def buildImageVariation(page):\n",
        "    global image_variation_prefs, prefs, pipe_image_variation\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "      if pref is not None:\n",
        "        if ptype == \"int\":\n",
        "          image_variation_prefs[pref] = int(e.control.value)\n",
        "        elif ptype == \"float\":\n",
        "          image_variation_prefs[pref] = float(e.control.value)\n",
        "        else:\n",
        "          image_variation_prefs[pref] = e.control.value\n",
        "    def add_to_image_variation_output(o):\n",
        "      page.image_variation_output.controls.append(o)\n",
        "      page.image_variation_output.update()\n",
        "      if not clear_button.visible:\n",
        "        clear_button.visible = True\n",
        "        clear_button.update()\n",
        "    page.add_to_image_variation_output = add_to_image_variation_output\n",
        "    def clear_output(e):\n",
        "      if prefs['enable_sounds']: page.snd_delete.play()\n",
        "      page.image_variation_output.controls = []\n",
        "      page.image_variation_output.update()\n",
        "      clear_button.visible = False\n",
        "      clear_button.update()\n",
        "    def image_variation_help(e):\n",
        "      def close_image_variation_dlg(e):\n",
        "        nonlocal image_variation_help_dlg\n",
        "        image_variation_help_dlg.open = False\n",
        "        page.update()\n",
        "      image_variation_help_dlg = AlertDialog(title=Text(\"üôÖ   Help with Image Variations\"), content=Column([\n",
        "          Text(\"Give it any of your favorite images and create variations of it.... Simple as that, no prompt needed.\"),\n",
        "        ], scroll=ScrollMode.AUTO), actions=[TextButton(\"ü§ó  Sounds Fun... \", on_click=close_image_variation_dlg)], actions_alignment=MainAxisAlignment.END)\n",
        "      page.dialog = image_variation_help_dlg\n",
        "      image_variation_help_dlg.open = True\n",
        "      page.update()\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "          upload_files(e)\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "      if e.progress == 1:\n",
        "        image_variation_prefs['file_name'] = e.file_name.rpartition('.')[0]\n",
        "        fname = os.path.join(root_dir, e.file_name)\n",
        "        init_image.value = fname\n",
        "        init_image.update()\n",
        "        image_variation_prefs['init_image'] = fname\n",
        "        page.update()\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    page.overlay.append(file_picker)\n",
        "    def pick_init(e):\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\", \"jpg\", \"jpeg\"], dialog_title=\"Pick init Image File\")\n",
        "    def change_guidance(e):\n",
        "      guidance_value.value = f\" {e.control.value}\"\n",
        "      guidance_value.update()\n",
        "      #guidance.controls[1].value = f\" {e.control.value}\"\n",
        "      guidance.update()\n",
        "      changed(e, 'guidance_scale', ptype=\"float\")\n",
        "    guidance_scale = Slider(min=0, max=50, divisions=100, label=\"{value}\", value=image_variation_prefs['guidance_scale'], on_change=change_guidance, expand=True)\n",
        "    guidance_value = Text(f\" {image_variation_prefs['guidance_scale']}\", weight=FontWeight.BOLD)\n",
        "    guidance = Row([Text(\"Guidance Scale: \"), guidance_value, guidance_scale])\n",
        "    init_image = TextField(label=\"Initial Image\", value=image_variation_prefs['init_image'], on_change=lambda e:changed(e,'init_image'), height=60, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_init))\n",
        "    seed = TextField(label=\"Seed\", width=90, value=str(image_variation_prefs['seed']), keyboard_type=KeyboardType.NUMBER, tooltip=\"0 or -1 picks a Random seed\", on_change=lambda e:changed(e,'seed', ptype='int'))\n",
        "    \n",
        "    #num_inference_steps = TextField(label=\"Inference Steps\", value=str(image_variation_prefs['num_inference_steps']), keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'num_inference_steps', ptype='int'))\n",
        "    num_inference_steps = Slider(min=1, max=100, divisions=99, label=\"{value}\", value=int(image_variation_prefs['num_inference_steps']), tooltip=\"The number of denoising steps. More denoising steps usually lead to a higher quality image at the expense of slower inference.\", expand=True, on_change=lambda e:changed(e,'num_inference_steps', ptype='int'))\n",
        "    num_inference_row = Row([Text(\"Number of Inference Steps: \"), num_inference_steps])\n",
        "    #eta = TextField(label=\"ETA\", value=str(image_variation_prefs['eta']), keyboard_type=KeyboardType.NUMBER, hint_text=\"Amount of Noise\", on_change=lambda e:changed(e,'eta', ptype='float'))\n",
        "    eta = Slider(min=0.0, max=1.0, divisions=20, label=\"{value}\", value=float(image_variation_prefs['eta']), tooltip=\"The weight of noise for added noise in a diffusion step. Its value is between 0.0 and 1.0 - 0.0 is DDIM and 1.0 is DDPM scheduler respectively.\", expand=True, on_change=lambda e:changed(e,'eta', ptype='float'))\n",
        "    eta_row = Row([Text(\"DDIM ETA: \"), eta])\n",
        "    max_size = Slider(min=256, max=1280, divisions=64, label=\"{value}px\", value=int(image_variation_prefs['max_size']), expand=True, on_change=lambda e:changed(e,'max_size', ptype='int'))\n",
        "    max_row = Row([Text(\"Max Resolution Size: \"), max_size])\n",
        "    page.image_variation_output = Column([])\n",
        "    clear_button = Row([ElevatedButton(content=Text(\"‚ùå   Clear Output\"), on_click=clear_output)], alignment=MainAxisAlignment.END)\n",
        "    clear_button.visible = len(page.image_variation_output.controls) > 0\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Row([Text(\"ü™©  Image Variations of any Init Image\", style=TextThemeStyle.TITLE_LARGE), IconButton(icon=icons.HELP, tooltip=\"Help with Image Variation Settings\", on_click=image_variation_help)], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Text(\"Creates a new version of your picture, without a prompt...\"),\n",
        "        Divider(thickness=1, height=4),\n",
        "        init_image,\n",
        "        #Row([init_image, mask_image, invert_mask]),\n",
        "        num_inference_row,\n",
        "        guidance,\n",
        "        eta_row,\n",
        "        max_row,\n",
        "        Row([NumberPicker(label=\"Number of Images: \", min=1, max=8, value=image_variation_prefs['num_images'], on_change=lambda e: changed(e, 'num_images')), seed]),\n",
        "        ElevatedButton(content=Text(\"üñçÔ∏è  Get Image Variation\", size=18), on_click=lambda _: run_image_variation(page)),\n",
        "        page.image_variation_output,\n",
        "        clear_button,\n",
        "      ]\n",
        "    ))], scroll=ScrollMode.AUTO, auto_scroll=True)\n",
        "    return c\n",
        "\n",
        "materialdiffusion_prefs = {\n",
        "    \"material_prompt\": '',\n",
        "    \"batch_folder_name\": '',\n",
        "    \"file_prefix\": \"material-\",\n",
        "    \"num_outputs\": 1,\n",
        "    \"steps\":50,\n",
        "    \"eta\":0.4,\n",
        "    \"width\": 512,\n",
        "    \"height\":512,\n",
        "    \"guidance_scale\":7.5,\n",
        "    \"seed\":0,\n",
        "    \"init_image\": '',\n",
        "    \"prompt_strength\": 0.5,\n",
        "    \"mask_image\": '',\n",
        "    \"invert_mask\": False,\n",
        "    \"apply_ESRGAN_upscale\": prefs['apply_ESRGAN_upscale'],\n",
        "    \"enlarge_scale\": prefs['enlarge_scale'],\n",
        "    #\"face_enhance\": prefs['face_enhance'],\n",
        "    \"display_upscaled_image\": prefs['display_upscaled_image'],\n",
        "}\n",
        "\n",
        "def buildMaterialDiffusion(page):\n",
        "    global prefs, materialdiffusion_prefs, status\n",
        "\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "      if pref is not None:\n",
        "        if ptype == \"int\":\n",
        "          materialdiffusion_prefs[pref] = int(e.control.value)\n",
        "        elif ptype == \"float\":\n",
        "          materialdiffusion_prefs[pref] = float(e.control.value)\n",
        "        else:\n",
        "          materialdiffusion_prefs[pref] = e.control.value\n",
        "    def pick_files_result(e: FilePickerResultEvent):\n",
        "        if e.files:\n",
        "            img = e.files\n",
        "            uf = []\n",
        "            fname = img[0]\n",
        "            print(\", \".join(map(lambda f: f.name, e.files)))\n",
        "            src_path = page.get_upload_url(fname.name, 600)\n",
        "            uf.append(FilePickerUploadFile(fname.name, upload_url=src_path))\n",
        "            pick_files_dialog.upload(uf)\n",
        "            print(str(src_path))\n",
        "            #src_path = ''.join(src_path)\n",
        "            print(str(uf[0]))\n",
        "            dst_path = os.path.join(root_dir, fname.name)\n",
        "            print(f'Copy {src_path} to {dst_path}')\n",
        "            #shutil.copy(src_path, dst_path)\n",
        "            # TODO: is init or mask?\n",
        "            init_image.value = dst_path\n",
        "\n",
        "    pick_files_dialog = FilePicker(on_result=pick_files_result)\n",
        "    page.overlay.append(pick_files_dialog)\n",
        "    #selected_files = Text()\n",
        "\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "            upload_files(e)\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "        nonlocal pick_type\n",
        "        if e.progress == 1:\n",
        "            fname = os.path.join(root_dir, e.file_name)\n",
        "            if pick_type == \"init\":\n",
        "                init_image.value = fname\n",
        "                init_image.update()\n",
        "                materialdiffusion_prefs['init_image'] = fname\n",
        "            elif pick_type == \"mask\":\n",
        "                mask_image.value = fname\n",
        "                mask_image.update()\n",
        "                materialdiffusion_prefs['mask_image'] = fname\n",
        "            page.update()\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    page.overlay.append(file_picker)\n",
        "    pick_type = \"\"\n",
        "    #page.overlay.append(pick_files_dialog)\n",
        "    def pick_init(e):\n",
        "        nonlocal pick_type\n",
        "        pick_type = \"init\"\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Init Image File\")\n",
        "    def pick_mask(e):\n",
        "        nonlocal pick_type\n",
        "        pick_type = \"mask\"\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Black & White Mask Image\")\n",
        "    def toggle_ESRGAN(e):\n",
        "        ESRGAN_settings.height = None if e.control.value else 0\n",
        "        materialdiffusion_prefs['apply_ESRGAN_upscale'] = e.control.value\n",
        "        ESRGAN_settings.update()\n",
        "        has_changed = True\n",
        "    def change_guidance(e):\n",
        "        guidance_value.value = f\" {e.control.value}\"\n",
        "        guidance_value.update()\n",
        "        #guidance.controls[1].value = f\" {e.control.value}\"\n",
        "        guidance.update()\n",
        "        changed(e, 'guidance_scale')\n",
        "    def change_width(e):\n",
        "        width_slider.controls[1].value = f\" {int(e.control.value)}px\"\n",
        "        width_slider.update()\n",
        "        changed(e, 'width', ptype=\"int\")\n",
        "    def change_height(e):\n",
        "        height_slider.controls[1].value = f\" {int(e.control.value)}px\"\n",
        "        height_slider.update()\n",
        "        changed(e, 'height', ptype=\"int\")\n",
        "    def change_enlarge_scale(e):\n",
        "        enlarge_scale_slider.controls[1].value = f\" {float(e.control.value)}x\"\n",
        "        enlarge_scale_slider.update()\n",
        "        changed(e, 'enlarge_scale', ptype=\"float\")\n",
        "    def change_strength(e):\n",
        "        strength_value.value = f\" {int(e.control.value * 100)}\"\n",
        "        strength_value.update()\n",
        "        guidance.update()\n",
        "        changed(e, 'prompt_strength', ptype=\"float\")\n",
        "\n",
        "    material_prompt = TextField(label=\"Material Prompt\", value=materialdiffusion_prefs['material_prompt'], on_change=lambda e:changed(e,'material_prompt'))\n",
        "    batch_folder_name = TextField(label=\"Batch Folder Name\", value=materialdiffusion_prefs['batch_folder_name'], on_change=lambda e:changed(e,'batch_folder_name'))\n",
        "    file_prefix = TextField(label=\"Filename Prefix\", value=materialdiffusion_prefs['file_prefix'], on_change=lambda e:changed(e,'file_prefix'))\n",
        "    #num_outputs = NumberPicker(label=\"Num of Outputs\", min=1, max=4, step=4, value=materialdiffusion_prefs['num_outputs'], on_change=lambda e:changed(e,'num_outputs', ptype=\"int\"))\n",
        "    #num_outputs = TextField(label=\"num_outputs\", value=materialdiffusion_prefs['num_outputs'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'num_outputs', ptype=\"int\"))\n",
        "    #n_iterations = TextField(label=\"Number of Iterations\", value=materialdiffusion_prefs['n_iterations'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'n_iterations', ptype=\"int\"))\n",
        "    steps = TextField(label=\"Inference Steps\", value=materialdiffusion_prefs['steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'steps', ptype=\"int\"))\n",
        "    eta = TextField(label=\"DDIM ETA\", value=materialdiffusion_prefs['eta'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'eta', ptype=\"float\"))\n",
        "    seed = TextField(label=\"Seed\", value=materialdiffusion_prefs['seed'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'seed', ptype=\"int\"))\n",
        "    param_rows = ResponsiveRow([Column([batch_folder_name, file_prefix, NumberPicker(label=\"Output Images\", min=1, max=4, step=3, value=materialdiffusion_prefs['num_outputs'], on_change=lambda e:changed(e,'num_outputs', ptype=\"int\"))], col={'xs':12, 'md':6}), \n",
        "                      Column([steps, eta, seed], col={'xs':12, 'md':6})])\n",
        "    guidance_scale = Slider(min=0, max=50, divisions=100, label=\"{value}\", value=materialdiffusion_prefs['guidance_scale'], on_change=change_guidance, expand=True)\n",
        "    guidance_value = Text(f\" {materialdiffusion_prefs['guidance_scale']}\", weight=FontWeight.BOLD)\n",
        "    guidance = Row([Text(\"Guidance Scale: \"), guidance_value, guidance_scale])\n",
        "    width = Slider(min=128, max=1024, divisions=14, label=\"{value}px\", value=materialdiffusion_prefs['width'], on_change=change_width, expand=True)\n",
        "    width_value = Text(f\" {int(materialdiffusion_prefs['width'])}px\", weight=FontWeight.BOLD)\n",
        "    width_slider = Row([Text(f\"Width: \"), width_value, width])\n",
        "    height = Slider(min=128, max=1024, divisions=14, label=\"{value}px\", value=materialdiffusion_prefs['height'], on_change=change_height, expand=True)\n",
        "    height_value = Text(f\" {int(materialdiffusion_prefs['height'])}px\", weight=FontWeight.BOLD)\n",
        "    height_slider = Row([Text(f\"Height: \"), height_value, height])\n",
        "\n",
        "    init_image = TextField(label=\"Init Image\", value=materialdiffusion_prefs['init_image'], on_change=lambda e:changed(e,'init_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_init), col={'xs':12, 'md':6})\n",
        "    mask_image = TextField(label=\"Mask Image\", value=materialdiffusion_prefs['mask_image'], on_change=lambda e:changed(e,'mask_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD_OUTLINED, on_click=pick_mask), col={'xs':10, 'md':5})\n",
        "    invert_mask = Checkbox(label=\"Invert\", tooltip=\"Swaps the Black & White of your Mask Image\", value=materialdiffusion_prefs['invert_mask'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'invert_mask'), col={'xs':2, 'md':1})\n",
        "    image_pickers = Container(content=ResponsiveRow([init_image, mask_image, invert_mask]), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    prompt_strength = Slider(min=0.1, max=0.9, divisions=16, label=\"{value}%\", value=materialdiffusion_prefs['prompt_strength'], on_change=change_strength, expand=True)\n",
        "    strength_value = Text(f\" {int(materialdiffusion_prefs['prompt_strength'] * 100)}%\", weight=FontWeight.BOLD)\n",
        "    strength_slider = Row([Text(\"Prompt Strength: \"), strength_value, prompt_strength])\n",
        "    img_block = Container(Column([image_pickers, strength_slider, Divider(height=9, thickness=2)]), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    apply_ESRGAN_upscale = Switch(label=\"Apply ESRGAN Upscale\", value=materialdiffusion_prefs['apply_ESRGAN_upscale'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_ESRGAN)\n",
        "    enlarge_scale_value = Text(f\" {float(materialdiffusion_prefs['enlarge_scale'])}x\", weight=FontWeight.BOLD)\n",
        "    enlarge_scale = Slider(min=1, max=4, divisions=6, label=\"{value}x\", value=materialdiffusion_prefs['enlarge_scale'], on_change=change_enlarge_scale, expand=True)\n",
        "    enlarge_scale_slider = Row([Text(\"Enlarge Scale: \"), enlarge_scale_value, enlarge_scale])\n",
        "    #face_enhance = Checkbox(label=\"Use Face Enhance GPFGAN\", value=materialdiffusion_prefs['face_enhance'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'face_enhance'))\n",
        "    display_upscaled_image = Checkbox(label=\"Display Upscaled Image\", value=materialdiffusion_prefs['display_upscaled_image'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'display_upscaled_image'))\n",
        "    ESRGAN_settings = Container(Column([enlarge_scale_slider, display_upscaled_image], spacing=0), padding=padding.only(left=32), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    page.ESRGAN_block_material = Container(Column([apply_ESRGAN_upscale, ESRGAN_settings]), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    page.ESRGAN_block_material.height = None if status['installed_ESRGAN'] else 0\n",
        "    if not materialdiffusion_prefs['apply_ESRGAN_upscale']:\n",
        "        ESRGAN_settings.height = 0\n",
        "    parameters_button = ElevatedButton(content=Text(value=\"üí®   Run Material Diffusion\", size=20), on_click=lambda _: run_materialdiffusion(page))\n",
        "\n",
        "    parameters_row = Row([parameters_button], alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "    page.materialdiffusion_output = Column([])\n",
        "    c = Column([Container(\n",
        "        padding=padding.only(18, 14, 20, 10), content=Column([\n",
        "            Text (\"üß±  Replicate Material Diffusion\", style=TextThemeStyle.TITLE_LARGE),\n",
        "            Text (\"Create Seamless Tiled Textures with your Prompt. Requires account at Replicate.com and your Key.\"),\n",
        "            Divider(thickness=1, height=4),\n",
        "            material_prompt,\n",
        "            param_rows, guidance, width_slider, height_slider, #Divider(height=9, thickness=2), \n",
        "            img_block, page.ESRGAN_block_material,\n",
        "            #(img_block if status['installed_img2img'] or status['installed_stability'] else Container(content=None)), (clip_block if prefs['install_CLIP_guided'] else Container(content=None)), (ESRGAN_block if prefs['install_ESRGAN'] else Container(content=None)), \n",
        "            parameters_row,\n",
        "            page.materialdiffusion_output\n",
        "        ],\n",
        "    ))], scroll=ScrollMode.AUTO)#batch_folder_name, batch_size, n_iterations, steps, eta, seed, \n",
        "    return c\n",
        "\n",
        "dall_e_prefs = {\n",
        "    'prompt': '',\n",
        "    'size': '512x512',\n",
        "    'num_images': 1,\n",
        "    'init_image': '',\n",
        "    'mask_image': '',\n",
        "    'variation': False,\n",
        "    \"invert_mask\": False,\n",
        "    'file_prefix': 'dalle-',\n",
        "    \"apply_ESRGAN_upscale\": prefs['apply_ESRGAN_upscale'],\n",
        "    \"enlarge_scale\": prefs['enlarge_scale'],\n",
        "    \"face_enhance\": prefs['face_enhance'],\n",
        "    \"display_upscaled_image\": prefs['display_upscaled_image'],\n",
        "    \"batch_folder_name\": '',\n",
        "}\n",
        "\n",
        "def buildDallE2(page):\n",
        "    global dall_e_prefs\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "      if pref is not None:\n",
        "        if ptype == \"int\":\n",
        "          dall_e_prefs[pref] = int(e.control.value)\n",
        "        elif ptype == \"float\":\n",
        "          dall_e_prefs[pref] = float(e.control.value)\n",
        "        else:\n",
        "          dall_e_prefs[pref] = e.control.value\n",
        "    def pick_files_result(e: FilePickerResultEvent):\n",
        "        if e.files:\n",
        "            img = e.files\n",
        "            dalle = []\n",
        "            fname = img[0]\n",
        "            print(\", \".join(map(lambda f: f.name, e.files)))\n",
        "            src_path = page.get_upload_url(fname.name, 600)\n",
        "            dalle.append(FilePickerUploadFile(fname.name, upload_url=src_path))\n",
        "            pick_files_dialog.upload(dalle)\n",
        "            print(str(src_path))\n",
        "            #src_path = ''.join(src_path)\n",
        "            print(str(dalle[0]))\n",
        "            dst_path = os.path.join(root_dir, fname.name)\n",
        "            print(f'Copy {src_path} to {dst_path}')\n",
        "            #shutil.copy(src_path, dst_path)\n",
        "            # TODO: is init or mask?\n",
        "            init_image.value = dst_path\n",
        "\n",
        "    pick_files_dialog = FilePicker(on_result=pick_files_result)\n",
        "    page.overlay.append(pick_files_dialog)\n",
        "    #selected_files = Text()\n",
        "\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "            upload_files(e)\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "        nonlocal pick_type\n",
        "        if e.progress == 1:\n",
        "            fname = os.path.join(root_dir, e.file_name)\n",
        "            if pick_type == \"init\":\n",
        "                init_image.value = fname\n",
        "                init_image.update()\n",
        "                dall_e_prefs['init_image'] = fname\n",
        "            elif pick_type == \"mask\":\n",
        "                mask_image.value = fname\n",
        "                mask_image.update()\n",
        "                dall_e_prefs['mask_image'] = fname\n",
        "            page.update()\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def upload_files(e):\n",
        "        dalle = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                dalle.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(dalle)\n",
        "    page.overlay.append(file_picker)\n",
        "    pick_type = \"\"\n",
        "    #page.overlay.append(pick_files_dialog)\n",
        "    def pick_init(e):\n",
        "        nonlocal pick_type\n",
        "        pick_type = \"init\"\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Init Image File\")\n",
        "    def pick_mask(e):\n",
        "        nonlocal pick_type\n",
        "        pick_type = \"mask\"\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Black & White Mask Image\")\n",
        "    def toggle_ESRGAN(e):\n",
        "        ESRGAN_settings.height = None if e.control.value else 0\n",
        "        dall_e_prefs['apply_ESRGAN_upscale'] = e.control.value\n",
        "        ESRGAN_settings.update()\n",
        "        has_changed = True\n",
        "    def change_enlarge_scale(e):\n",
        "        enlarge_scale_slider.controls[1].value = f\" {float(e.control.value)}x\"\n",
        "        enlarge_scale_slider.update()\n",
        "        changed(e, 'enlarge_scale', ptype=\"float\")\n",
        "\n",
        "    prompt = TextField(label=\"Prompt Text\", value=dall_e_prefs['prompt'], on_change=lambda e:changed(e,'prompt'))\n",
        "    batch_folder_name = TextField(label=\"Batch Folder Name\", value=dall_e_prefs['batch_folder_name'], on_change=lambda e:changed(e,'batch_folder_name'))\n",
        "    file_prefix = TextField(label=\"Filename Prefix\", value=dall_e_prefs['file_prefix'], on_change=lambda e:changed(e,'file_prefix'))\n",
        "    #num_images = NumberPicker(label=\"Num of Outputs\", min=1, max=4, step=4, value=dall_e_prefs['num_images'], on_change=lambda e:changed(e,'num_images', ptype=\"int\"))\n",
        "    #num_images = TextField(label=\"num_images\", value=dall_e_prefs['num_images'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'num_images', ptype=\"int\"))\n",
        "    #n_iterations = TextField(label=\"Number of Iterations\", value=dall_e_prefs['n_iterations'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'n_iterations', ptype=\"int\"))\n",
        "    #steps = TextField(label=\"Inference Steps\", value=dall_e_prefs['steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'steps', ptype=\"int\"))\n",
        "    #eta = TextField(label=\"DDIM ETA\", value=dall_e_prefs['eta'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'eta', ptype=\"float\"))\n",
        "    #seed = TextField(label=\"Seed\", value=dall_e_prefs['seed'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'seed', ptype=\"int\"))\n",
        "    size = Dropdown(label=\"Image Size\", width=180, options=[dropdown.Option(\"256x256\"), dropdown.Option(\"512x512\"), dropdown.Option(\"1024x1024\")], value=dall_e_prefs['size'], on_change=lambda e:changed(e,'size'))\n",
        "    param_rows = Row([Row([batch_folder_name, file_prefix, size, NumberPicker(label=\"Number of Images\", min=1, max=10, step=1, value=dall_e_prefs['num_images'], on_change=lambda e:changed(e,'num_images', ptype=\"int\"))])])\n",
        "    \n",
        "    #width = Slider(min=128, max=1024, divisions=6, label=\"{value}px\", value=dall_e_prefs['width'], on_change=change_width, expand=True)\n",
        "    #width_value = Text(f\" {int(dall_e_prefs['width'])}px\", weight=FontWeight.BOLD)\n",
        "    #width_slider = Row([Text(f\"Width: \"), width_value, width])\n",
        "    #height = Slider(min=128, max=1024, divisions=6, label=\"{value}px\", value=dall_e_prefs['height'], on_change=change_height, expand=True)\n",
        "    #height_value = Text(f\" {int(dall_e_prefs['height'])}px\", weight=FontWeight.BOLD)\n",
        "    #height_slider = Row([Text(f\"Height: \"), height_value, height])\n",
        "    init_image = TextField(label=\"Init Image\", value=dall_e_prefs['init_image'], on_change=lambda e:changed(e,'init_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_init, col={\"*\":1, \"md\":3}))\n",
        "    mask_image = TextField(label=\"Mask Image\", value=dall_e_prefs['mask_image'], on_change=lambda e:changed(e,'mask_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD_OUTLINED, on_click=pick_mask, col={\"*\":1, \"md\":3}))\n",
        "    variation = Checkbox(label=\"Variation   \", tooltip=\"Creates Variation of Init Image. Disregards the Prompt and Mask.\", value=dall_e_prefs['variation'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'variation'))\n",
        "    invert_mask = Checkbox(label=\"Invert\", tooltip=\"Swaps the Black & White of your Mask Image\", value=dall_e_prefs['invert_mask'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'invert_mask'))\n",
        "    image_pickers = Container(content=ResponsiveRow([Row([init_image, variation], col={\"md\":6}), Row([mask_image, invert_mask], col={\"md\":6})], run_spacing=2), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    #prompt_strength = Slider(min=0.1, max=0.9, divisions=16, label=\"{value}%\", value=dall_e_prefs['prompt_strength'], on_change=change_strength, expand=True)\n",
        "    #strength_value = Text(f\" {int(dall_e_prefs['prompt_strength'] * 100)}%\", weight=FontWeight.BOLD) \n",
        "    #strength_slider = Row([Text(\"Prompt Strength: \"), strength_value, prompt_strength])\n",
        "    img_block = Container(Column([image_pickers, Divider(height=9, thickness=2)]), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    apply_ESRGAN_upscale = Switch(label=\"Apply ESRGAN Upscale\", value=dall_e_prefs['apply_ESRGAN_upscale'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_ESRGAN)\n",
        "    enlarge_scale_value = Text(f\" {float(dall_e_prefs['enlarge_scale'])}x\", weight=FontWeight.BOLD)\n",
        "    enlarge_scale = Slider(min=1, max=4, divisions=6, label=\"{value}x\", value=dall_e_prefs['enlarge_scale'], on_change=change_enlarge_scale, expand=True)\n",
        "    enlarge_scale_slider = Row([Text(\"Enlarge Scale: \"), enlarge_scale_value, enlarge_scale])\n",
        "    face_enhance = Checkbox(label=\"Use Face Enhance GPFGAN\", value=dall_e_prefs['face_enhance'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'face_enhance'))\n",
        "    display_upscaled_image = Checkbox(label=\"Display Upscaled Image\", value=dall_e_prefs['display_upscaled_image'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'display_upscaled_image'))\n",
        "    ESRGAN_settings = Container(Column([enlarge_scale_slider, face_enhance, display_upscaled_image], spacing=0), padding=padding.only(left=32), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    page.ESRGAN_block_dalle = Container(Column([apply_ESRGAN_upscale, ESRGAN_settings]), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    page.ESRGAN_block_dalle.height = None if status['installed_ESRGAN'] else 0\n",
        "    if not dall_e_prefs['apply_ESRGAN_upscale']:\n",
        "        ESRGAN_settings.height = 0\n",
        "    list_button = ElevatedButton(content=Text(value=\"üìú   Run from Prompts List\", size=20), on_click=lambda _: run_dall_e(page, from_list=True))\n",
        "    parameters_button = ElevatedButton(content=Text(value=\"üñºÔ∏è   Run Dall-E 2\", size=20), on_click=lambda _: run_dall_e(page))\n",
        "\n",
        "    parameters_row = Row([parameters_button, list_button], spacing=22)#, alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "    page.dall_e_output = Column([])\n",
        "    c = Column([Container(\n",
        "        padding=padding.only(18, 14, 20, 10), content=Column([\n",
        "            Text (\"üë∫  OpenAI Dall-E 2\", style=TextThemeStyle.TITLE_LARGE),\n",
        "            Text (\"Generates Images using your OpenAI API Key. Note: Uses same credits as official website.\"),\n",
        "            Divider(thickness=1, height=4),\n",
        "            prompt,\n",
        "            param_rows,\n",
        "            img_block, page.ESRGAN_block_dalle,\n",
        "            #(img_block if status['installed_img2img'] or status['installed_stability'] else Container(content=None)), (clip_block if prefs['install_CLIP_guided'] else Container(content=None)), (ESRGAN_block if prefs['install_ESRGAN'] else Container(content=None)), \n",
        "            parameters_row,\n",
        "            page.dall_e_output\n",
        "        ],\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "kandinsky_prefs = {\n",
        "    \"prompt\": '',\n",
        "    \"batch_folder_name\": '',\n",
        "    \"file_prefix\": \"kandinsky-\",\n",
        "    \"num_images\": 1,\n",
        "    \"steps\":100,\n",
        "    \"ddim_eta\":0.05,\n",
        "    \"width\": 512,\n",
        "    \"height\":512,\n",
        "    \"guidance_scale\":8,\n",
        "    \"dynamic_threshold_v\":99.5,\n",
        "    \"sampler\": \"ddim_sampler\",\n",
        "    \"denoised_type\": \"dynamic_threshold\",\n",
        "    \"init_image\": '',\n",
        "    \"strength\": 0.5,\n",
        "    \"mask_image\": '',\n",
        "    \"invert_mask\": False,\n",
        "    \"apply_ESRGAN_upscale\": prefs['apply_ESRGAN_upscale'],\n",
        "    \"enlarge_scale\": prefs['enlarge_scale'],\n",
        "    \"face_enhance\": prefs['face_enhance'],\n",
        "    \"display_upscaled_image\": prefs['display_upscaled_image'],\n",
        "}\n",
        "\n",
        "def buildKandinsky(page):\n",
        "    global prefs, kandinsky_prefs, status\n",
        "\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "      if pref is not None:\n",
        "        if ptype == \"int\":\n",
        "          kandinsky_prefs[pref] = int(e.control.value)\n",
        "        elif ptype == \"float\":\n",
        "          kandinsky_prefs[pref] = float(e.control.value)\n",
        "        else:\n",
        "          kandinsky_prefs[pref] = e.control.value\n",
        "    def pick_files_result(e: FilePickerResultEvent):\n",
        "        if e.files:\n",
        "            img = e.files\n",
        "            uf = []\n",
        "            fname = img[0]\n",
        "            print(\", \".join(map(lambda f: f.name, e.files)))\n",
        "            src_path = page.get_upload_url(fname.name, 600)\n",
        "            uf.append(FilePickerUploadFile(fname.name, upload_url=src_path))\n",
        "            pick_files_dialog.upload(uf)\n",
        "            print(str(src_path))\n",
        "            #src_path = ''.join(src_path)\n",
        "            print(str(uf[0]))\n",
        "            dst_path = os.path.join(root_dir, fname.name)\n",
        "            print(f'Copy {src_path} to {dst_path}')\n",
        "            #shutil.copy(src_path, dst_path)\n",
        "            # TODO: is init or mask?\n",
        "            init_image.value = dst_path\n",
        "\n",
        "    pick_files_dialog = FilePicker(on_result=pick_files_result)\n",
        "    page.overlay.append(pick_files_dialog)\n",
        "    #selected_files = Text()\n",
        "\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "            upload_files(e)\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "        nonlocal pick_type\n",
        "        if e.progress == 1:\n",
        "            fname = os.path.join(root_dir, e.file_name)\n",
        "            if pick_type == \"init\":\n",
        "                init_image.value = fname\n",
        "                init_image.update()\n",
        "                kandinsky_prefs['init_image'] = fname\n",
        "            elif pick_type == \"mask\":\n",
        "                mask_image.value = fname\n",
        "                mask_image.update()\n",
        "                kandinsky_prefs['mask_image'] = fname\n",
        "            page.update()\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    page.overlay.append(file_picker)\n",
        "    pick_type = \"\"\n",
        "    #page.overlay.append(pick_files_dialog)\n",
        "    def pick_init(e):\n",
        "        nonlocal pick_type\n",
        "        pick_type = \"init\"\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Init Image File\")\n",
        "    def pick_mask(e):\n",
        "        nonlocal pick_type\n",
        "        pick_type = \"mask\"\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Black & White Mask Image\")\n",
        "    def toggle_ESRGAN(e):\n",
        "        ESRGAN_settings.height = None if e.control.value else 0\n",
        "        kandinsky_prefs['apply_ESRGAN_upscale'] = e.control.value\n",
        "        ESRGAN_settings.update()\n",
        "    def change_guidance(e):\n",
        "        guidance_value.value = f\" {int(e.control.value)}\"\n",
        "        guidance_value.update()\n",
        "        #guidance.controls[1].value = f\" {e.control.value}\"\n",
        "        guidance.update()\n",
        "        changed(e, 'guidance_scale', ptype=\"int\")\n",
        "    def change_width(e):\n",
        "        width_slider.controls[1].value = f\" {int(e.control.value)}px\"\n",
        "        width_slider.update()\n",
        "        changed(e, 'width', ptype=\"int\")\n",
        "    def change_height(e):\n",
        "        height_slider.controls[1].value = f\" {int(e.control.value)}px\"\n",
        "        height_slider.update()\n",
        "        changed(e, 'height', ptype=\"int\")\n",
        "    def change_enlarge_scale(e):\n",
        "        enlarge_scale_slider.controls[1].value = f\" {float(e.control.value)}x\"\n",
        "        enlarge_scale_slider.update()\n",
        "        changed(e, 'enlarge_scale', ptype=\"float\")\n",
        "    def change_strength(e):\n",
        "        strength_value.value = f\" {e.control.value}\"\n",
        "        strength_value.update()\n",
        "        guidance.update()\n",
        "        changed(e, 'strength', ptype=\"float\")\n",
        "\n",
        "    prompt = TextField(label=\"Text Prompt\", value=kandinsky_prefs['prompt'], on_change=lambda e:changed(e,'prompt'))\n",
        "    batch_folder_name = TextField(label=\"Batch Folder Name\", value=kandinsky_prefs['batch_folder_name'], on_change=lambda e:changed(e,'batch_folder_name'))\n",
        "    file_prefix = TextField(label=\"Filename Prefix\", value=kandinsky_prefs['file_prefix'], on_change=lambda e:changed(e,'file_prefix'))\n",
        "    #num_outputs = NumberPicker(label=\"Num of Outputs\", min=1, max=4, step=4, value=kandinsky_prefs['num_outputs'], on_change=lambda e:changed(e,'num_outputs', ptype=\"int\"))\n",
        "    #num_outputs = TextField(label=\"num_outputs\", value=kandinsky_prefs['num_outputs'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'num_outputs', ptype=\"int\"))\n",
        "    #n_iterations = TextField(label=\"Number of Iterations\", value=kandinsky_prefs['n_iterations'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'n_iterations', ptype=\"int\"))\n",
        "    steps = TextField(label=\"Number of Steps\", value=kandinsky_prefs['steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'steps', ptype=\"int\"))\n",
        "    ddim_eta = TextField(label=\"DDIM ETA\", value=kandinsky_prefs['ddim_eta'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'ddim_eta', ptype=\"float\"))\n",
        "    dynamic_threshold_v = TextField(label=\"Dynamic Threshold\", value=kandinsky_prefs['dynamic_threshold_v'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'dynamic_threshold_v', ptype=\"float\"))\n",
        "    param_rows = ResponsiveRow([Column([batch_folder_name, file_prefix, NumberPicker(label=\"Number of Images\", min=1, max=9, step=1, value=kandinsky_prefs['num_images'], on_change=lambda e:changed(e,'num_images', ptype=\"int\"))], col={'xs':12, 'md':6}), \n",
        "                      Column([steps, ddim_eta, dynamic_threshold_v], col={'xs':12, 'md':6})])\n",
        "    sampler = Dropdown(label=\"Sampler\", width=180, options=[dropdown.Option(\"ddim_sampler\"), dropdown.Option(\"p_sampler\")], value=kandinsky_prefs['sampler'], on_change=lambda e:changed(e,'sampler'), col={'xs':12, 'md':6})\n",
        "    denoised_type = Dropdown(label=\"Denoised Type\", width=180, options=[dropdown.Option(\"dynamic_threshold\"), dropdown.Option(\"clip_denoised\")], value=kandinsky_prefs['denoised_type'], on_change=lambda e:changed(e,'denoised_type'), col={'xs':12, 'md':6})\n",
        "    dropdown_row = ResponsiveRow([sampler, denoised_type])\n",
        "    guidance_scale = Slider(min=0, max=50, divisions=50, label=\"{value}\", value=kandinsky_prefs['guidance_scale'], on_change=change_guidance, expand=True)\n",
        "    guidance_value = Text(f\" {kandinsky_prefs['guidance_scale']}\", weight=FontWeight.BOLD)\n",
        "    guidance = Row([Text(\"Guidance Scale: \"), guidance_value, guidance_scale])\n",
        "    width = Slider(min=128, max=1024, divisions=14, label=\"{value}px\", value=kandinsky_prefs['width'], on_change=change_width, expand=True)\n",
        "    width_value = Text(f\" {int(kandinsky_prefs['width'])}px\", weight=FontWeight.BOLD)\n",
        "    width_slider = Row([Text(f\"Width: \"), width_value, width])\n",
        "    height = Slider(min=128, max=1024, divisions=14, label=\"{value}px\", value=kandinsky_prefs['height'], on_change=change_height, expand=True)\n",
        "    height_value = Text(f\" {int(kandinsky_prefs['height'])}px\", weight=FontWeight.BOLD)\n",
        "    height_slider = Row([Text(f\"Height: \"), height_value, height])\n",
        "\n",
        "    init_image = TextField(label=\"Init Image\", value=kandinsky_prefs['init_image'], on_change=lambda e:changed(e,'init_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_init), col={'xs':12, 'md':6})\n",
        "    mask_image = TextField(label=\"Mask Image\", value=kandinsky_prefs['mask_image'], on_change=lambda e:changed(e,'mask_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD_OUTLINED, on_click=pick_mask), col={'xs':10, 'md':5})\n",
        "    invert_mask = Checkbox(label=\"Invert\", tooltip=\"Swaps the Black & White of your Mask Image\", value=kandinsky_prefs['invert_mask'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'invert_mask'), col={'xs':2, 'md':1})\n",
        "    image_pickers = Container(content=ResponsiveRow([init_image, mask_image, invert_mask]), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    strength = Slider(min=0.1, max=0.9, divisions=16, label=\"{value}\", value=kandinsky_prefs['strength'], on_change=change_strength, expand=True)\n",
        "    strength_value = Text(f\" {kandinsky_prefs['strength']}\", weight=FontWeight.BOLD)\n",
        "    strength_slider = Row([Text(\"Init Image Strength: \"), strength_value, strength])\n",
        "    img_block = Container(Column([image_pickers, strength_slider, Divider(height=9, thickness=2)]), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    apply_ESRGAN_upscale = Switch(label=\"Apply ESRGAN Upscale\", value=kandinsky_prefs['apply_ESRGAN_upscale'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_ESRGAN)\n",
        "    enlarge_scale_value = Text(f\" {float(kandinsky_prefs['enlarge_scale'])}x\", weight=FontWeight.BOLD)\n",
        "    enlarge_scale = Slider(min=1, max=4, divisions=6, label=\"{value}x\", value=kandinsky_prefs['enlarge_scale'], on_change=change_enlarge_scale, expand=True)\n",
        "    enlarge_scale_slider = Row([Text(\"Enlarge Scale: \"), enlarge_scale_value, enlarge_scale])\n",
        "    face_enhance = Checkbox(label=\"Use Face Enhance GPFGAN\", value=kandinsky_prefs['face_enhance'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'face_enhance'))\n",
        "    display_upscaled_image = Checkbox(label=\"Display Upscaled Image\", value=kandinsky_prefs['display_upscaled_image'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'display_upscaled_image'))\n",
        "    ESRGAN_settings = Container(Column([enlarge_scale_slider, face_enhance, display_upscaled_image], spacing=0), padding=padding.only(left=32), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    page.ESRGAN_block_kandinsky = Container(Column([apply_ESRGAN_upscale, ESRGAN_settings]), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    page.ESRGAN_block_kandinsky.height = None if status['installed_ESRGAN'] else 0\n",
        "    if not kandinsky_prefs['apply_ESRGAN_upscale']:\n",
        "        ESRGAN_settings.height = 0\n",
        "    parameters_button = ElevatedButton(content=Text(value=\"‚ú®   Run Kandinsky 2\", size=20), on_click=lambda _: run_kandinsky(page))\n",
        "\n",
        "    parameters_row = Row([parameters_button], alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "    page.kandinsky_output = Column([])\n",
        "    c = Column([Container(\n",
        "        padding=padding.only(18, 14, 20, 10), content=Column([\n",
        "            Text (\"üéé  Kandinsky 2.0\", style=TextThemeStyle.TITLE_LARGE),\n",
        "            Text (\"A Latent Diffusion model with two Multilingual text encoders, supports 100+ languages, made in Russia.\"),\n",
        "            Divider(thickness=1, height=4),\n",
        "            prompt,\n",
        "            param_rows, dropdown_row, guidance, width_slider, height_slider, #Divider(height=9, thickness=2), \n",
        "            img_block, page.ESRGAN_block_kandinsky,\n",
        "            #(img_block if status['installed_img2img'] or status['installed_stability'] else Container(content=None)), (clip_block if prefs['install_CLIP_guided'] else Container(content=None)), (ESRGAN_block if prefs['install_ESRGAN'] else Container(content=None)), \n",
        "            parameters_row,\n",
        "            page.kandinsky_output\n",
        "        ],\n",
        "    ))], scroll=ScrollMode.AUTO)#batch_folder_name, batch_size, n_iterations, steps, ddim_eta, seed, \n",
        "    return c\n",
        "\n",
        "\n",
        "CLIPstyler_prefs = {\n",
        "    'source':'a photo',\n",
        "    'prompt_text': 'Detailed oil painting',\n",
        "    'batch_folder_name': 'clipstyler',\n",
        "    'crop_size': 128,\n",
        "    'num_crops': 64,\n",
        "    'original_image': '',\n",
        "    'image_dir': \"\",\n",
        "    'training_iterations': 100,\n",
        "    'width': 512,\n",
        "    'height': 512,\n",
        "    \"apply_ESRGAN_upscale\": prefs['apply_ESRGAN_upscale'],\n",
        "    \"enlarge_scale\": prefs['enlarge_scale'],\n",
        "    \"display_upscaled_image\": prefs['display_upscaled_image'],\n",
        "}\n",
        "\n",
        "def buildCLIPstyler(page):\n",
        "    global CLIPstyler, prefs\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "      if pref is not None:\n",
        "        if ptype == \"int\":\n",
        "          CLIPstyler_prefs[pref] = int(e.control.value)\n",
        "        elif ptype == \"float\":\n",
        "          CLIPstyler_prefs[pref] = float(e.control.value)\n",
        "        else:\n",
        "          CLIPstyler_prefs[pref] = e.control.value\n",
        "    def pick_files_result(e: FilePickerResultEvent):\n",
        "        if e.files:\n",
        "            img = e.files\n",
        "            uf = []\n",
        "            fname = img[0]\n",
        "            print(\", \".join(map(lambda f: f.name, e.files)))\n",
        "            src_path = page.get_upload_url(fname.name, 600)\n",
        "            uf.append(FilePickerUploadFile(fname.name, upload_url=src_path))\n",
        "            pick_files_dialog.upload(uf)\n",
        "            print(str(src_path))\n",
        "            #src_path = ''.join(src_path)\n",
        "            print(str(uf[0]))\n",
        "            dst_path = os.path.join(root_dir, fname.name)\n",
        "            print(f'Copy {src_path} to {dst_path}')\n",
        "            #shutil.copy(src_path, dst_path)\n",
        "            # TODO: is original or mask?\n",
        "            original_image.value = dst_path\n",
        "\n",
        "    pick_files_dialog = FilePicker(on_result=pick_files_result)\n",
        "    page.overlay.append(pick_files_dialog)\n",
        "    #selected_files = Text()\n",
        "\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "            upload_files(e)\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "        if e.progress == 1:\n",
        "            fname = os.path.join(root_dir, e.file_name)\n",
        "            original_image.value = fname\n",
        "            original_image.update()\n",
        "            CLIPstyler_prefs['original_image'] = fname\n",
        "            page.update()\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    page.overlay.append(file_picker)\n",
        "    pick_type = \"\"\n",
        "    #page.overlay.append(pick_files_dialog)\n",
        "    def pick_original(e):\n",
        "        file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\", \"jpg\", \"jpeg\"], dialog_title=\"Pick original Image File\")\n",
        "    def toggle_ESRGAN(e):\n",
        "        ESRGAN_settings.height = None if e.control.value else 0\n",
        "        CLIPstyler_prefs['apply_ESRGAN_upscale'] = e.control.value\n",
        "        ESRGAN_settings.update()\n",
        "        has_changed = True\n",
        "    def change_iterations(e):\n",
        "        changed(e, 'training_iterations', ptype=\"int\")\n",
        "        iterations_value.value = f\" {int(e.control.value)}\"\n",
        "        iterations_value.update()\n",
        "        #iterations.controls[1].value = f\" {e.control.value}\"\n",
        "        iterations.update()\n",
        "    def change_width(e):\n",
        "        width_slider.controls[1].value = f\" {int(e.control.value)}px\"\n",
        "        width_slider.update()\n",
        "        changed(e, 'width', ptype=\"int\")\n",
        "    def change_height(e):\n",
        "        height_slider.controls[1].value = f\" {int(e.control.value)}px\"\n",
        "        height_slider.update()\n",
        "        changed(e, 'height', ptype=\"int\")\n",
        "    def change_enlarge_scale(e):\n",
        "        enlarge_scale_slider.controls[1].value = f\" {float(e.control.value)}x\"\n",
        "        enlarge_scale_slider.update()\n",
        "        changed(e, 'enlarge_scale', ptype=\"float\")\n",
        "\n",
        "    prompt_text = TextField(label=\"Stylized Prompt Text\", value=CLIPstyler_prefs['prompt_text'], on_change=lambda e:changed(e,'prompt_text'))\n",
        "    batch_folder_name = TextField(label=\"Batch Folder Name\", value=CLIPstyler_prefs['batch_folder_name'], on_change=lambda e:changed(e,'batch_folder_name'))\n",
        "    source = TextField(label=\"Source Type\", value=CLIPstyler_prefs['source'], on_change=lambda e:changed(e,'source'))\n",
        "    #training_iterations = TextField(label=\"Training Iterations\", value=CLIPstyler_prefs['training_iterations'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'training_iterations', ptype=\"int\"))\n",
        "    crop_size = TextField(label=\"Crop Size\", value=CLIPstyler_prefs['crop_size'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'crop_size', ptype=\"int\"))\n",
        "    num_crops = TextField(label=\"Number of Crops\", value=CLIPstyler_prefs['num_crops'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e:changed(e,'num_crops', ptype=\"int\"))\n",
        "    param_rows = Column([Row([batch_folder_name, source]), Row([crop_size, num_crops])])\n",
        "    training_iterations = Slider(min=50, max=500, divisions=90, label=\"{value}\", value=CLIPstyler_prefs['training_iterations'], on_change=change_iterations, expand=True)\n",
        "    iterations_value = Text(f\" {CLIPstyler_prefs['training_iterations']}\", weight=FontWeight.BOLD)\n",
        "    iterations = Row([Text(\"Training Iterations: \"), iterations_value, training_iterations])\n",
        "    width = Slider(min=128, max=1024, divisions=14, label=\"{value}px\", value=CLIPstyler_prefs['width'], on_change=change_width, expand=True)\n",
        "    width_value = Text(f\" {int(CLIPstyler_prefs['width'])}px\", weight=FontWeight.BOLD)\n",
        "    width_slider = Row([Text(f\"Width: \"), width_value, width])\n",
        "    height = Slider(min=128, max=1024, divisions=14, label=\"{value}px\", value=CLIPstyler_prefs['height'], on_change=change_height, expand=True)\n",
        "    height_value = Text(f\" {int(CLIPstyler_prefs['height'])}px\", weight=FontWeight.BOLD)\n",
        "    height_slider = Row([Text(f\"Height: \"), height_value, height])\n",
        "\n",
        "    original_image = TextField(label=\"Original Image\", value=CLIPstyler_prefs['original_image'], on_change=lambda e:changed(e,'original_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_original, col={\"*\":1, \"md\":3}))\n",
        "    #mask_image = TextField(label=\"Mask Image\", value=CLIPstyler_prefs['mask_image'], on_change=lambda e:changed(e,'mask_image'), expand=True, suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD_OUTLINED, on_click=pick_mask, col={\"*\":1, \"md\":3}))\n",
        "    #invert_mask = Checkbox(label=\"Invert\", tooltip=\"Swaps the Black & White of your Mask Image\", value=CLIPstyler_prefs['invert_mask'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'invert_mask'))\n",
        "    image_picker = Container(content=Row([original_image]), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    #prompt_strength = Slider(min=0.1, max=0.9, divisions=16, label=\"{value}%\", value=CLIPstyler_prefs['prompt_strength'], on_change=change_strength, expand=True)\n",
        "    #strength_value = Text(f\" {int(CLIPstyler_prefs['prompt_strength'] * 100)}%\", weight=FontWeight.BOLD)\n",
        "    #strength_slider = Row([Text(\"Prompt Strength: \"), strength_value, prompt_strength])\n",
        "    #img_block = Container(Column([image_pickers, strength_slider, Divider(height=9, thickness=2)]), padding=padding.only(top=5), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    apply_ESRGAN_upscale = Switch(label=\"Apply ESRGAN Upscale\", value=CLIPstyler_prefs['apply_ESRGAN_upscale'], active_color=colors.PRIMARY_CONTAINER, active_track_color=colors.PRIMARY, on_change=toggle_ESRGAN)\n",
        "    enlarge_scale_value = Text(f\" {float(CLIPstyler_prefs['enlarge_scale'])}x\", weight=FontWeight.BOLD)\n",
        "    enlarge_scale = Slider(min=1, max=4, divisions=6, label=\"{value}x\", value=CLIPstyler_prefs['enlarge_scale'], on_change=change_enlarge_scale, expand=True)\n",
        "    enlarge_scale_slider = Row([Text(\"Enlarge Scale: \"), enlarge_scale_value, enlarge_scale])\n",
        "    #face_enhance = Checkbox(label=\"Use Face Enhance GPFGAN\", value=CLIPstyler_prefs['face_enhance'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'face_enhance'))\n",
        "    display_upscaled_image = Checkbox(label=\"Display Upscaled Image\", value=CLIPstyler_prefs['display_upscaled_image'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'display_upscaled_image'))\n",
        "    ESRGAN_settings = Container(Column([enlarge_scale_slider, display_upscaled_image], spacing=0), padding=padding.only(left=32), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    page.ESRGAN_block_styler = Container(Column([apply_ESRGAN_upscale, ESRGAN_settings]), animate_size=animation.Animation(1000, AnimationCurve.BOUNCE_OUT), clip_behavior=ClipBehavior.HARD_EDGE)\n",
        "    page.ESRGAN_block_styler.height = None if status['installed_ESRGAN'] else 0\n",
        "    if not CLIPstyler_prefs['apply_ESRGAN_upscale']:\n",
        "        ESRGAN_settings.height = 0\n",
        "    parameters_button = ElevatedButton(content=Text(value=\"üìé   Run CLIP-Styler\", size=20), on_click=lambda _: run_CLIPstyler(page))\n",
        "\n",
        "    parameters_row = Row([parameters_button], alignment=MainAxisAlignment.SPACE_BETWEEN)\n",
        "    page.CLIPstyler_output = Column([])\n",
        "    c = Column([Container(\n",
        "        padding=padding.only(18, 14, 20, 10), content=Column([\n",
        "            Text (\"üòé   CLIP-Styler\", style=TextThemeStyle.TITLE_LARGE),\n",
        "            Text (\"Transfers a Text Guided Style onto your Image From Prompt Description...\"),\n",
        "            Divider(thickness=1, height=4),\n",
        "            image_picker, prompt_text,\n",
        "            param_rows, iterations, width_slider, height_slider, #Divider(height=9, thickness=2), \n",
        "            page.ESRGAN_block_styler,\n",
        "            #(img_block if status['installed_img2img'] or status['installed_stability'] else Container(content=None)), (clip_block if prefs['install_CLIP_guided'] else Container(content=None)), (ESRGAN_block if prefs['install_ESRGAN'] else Container(content=None)), \n",
        "            parameters_row,\n",
        "            page.CLIPstyler_output\n",
        "        ],\n",
        "    ))], scroll=ScrollMode.AUTO)#batch_folder_name, batch_size, n_iterations, steps, crop_size, num_crops, \n",
        "    return c\n",
        "\n",
        "def buildDreamMask(page):\n",
        "    #prog_bars: Dict[str, ProgressRing] = {}\n",
        "    files = Ref[Column]()\n",
        "    #upload_button = Ref[ElevatedButton]()\n",
        "\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        files.current.controls.clear()\n",
        "        if e.files != None:\n",
        "          upload_files(e)\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "      if e.progress == 1:\n",
        "        files.current.controls.append(Row([Text(f\"Done uploading {root_dir}{e.file_name}\")]))\n",
        "        page.update()\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    page.overlay.append(file_picker)\n",
        "\n",
        "    c = Column([\n",
        "        ElevatedButton(\n",
        "            \"Select Init Image to Mask...\",\n",
        "            icon=icons.FOLDER_OPEN,\n",
        "            on_click=lambda _: file_picker.pick_files(allow_multiple=False, allowed_extensions=[\"png\", \"PNG\"], dialog_title=\"Pick Init Image File\" ),\n",
        "        ),\n",
        "        Column(ref=files),\n",
        "    ])\n",
        "    return c\n",
        "\n",
        "dreambooth_prefs = {\n",
        "    'instance_prompt': '',\n",
        "    'prior_preservation': False,\n",
        "    'prior_preservation_class_prompt': \"\",\n",
        "    'num_class_images': 12,\n",
        "    'sample_batch_size': 2,\n",
        "    'prior_loss_weight': 0.5,\n",
        "    'prior_preservation_class_folder': os.path.join(root_dir, \"class_images\"),\n",
        "    'learning_rate': 5e-06,\n",
        "    'max_train_steps': 450,\n",
        "    'seed': 222476,\n",
        "    'name_of_your_concept': \"\",\n",
        "    'save_concept': True,\n",
        "    'where_to_save_concept': \"Public Library\",\n",
        "    'max_size': 512,\n",
        "    'image_path': '',\n",
        "    'readme_description': '',\n",
        "    'urls': [],\n",
        "}\n",
        "\n",
        "def buildDreamBooth(page):\n",
        "    global prefs, dreambooth_prefs\n",
        "    from PIL import Image as PILImage\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "        if pref is not None:\n",
        "          if ptype == \"int\":\n",
        "            dreambooth_prefs[pref] = int(e.control.value)\n",
        "          elif ptype == \"float\":\n",
        "            dreambooth_prefs[pref] = float(e.control.value)\n",
        "          else:\n",
        "            dreambooth_prefs[pref] = e.control.value\n",
        "    def add_to_dreambooth_output(o):\n",
        "        page.dreambooth_output.controls.append(o)\n",
        "        page.dreambooth_output.update()\n",
        "    def clear_output(e):\n",
        "        if prefs['enable_sounds']: page.snd_delete.play()\n",
        "        page.dreambooth_output.controls = []\n",
        "        page.dreambooth_output.update()\n",
        "        clear_button.visible = False\n",
        "        clear_button.update()\n",
        "    def db_help(e):\n",
        "        def close_db_dlg(e):\n",
        "          nonlocal db_help_dlg\n",
        "          db_help_dlg.open = False\n",
        "          page.update()\n",
        "        db_help_dlg = AlertDialog(title=Text(\"üíÅ   Help with DreamBooth\"), content=Column([\n",
        "            Text(\"First thing is to collect all your own images that you want to teach it to dream.  Feed it at least 5 square pictures of the object or style to learn, and it'll save your Custom Model Checkpoint.\"),\n",
        "            Text(\"Fine-tune your perameters, but be aware that the training process takes a long time to run, so careful with the settings if you don't have the patience or processor. Dream at your own risk.\"),\n",
        "          ], scroll=ScrollMode.AUTO), actions=[TextButton(emojize(':sleepy_face:') + \"  Got it... \", on_click=close_db_dlg)], actions_alignment=MainAxisAlignment.END)\n",
        "        page.dialog = db_help_dlg\n",
        "        db_help_dlg.open = True\n",
        "        page.update()\n",
        "    def delete_image(e):\n",
        "        f = e.control.data\n",
        "        if os.path.isfile(f):\n",
        "          os.remove(f)\n",
        "          for i, fl in enumerate(page.db_file_list.controls):\n",
        "            if fl.title.value == f:\n",
        "              del page.db_file_list.controls[i]\n",
        "              page.db_file_list.update()\n",
        "              continue\n",
        "    def delete_all_images(e):\n",
        "        for fl in page.db_file_list.controls:\n",
        "          f = fl.title.value\n",
        "          if os.path.isfile(f):\n",
        "            os.remove(f)\n",
        "        page.db_file_list.controls.clear()\n",
        "        page.db_file_list.update()\n",
        "    def add_file(fpath, update=True):\n",
        "        page.db_file_list.controls.append(ListTile(title=Text(fpath), dense=True, trailing=PopupMenuButton(icon=icons.MORE_VERT,\n",
        "          items=[#TODO: View Image\n",
        "              PopupMenuItem(icon=icons.DELETE, text=\"Delete Image\", on_click=delete_image, data=fpath),\n",
        "              PopupMenuItem(icon=icons.DELETE_SWEEP, text=\"Delete All\", on_click=delete_all_images, data=fpath),\n",
        "          ])))\n",
        "        if update: page.db_file_list.update()\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "          upload_files(e)\n",
        "    save_dir = os.path.join(root_dir, 'my_concept')\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "        if e.progress == 1:\n",
        "          if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "          fname = os.path.join(root_dir, e.file_name)\n",
        "          fpath = os.path.join(save_dir, e.file_name)\n",
        "          original_img = PILImage.open(fname)\n",
        "          width, height = original_img.size\n",
        "          width, height = scale_dimensions(width, height, dreambooth_prefs['max_size'])\n",
        "          original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "          original_img.save(fpath)\n",
        "          os.remove(fname)\n",
        "          #shutil.move(fname, fpath)\n",
        "          add_file(fpath)\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def pick_path(e):\n",
        "        file_picker.pick_files(allow_multiple=True, allowed_extensions=[\"png\", \"PNG\", \"jpg\", \"jpeg\"], dialog_title=\"Pick Image File to Enlarge\")\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    page.overlay.append(file_picker)\n",
        "    def add_image(e):\n",
        "        save_dir = os.path.join(root_dir, 'my_concept')\n",
        "        if not os.path.exists(save_dir):\n",
        "          os.mkdir(save_dir)\n",
        "        if image_path.value.startswith('http'):\n",
        "          import requests\n",
        "          from io import BytesIO\n",
        "          response = requests.get(image_path.value)\n",
        "          fpath = os.path.join(save_dir, image_path.value.rpartition(slash)[2])\n",
        "          concept_image = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "          width, height = concept_image.size\n",
        "          width, height = scale_dimensions(width, height, dreambooth_prefs['max_size'])\n",
        "          concept_image = concept_image.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "          concept_image.save(fpath)\n",
        "          add_file(fpath)\n",
        "        elif os.path.isfile(image_path.value):\n",
        "          fpath = os.path.join(save_dir, image_path.value.rpartition(slash)[2])\n",
        "          original_img = PILImage.open(image_path.value)\n",
        "          width, height = original_img.size\n",
        "          width, height = scale_dimensions(width, height, dreambooth_prefs['max_size'])\n",
        "          original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "          original_img.save(fpath)\n",
        "          #shutil.copy(image_path.value, fpath)\n",
        "          add_file(fpath)\n",
        "        elif os.path.isdir(image_path.value):\n",
        "          for f in os.listdir(image_path.value):\n",
        "            file_path = os.path.join(image_path.value, f)\n",
        "            if os.path.isdir(file_path): continue\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "              fpath = os.path.join(save_dir, f)\n",
        "              original_img = PILImage.open(file_path)\n",
        "              width, height = original_img.size\n",
        "              width, height = scale_dimensions(width, height, dreambooth_prefs['max_size'])\n",
        "              original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "              original_img.save(fpath)\n",
        "              #shutil.copy(file_path, fpath)\n",
        "              add_file(fpath)\n",
        "        else:\n",
        "          if bool(image_path.value):\n",
        "            alert_msg(page, \"Couldn't find a valid File, Path or URL...\")\n",
        "          else:\n",
        "            pick_path(e)\n",
        "          return\n",
        "        image_path.value = \"\"\n",
        "        image_path.update()\n",
        "    def load_images():\n",
        "        if os.path.exists(save_dir):\n",
        "          for f in os.listdir(save_dir):\n",
        "            existing = os.path.join(save_dir, f)\n",
        "            if os.path.isdir(existing): continue\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "              add_file(existing, update=False)\n",
        "    instance_prompt = TextField(label=\"Instance Prompt Token Text\", value=dreambooth_prefs['instance_prompt'], on_change=lambda e:changed(e,'instance_prompt'))\n",
        "    prior_preservation_class_prompt = TextField(label=\"Prior Preservation Class Prompt\", value=dreambooth_prefs['prior_preservation_class_prompt'], on_change=lambda e:changed(e,'prior_preservation_class_prompt'))\n",
        "    prior_preservation = Checkbox(label=\"Prior Preservation\", tooltip=\"If you'd like class of the concept (e.g.: toy, dog, painting) is guaranteed to be preserved. This increases the quality and helps with generalization at the cost of training time\", value=dreambooth_prefs['prior_preservation'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'prior_preservation'))\n",
        "    num_class_images = TextField(label=\"Number of Class Images\", value=dreambooth_prefs['num_class_images'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'num_class_images', ptype='int'), width = 160)\n",
        "    sample_batch_size = TextField(label=\"Sample Batch Size\", value=dreambooth_prefs['sample_batch_size'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'sample_batch_size', ptype='int'), width = 160)\n",
        "    prior_loss_weight = TextField(label=\"Prior Loss Weight\", value=dreambooth_prefs['prior_loss_weight'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'prior_loss_weight', ptype='float'), width = 160)\n",
        "    max_train_steps = TextField(label=\"Max Training Steps\", value=dreambooth_prefs['max_train_steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'max_train_steps', ptype='int'), width = 160)\n",
        "    learning_rate = TextField(label=\"Learning Rate\", value=dreambooth_prefs['learning_rate'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'learning_rate', ptype='float'), width = 160)\n",
        "    seed = TextField(label=\"Seed\", value=dreambooth_prefs['seed'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'seed', ptype='int'), width = 160)\n",
        "    save_concept = Checkbox(label=\"Save Concept    \", tooltip=\"\", value=dreambooth_prefs['save_concept'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'save_concept'))\n",
        "    where_to_save_concept = Dropdown(label=\"Where to Save Concept\", width=250, options=[dropdown.Option(\"Public Library\"), dropdown.Option(\"Privately to my Profile\")], value=dreambooth_prefs['where_to_save_concept'], on_change=lambda e: changed(e, 'where_to_save_concept'))\n",
        "    prior_preservation_class_folder = TextField(label=\"Prior Preservation Class Folder\", value=dreambooth_prefs['prior_preservation_class_folder'], on_change=lambda e:changed(e,'prior_preservation_class_folder'))\n",
        "    name_of_your_concept = TextField(label=\"Name of your Concept\", value=dreambooth_prefs['name_of_your_concept'], on_change=lambda e:changed(e,'name_of_your_concept'))\n",
        "    readme_description = TextField(label=\"Extra README Description\", value=dreambooth_prefs['readme_description'], on_change=lambda e:changed(e,'readme_description'))\n",
        "    max_size = Slider(min=256, max=1024, divisions=12, label=\"{value}px\", value=float(dreambooth_prefs['max_size']), expand=True, on_change=lambda e:changed(e,'max_size', ptype='int'))\n",
        "    max_row = Row([Text(\"Max Resolution Size: \"), max_size])\n",
        "    image_path = TextField(label=\"Image File or Folder Path or URL to Train\", value=dreambooth_prefs['image_path'], on_change=lambda e:changed(e,'image_path'), suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_path), expand=1)\n",
        "    add_image_button = ElevatedButton(content=Text(\"Add File or Folder\"), on_click=add_image)\n",
        "    page.db_file_list = Column([], tight=True, spacing=0)\n",
        "    load_images()\n",
        "    #seed = TextField(label=\"Seed\", value=dreambooth_prefs['seed'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'seed', ptype='int'), width = 160)\n",
        "    #lambda_entropy = TextField(label=\"Lambda Entropy\", value=dreamfusdreambooth_prefsion_prefs['lambda_entropy'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'lambda_entropy', ptype='float'), width = 160)\n",
        "    #max_steps = TextField(label=\"Max Steps\", value=dreambooth_prefs['max_steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'max_steps', ptype='int'), width = 160)\n",
        "    page.dreambooth_output = Column([])\n",
        "    clear_button = Row([ElevatedButton(content=Text(\"‚ùå   Clear Output\"), on_click=clear_output)], alignment=MainAxisAlignment.END)\n",
        "    clear_button.visible = len(page.dreambooth_output.controls) > 0\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Row([Text(\"üò∂‚Äçüå´Ô∏è  Create Custom DreamBooth Concept Model\", style=TextThemeStyle.TITLE_LARGE), IconButton(icon=icons.HELP, tooltip=\"Help with DreamBooth Settings\", on_click=db_help)], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Text(\"Provide a collection of images to conceptualize. Warning: May take over an hour to run the training...\"),\n",
        "        Divider(thickness=1, height=4),\n",
        "        Row([instance_prompt, name_of_your_concept]),\n",
        "        Row([num_class_images, sample_batch_size, prior_loss_weight]),\n",
        "        Row([max_train_steps, learning_rate, seed]),\n",
        "        Row([save_concept, where_to_save_concept]),\n",
        "        readme_description,\n",
        "        #Row([prior_preservation_class_folder]),\n",
        "        max_row,\n",
        "        Row([image_path, add_image_button]),\n",
        "        page.db_file_list,\n",
        "        ElevatedButton(content=Text(\"üë®‚Äçüé®Ô∏è  Run DreamBooth\", size=18), on_click=lambda _: run_dreambooth(page)),\n",
        "        page.dreambooth_output,\n",
        "        clear_button,\n",
        "      ]\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "textualinversion_prefs = {\n",
        "    'what_to_teach': 'object',\n",
        "    'placeholder_token': '',\n",
        "    'initializer_token': '',\n",
        "    'scale_lr': True,\n",
        "    'max_train_steps': 3000,\n",
        "    'train_batch_size': 1,\n",
        "    'gradient_accumulation_steps': 4,\n",
        "    'seed': 22276,\n",
        "    'repeats': 100,\n",
        "    'output_dir': os.path.join(root_dir, \"sd-concept-output\"),\n",
        "    'learning_rate': 5e-04,\n",
        "    'name_of_your_concept': \"\",\n",
        "    'save_concept': True,\n",
        "    'where_to_save_concept': \"Public Library\",\n",
        "    'max_size': 512,\n",
        "    'image_path': '',\n",
        "    'readme_description': '',\n",
        "    'urls': [],\n",
        "}\n",
        "def buildTextualInversion(page):\n",
        "    global prefs, textualinversion_prefs\n",
        "    from PIL import Image as PILImage\n",
        "    def changed(e, pref=None, ptype=\"str\"):\n",
        "        if pref is not None:\n",
        "          if ptype == \"int\":\n",
        "            textualinversion_prefs[pref] = int(e.control.value)\n",
        "          elif ptype == \"float\":\n",
        "            textualinversion_prefs[pref] = float(e.control.value)\n",
        "          else:\n",
        "            textualinversion_prefs[pref] = e.control.value\n",
        "    def add_to_textualinversion_output(o):\n",
        "        page.textualinversion_output.controls.append(o)\n",
        "        page.textualinversion_output.update()\n",
        "    def clear_output(e):\n",
        "        if prefs['enable_sounds']: page.snd_delete.play()\n",
        "        page.textualinversion_output.controls = []\n",
        "        page.textualinversion_output.update()\n",
        "        clear_button.visible = False\n",
        "        clear_button.update()\n",
        "    def ti_help(e):\n",
        "        def close_ti_dlg(e):\n",
        "          nonlocal ti_help_dlg\n",
        "          ti_help_dlg.open = False\n",
        "          page.update()\n",
        "        ti_help_dlg = AlertDialog(title=Text(\"üíÅ   Help with Textual-Inversion\"), content=Column([\n",
        "            Text(\"\"),\n",
        "          ], scroll=ScrollMode.AUTO), actions=[TextButton(\"üò™  I'll figure it out... \", on_click=close_ti_dlg)], actions_alignment=MainAxisAlignment.END)\n",
        "        page.dialog = ti_help_dlg\n",
        "        ti_help_dlg.open = True\n",
        "        page.update()\n",
        "    def delete_image(e):\n",
        "        f = e.control.data\n",
        "        if os.path.isfile(f):\n",
        "          os.remove(f)\n",
        "          for i, fl in enumerate(page.ti_file_list.controls):\n",
        "            if fl.title.value == f:\n",
        "              del page.ti_file_list.controls[i]\n",
        "              page.ti_file_list.update()\n",
        "              continue\n",
        "    def delete_all_images(e):\n",
        "        for fl in page.ti_file_list.controls:\n",
        "          f = fl.title.value\n",
        "          if os.path.isfile(f):\n",
        "            os.remove(f)\n",
        "        page.ti_file_list.controls.clear()\n",
        "        page.ti_file_list.update()\n",
        "    def add_file(fpath, update=True):\n",
        "        page.ti_file_list.controls.append(ListTile(title=Text(fpath), dense=True, trailing=PopupMenuButton(icon=icons.MORE_VERT,\n",
        "          items=[#TODO: View Image\n",
        "              PopupMenuItem(icon=icons.DELETE, text=\"Delete Image\", on_click=delete_image, data=fpath),\n",
        "              PopupMenuItem(icon=icons.DELETE_SWEEP, text=\"Delete All\", on_click=delete_all_images, data=fpath),\n",
        "          ])))\n",
        "        if update: page.ti_file_list.update()\n",
        "    def file_picker_result(e: FilePickerResultEvent):\n",
        "        if e.files != None:\n",
        "          upload_files(e)\n",
        "    save_dir = os.path.join(root_dir, 'my_concept')\n",
        "    def on_upload_progress(e: FilePickerUploadEvent):\n",
        "        if e.progress == 1:\n",
        "          if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "          fname = os.path.join(root_dir, e.file_name)\n",
        "          fpath = os.path.join(save_dir, e.file_name)\n",
        "          original_img = PILImage.open(fname)\n",
        "          width, height = original_img.size\n",
        "          width, height = scale_dimensions(width, height, textualinversion_prefs['max_size'])\n",
        "          original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "          original_img.save(fpath)\n",
        "          os.remove(fname)\n",
        "          #shutil.move(fname, fpath)\n",
        "          add_file(fpath)\n",
        "    file_picker = FilePicker(on_result=file_picker_result, on_upload=on_upload_progress)\n",
        "    def pick_path(e):\n",
        "        file_picker.pick_files(allow_multiple=True, allowed_extensions=[\"png\", \"PNG\", \"jpg\", \"jpeg\"], dialog_title=\"Pick Image File to Enlarge\")\n",
        "    def upload_files(e):\n",
        "        uf = []\n",
        "        if file_picker.result != None and file_picker.result.files != None:\n",
        "            for f in file_picker.result.files:\n",
        "                uf.append(FilePickerUploadFile(f.name, upload_url=page.get_upload_url(f.name, 600)))\n",
        "            file_picker.upload(uf)\n",
        "    page.overlay.append(file_picker)\n",
        "    def add_image(e):\n",
        "        save_dir = os.path.join(root_dir, 'my_concept')\n",
        "        if not os.path.exists(save_dir):\n",
        "          os.mkdir(save_dir)\n",
        "        if image_path.value.startswith('http'):\n",
        "          import requests\n",
        "          from io import BytesIO\n",
        "          response = requests.get(image_path.value)\n",
        "          fpath = os.path.join(save_dir, image_path.value.rpartition(slash)[2])\n",
        "          concept_image = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "          width, height = concept_image.size\n",
        "          width, height = scale_dimensions(width, height, textualinversion_prefs['max_size'])\n",
        "          concept_image = concept_image.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "          concept_image.save(fpath)\n",
        "          add_file(fpath)\n",
        "        elif os.path.isfile(image_path.value):\n",
        "          fpath = os.path.join(save_dir, image_path.value.rpartition(slash)[2])\n",
        "          original_img = PILImage.open(image_path.value)\n",
        "          width, height = original_img.size\n",
        "          width, height = scale_dimensions(width, height, textualinversion_prefs['max_size'])\n",
        "          original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "          original_img.save(fpath)\n",
        "          #shutil.copy(image_path.value, fpath)\n",
        "          add_file(fpath)\n",
        "        elif os.path.isdir(image_path.value):\n",
        "          for f in os.listdir(image_path.value):\n",
        "            file_path = os.path.join(image_path.value, f)\n",
        "            if os.path.isdir(file_path): continue\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "              fpath = os.path.join(save_dir, f)\n",
        "              original_img = PILImage.open(file_path)\n",
        "              width, height = original_img.size\n",
        "              width, height = scale_dimensions(width, height, textualinversion_prefs['max_size'])\n",
        "              original_img = original_img.resize((width, height), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "              original_img.save(fpath)\n",
        "              #shutil.copy(file_path, fpath)\n",
        "              add_file(fpath)\n",
        "        else:\n",
        "          if bool(image_path.value):\n",
        "            alert_msg(page, \"Couldn't find a valid File, Path or URL...\")\n",
        "          else:\n",
        "            pick_path(e)\n",
        "          return\n",
        "        image_path.value = \"\"\n",
        "        image_path.update()\n",
        "    def load_images():\n",
        "        if os.path.exists(save_dir):\n",
        "          for f in os.listdir(save_dir):\n",
        "            existing = os.path.join(save_dir, f)\n",
        "            if os.path.isdir(existing): continue\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "              add_file(existing, update=False)\n",
        "    what_to_teach = Dropdown(label=\"What to Teach\", width=250, options=[dropdown.Option(\"object\"), dropdown.Option(\"style\")], value=textualinversion_prefs['what_to_teach'], on_change=lambda e: changed(e, 'what_to_teach'))\n",
        "    placeholder_token = TextField(label=\"Placeholder <Token> Keyword\", value=textualinversion_prefs['placeholder_token'], on_change=lambda e:changed(e,'placeholder_token'))\n",
        "    initializer_token = TextField(label=\"Initializer Token Category Summary\", value=textualinversion_prefs['initializer_token'], on_change=lambda e:changed(e,'initializer_token'))\n",
        "    scale_lr = Checkbox(label=\"Scale Learning Rate\", tooltip=\"\", value=textualinversion_prefs['scale_lr'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'scale_lr'))\n",
        "    gradient_accumulation_steps = TextField(label=\"Gradient Accumulation Steps\", value=textualinversion_prefs['gradient_accumulation_steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'gradient_accumulation_steps', ptype='int'), width = 160)\n",
        "    repeats = TextField(label=\"Repeats\", value=textualinversion_prefs['repeats'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'repeats', ptype='int'), width = 160)\n",
        "    train_batch_size = TextField(label=\"Train Batch Size\", value=textualinversion_prefs['train_batch_size'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'train_batch_size', ptype='float'), width = 160)\n",
        "    max_train_steps = TextField(label=\"Max Training Steps\", value=textualinversion_prefs['max_train_steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'max_train_steps', ptype='int'), width = 160)\n",
        "    learning_rate = TextField(label=\"Learning Rate\", value=textualinversion_prefs['learning_rate'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'learning_rate', ptype='float'), width = 160)\n",
        "    seed = TextField(label=\"Seed\", value=textualinversion_prefs['seed'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'seed', ptype='int'), width = 160)\n",
        "    save_concept = Checkbox(label=\"Save Concept    \", tooltip=\"\", value=textualinversion_prefs['save_concept'], fill_color=colors.PRIMARY_CONTAINER, check_color=colors.ON_PRIMARY_CONTAINER, on_change=lambda e:changed(e,'save_concept'))\n",
        "    where_to_save_concept = Dropdown(label=\"Where to Save Concept\", width=250, options=[dropdown.Option(\"Public Library\"), dropdown.Option(\"Privately to my Profile\")], value=textualinversion_prefs['where_to_save_concept'], on_change=lambda e: changed(e, 'where_to_save_concept'))\n",
        "    output_dir = TextField(label=\"Prior Preservation Class Folder\", value=textualinversion_prefs['output_dir'], on_change=lambda e:changed(e,'output_dir'))\n",
        "    name_of_your_concept = TextField(label=\"Name of your Concept\", value=textualinversion_prefs['name_of_your_concept'], on_change=lambda e:changed(e,'name_of_your_concept'))\n",
        "    readme_description = TextField(label=\"Extra README Description\", value=textualinversion_prefs['readme_description'], on_change=lambda e:changed(e,'readme_description'))\n",
        "    max_size = Slider(min=256, max=1024, divisions=12, label=\"{value}px\", value=float(textualinversion_prefs['max_size']), expand=True, on_change=lambda e:changed(e,'max_size', ptype='int'))\n",
        "    max_row = Row([Text(\"Max Resolution Size: \"), max_size])\n",
        "    image_path = TextField(label=\"Image File or Folder Path or URL to Train\", value=textualinversion_prefs['image_path'], on_change=lambda e:changed(e,'image_path'), suffix=IconButton(icon=icons.DRIVE_FOLDER_UPLOAD, on_click=pick_path), expand=1)\n",
        "    add_image_button = ElevatedButton(content=Text(\"Add File or Folder\"), on_click=add_image)\n",
        "    page.ti_file_list = Column([], tight=True, spacing=0)\n",
        "    load_images()\n",
        "    #seed = TextField(label=\"Seed\", value=textualinversion_prefs['seed'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'seed', ptype='int'), width = 160)\n",
        "    #lambda_entropy = TextField(label=\"Lambda Entropy\", value=dreamfustextualinversion_prefsion_prefs['lambda_entropy'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'lambda_entropy', ptype='float'), width = 160)\n",
        "    #max_steps = TextField(label=\"Max Steps\", value=textualinversion_prefs['max_steps'], keyboard_type=KeyboardType.NUMBER, on_change=lambda e: changed(e, 'max_steps', ptype='int'), width = 160)\n",
        "    page.textualinversion_output = Column([])\n",
        "    clear_button = Row([ElevatedButton(content=Text(\"‚ùå   Clear Output\"), on_click=clear_output)], alignment=MainAxisAlignment.END)\n",
        "    clear_button.visible = len(page.textualinversion_output.controls) > 0\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Row([Text(\"üò∂‚Äçüå´Ô∏è  Create Cusom Textual-Inversion Concept Model\", style=TextThemeStyle.TITLE_LARGE), IconButton(icon=icons.HELP, tooltip=\"Help with Textual-Inversion Settings\", on_click=ti_help)], alignment=MainAxisAlignment.SPACE_BETWEEN),\n",
        "        Text(\"Provide a collection of images to conceptualize. Warning: May take over an hour to run the training...\"),\n",
        "        Divider(thickness=1, height=4),\n",
        "        Row([what_to_teach, initializer_token]),\n",
        "        Row([placeholder_token, name_of_your_concept]),\n",
        "        scale_lr,\n",
        "        Row([gradient_accumulation_steps, repeats, train_batch_size]),\n",
        "        Row([max_train_steps, learning_rate, seed]),\n",
        "        Row([save_concept, where_to_save_concept]),\n",
        "        readme_description,\n",
        "        #Row([output_dir]),\n",
        "        max_row,\n",
        "        Row([image_path, add_image_button]),\n",
        "        page.ti_file_list,\n",
        "        ElevatedButton(content=Text(\"üë®‚Äçüé®Ô∏è  Run Textual-Inversion\", size=18), on_click=lambda _: run_textualinversion(page)),\n",
        "        page.textualinversion_output,\n",
        "        clear_button,\n",
        "      ]\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "def get_directory_size(directory):\n",
        "    total = 0\n",
        "    for entry in os.scandir(directory):\n",
        "        if entry.is_file():\n",
        "            total += entry.stat().st_size\n",
        "        elif entry.is_dir():\n",
        "            try:\n",
        "                total += get_directory_size(entry.path)\n",
        "            except FileNotFoundError:\n",
        "                pass\n",
        "    return total\n",
        "def convert_bytes(num):\n",
        "    step_unit = 1000.0 #1024 bad the size\n",
        "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
        "        if num < step_unit:\n",
        "            return \"%3.1f %s\" % (num, x)\n",
        "        num /= step_unit\n",
        "\n",
        "def buildCachedModelManager(page):\n",
        "    global prefs\n",
        "    def scan_cache(e):\n",
        "      if not bool(prefs['cache_dir']):\n",
        "        alert_msg(page, \"You haven't set a Cache Directory in your Settings...\")\n",
        "        return\n",
        "      elif not os.path.isdir(prefs['cache_dir']):\n",
        "        alert_msg(page, \"The Cache Directory in your Settings can't be found...\")\n",
        "        return\n",
        "      if len(page.cached_folders.controls) > 1:\n",
        "        page.cached_folders.controls.clear()\n",
        "        page.cached_folders.update()\n",
        "      page.cached_folders.controls.append(Row([ProgressRing(), Text(f\"Scanning {prefs['cache_dir']}\")]))\n",
        "      dirs = [f.path for f in os.scandir(prefs['cache_dir']) if f.is_dir()]\n",
        "      del page.cached_folders.controls[-1]\n",
        "      page.cached_folders.update()\n",
        "      for dir in dirs:\n",
        "        page.cached_folders.controls.append(ListTile(title=Row([Text(f\".{slash}{dir.rpartition(slash)[2]}\", weight=FontWeight.BOLD), Text(\"\")], alignment=MainAxisAlignment.SPACE_BETWEEN), data=dir, dense=True, trailing=PopupMenuButton(icon=icons.MORE_VERT,\n",
        "          items=[PopupMenuItem(icon=icons.DELETE, text=\"Delete Model Directory\", on_click=del_dir, data=dir)])))\n",
        "        page.cached_folders.update()\n",
        "      for l in page.cached_folders.controls:\n",
        "        size = convert_bytes(get_directory_size(l.data))\n",
        "        l.title.controls[1].value = size\n",
        "        l.title.controls[1].update()\n",
        "        page.cached_folders.update()\n",
        "    def del_dir(e):\n",
        "      dir = e.control.data\n",
        "      shutil.rmtree(dir, ignore_errors=True)\n",
        "      for i, l in enumerate(page.cached_folders.controls):\n",
        "        if l.data == dir:\n",
        "          del page.cached_folders.controls[i]\n",
        "          page.cached_folders.update()\n",
        "          break\n",
        "      if prefs['enable_sounds']: e.page.snd_delete.play()\n",
        "    page.cached_folders = Column([])\n",
        "    c = Column([Container(\n",
        "      padding=padding.only(18, 14, 20, 10),\n",
        "      content=Column([\n",
        "        Text(\"üóÇÔ∏è   Manage your Cache Directory Saved Models\", style=TextThemeStyle.TITLE_LARGE),\n",
        "        Text(\"If you're cacheing your model files, it can fill up your drive space quickly, so you can trim the fat as needed... Redownloads when used.\"),\n",
        "        Divider(thickness=1, height=4),\n",
        "        \n",
        "        page.cached_folders,\n",
        "        ElevatedButton(content=Text(\"üîç  Scan Cache Dirctory\", size=18), on_click=scan_cache),\n",
        "      ]\n",
        "    ))], scroll=ScrollMode.AUTO)\n",
        "    return c\n",
        "\n",
        "use_custom_scheduler = False\n",
        "retry_attempts_if_NSFW = 3\n",
        "unet = None\n",
        "pipe = None\n",
        "pipe_img2img = None\n",
        "pipe_interpolation = None\n",
        "pipe_clip_guided = None\n",
        "pipe_conceptualizer = None\n",
        "pipe_repaint = None\n",
        "pipe_imagic = None\n",
        "pipe_composable = None\n",
        "pipe_safe = None\n",
        "pipe_versatile = None\n",
        "pipe_versatile_text2img = None\n",
        "pipe_versatile_variation = None\n",
        "pipe_versatile_dualguided = None\n",
        "pipe_upscale = None\n",
        "pipe_depth = None\n",
        "pipe_image_variation = None\n",
        "pipe_kandinsky = None\n",
        "stability_api = None\n",
        "model_path = \"CompVis/stable-diffusion-v1-4\"\n",
        "inpaint_model = \"stabilityai/stable-diffusion-2-inpainting\"\n",
        "#\"runwayml/stable-diffusion-inpainting\"\n",
        "scheduler = None\n",
        "scheduler_clip = None\n",
        "if is_Colab:\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "\n",
        "finetuned_models = [\n",
        "    #{\"name\": \"Stable Diffusion v1.5\", \"path\": \"runwayml/stable-diffusion-v1-5\", \"prefix\": \"\", \"revision\": \"fp16\"},\n",
        "    #{\"name\": \"Stable Diffusion v1.4\", \"path\": \"CompVis/stable-diffusion-v1-4\", \"prefix\": \"\", \"revision\": \"fp16\"},\n",
        "    {\"name\": \"Midjourney v4 style\", \"path\": \"prompthero/midjourney-v4-diffusion\", \"prefix\": \"mdjrny-v4 style \"},\n",
        "    {\"name\": \"Openjourney\", \"path\": \"prompthero/openjourney\", \"prefix\": \"mdjrny-v4 style \"},\n",
        "    {\"name\": \"Future Diffusion\", \"path\": \"nitrosocke/Future-Diffusion\", \"prefix\": \"future style \"},\n",
        "    {\"name\": \"Anything v3.0\", \"path\": \"Linaqruf/anything-v3.0\", \"prefix\": \"\"},\n",
        "    {\"name\": \"Analog Diffusion\", \"path\": \"wavymulder/Analog-Diffusion\", \"prefix\": \"analog style \"},\n",
        "    {\"name\": \"Architecture Diffusers\", \"path\": \"rrustom/stable-architecture-diffusers\", \"prefix\": \"\"},\n",
        "    {\"name\": \"Arcane\", \"path\":\"nitrosocke/Arcane-Diffusion\", \"prefix\":\"arcane style \"},\n",
        "    {\"name\": \"Archer Diffusion\", \"path\":\"nitrosocke/archer-diffusion\", \"prefix\":\"archer style \"},\n",
        "    {\"name\": \"Nitro Diffusion\", \"path\":\"nitrosocke/nitro-diffusion\", \"prefix\":\"archer style, arcane style, modern disney style \"},\n",
        "    {\"name\": \"Beeple Diffusion\", \"path\": \"riccardogiorato/beeple-diffusion\", \"prefix\": \"beeple style \"},\n",
        "    {\"name\": \"Elden Ring\", \"path\": \"nitrosocke/elden-ring-diffusion\", \"prefix\":\"elden ring style \"},\n",
        "    {\"name\": \"Modern Disney\", \"path\": \"nitrosocke/mo-di-diffusion\", \"prefix\": \"modern disney style \"},\n",
        "    {\"name\": \"Classic Disney\", \"path\": \"nitrosocke/classic-anim-diffusion\", \"prefix\": \"classic disney style \"},\n",
        "    {\"name\": \"Loving Vincent (Van Gogh)\", \"path\": \"dallinmackay/Van-Gogh-diffusion\", \"prefix\": \"lvngvncnt \"},\n",
        "    {\"name\": \"Redshift renderer (Cinema4D)\", \"path\": \"nitrosocke/redshift-diffusion\", \"prefix\": \"redshift style \"},\n",
        "    {\"name\": \"Waifu\", \"path\": \"hakurei/waifu-diffusion\", \"prefix\": \"\", \"revision\": \"fp16\"},\n",
        "    {\"name\": \"TrinArt Waifu 50-50\", \"path\": \"doohickey/trinart-waifu-diffusion-50-50\", \"prefix\": \"\"},\n",
        "    {\"name\": \"WikiArt v2\", \"path\": \"valhalla/sd-wikiart-v2\", \"prefix\": \"\"},\n",
        "    {\"name\": \"Jak's Woolitize\", \"path\": \"plasmo/woolitize\", \"prefix\": \"woolitize \"},\n",
        "    {\"name\": \"Inkpunk Diffusion\", \"path\": \"Envvi/Inkpunk-Diffusion\", \"prefix\": \"nvinkpunk \"},\n",
        "    {\"name\": \"Simpsons Model\", \"path\": \"Norod78/sd-simpsons-model\", \"prefix\":\"\"},\n",
        "    {\"name\": \"Spider-Verse\", \"path\": \"nitrosocke/spider-verse-diffusion\", \"prefix\":\"spiderverse style \"},\n",
        "    {\"name\": \"Pok√©mon\", \"path\": \"lambdalabs/sd-pokemon-diffusers\", \"prefix\": \"\"},\n",
        "    {\"name\": \"Pony Diffusion\", \"path\": \"AstraliteHeart/pony-diffusion\", \"prefix\": \"\"},\n",
        "    {\"name\": \"Robo Diffusion\", \"path\": \"nousr/robo-diffusion\", \"prefix\": \"\"},\n",
        "    {\"name\": \"Dungeons & Diffusion\", \"path\": \"0xJustin/Dungeons-and-Diffusion\", \"prefix\": \"\"},\n",
        "    {\"name\": \"Cyberpunk Anime\", \"path\": \"DGSpitzer/Cyberpunk-Anime-Diffusion\", \"prefix\": \"dgs illustration style \"},\n",
        "    {\"name\": \"Tron Legacy\", \"path\": \"dallinmackay/Tron-Legacy-diffusion\", \"prefix\": \"trnlgcy \"},\n",
        "    {\"name\": \"Guohua Diffusion\", \"path\": \"Langboat/Guohua-Diffusion\", \"prefix\": \"guohua style \"},\n",
        "    {\"name\": \"Trin-sama TrinArt\", \"path\": \"naclbit/trinart_stable_diffusion_v2\", \"prefix\": \"\", \"revision\": \"diffusers-115k\"},\n",
        "    {\"name\": \"Naruto Diffusers\", \"path\": \"lambdalabs/sd-naruto-diffusers\", \"prefix\": \"\"},\n",
        "    {\"name\": \"Zelda: Breath of The Wild\", \"path\": \"s3nh/zelda-botw-stable-diffusion\", \"prefix\": \"botw style \"},\n",
        "    {\"name\": \"JWST Deep Space Diffusion\", \"path\": \"dallinmackay/JWST-Deep-Space-diffusion\", \"prefix\": \"JWST \"},\n",
        "    #{\"name\": \"LinkedIn-diffusion\", \"path\": \"prompthero/linkedin-diffusion\", \"prefix\": \"lnkdn photography \"},\n",
        "    {\"name\": \"Bloodborne Diffusion\", \"path\": \"Guizmus/BloodborneDiffusion\", \"prefix\": \"Bloodborne Style \"},\n",
        "    {\"name\": \"Cats the Musical\", \"path\": \"dallinmackay/Cats-Musical-diffusion\", \"prefix\": \"ctsmscl \"},\n",
        "    {\"name\": \"Anon v1\", \"path\": \"TheMindExpansionNetwork/anonv1\", \"prefix\": \"AnonV1 \"},\n",
        "    {\"name\": \"Avatar\", \"path\": \"Jersonm89/Avatar\", \"prefix\": \"avatar style \"},\n",
        "    {\"name\": \"Dreamlike Diffusion v1\", \"path\": \"dreamlike-art/dreamlike-diffusion-1.0\", \"prefix\": \"dreamlikeart \"},\n",
        "    {\"name\": \"Glitch\", \"path\": \"BakkerHenk/glitch\", \"prefix\": \"a photo in sks glitched style \"},\n",
        "    {\"name\": \"Knollingcase\", \"path\": \"Aybeeceedee/knollingcase\", \"prefix\": \"knollingcase \"},\n",
        "    {\"name\": \"Wavy Diffusion\", \"path\": \"wavymulder/wavyfusion\", \"prefix\": \"wa-vy style \"},\n",
        "    {\"name\": \"TARDISfusion Classic Tardis\", \"path\": \"Guizmus/Tardisfusion\", \"prefix\": \"Classic Tardis style \"},\n",
        "    {\"name\": \"TARDISfusion Modern Tardis\", \"path\": \"Guizmus/Tardisfusion\", \"prefix\": \"Modern Tardis style \"},\n",
        "    {\"name\": \"TARDISfusion Tardis Box\", \"path\": \"Guizmus/Tardisfusion\", \"prefix\": \"Tardis Box style \"},\n",
        "    #{\"name\": \"Studio Ghibli\", \"path\": \"flax/StudioGhibli\", \"prefix\": \"\", \"vae\": True},\n",
        "    #{\"name\": \"Picture of the Week\", \"path\": \"Guizmus/SD_PoW_Collection\", \"prefix\": \"PoW Style \", \"vae\": True},\n",
        "    #{\"name\": \"PoW Bendstract \", \"path\": \"Guizmus/SD_PoW_Collection\", \"prefix\": \"Bendstract Style \", \"vae\": True},\n",
        "    #{\"name\": \"PoW BendingReality\", \"path\": \"Guizmus/SD_PoW_Collection\", \"prefix\": \"BendingReality Style \", \"vae\": True},\n",
        "    #{\"name\": \"3d Illustration\", \"path\": \"aidystark/3Dillustration-stable-diffusion\", \"prefix\": \"3d illustration style \", \"vae\": True},\n",
        "    #{\"name\": \"megaPals Vintage\", \"path\": \"elRivx/megaPals\", \"prefix\": \"megaPals style \"},\n",
        "    #{\"name\": \"Epic Space Machine\", \"path\": \"rabidgremlin/sd-db-epic-space-machine\", \"prefix\": \"EpicSpaceMachine \"},\n",
        "    #{\"name\": \"Ouroboros\", \"path\": \"Eppinette/Ouroboros\", \"prefix\": \"m_ouroboros style \"},\n",
        "    #{\"name\": \"Neko Girls\", \"path\": \"Nerfgun3/NekoModel\", \"prefix\": \"neko \"},\n",
        "    #{\"name\": \"New Horror Fantasy\", \"path\": \"elRivx/sd-newhorrorfantasy_style\", \"prefix\": \"newhorrorfantasy_style \"},\n",
        "    #{\"name\": \"DCAU Batman\", \"path\": \"IShallRiseAgain/DCAU\", \"prefix\": \"Batman_the_animated_series \"},\n",
        "    #{\"name\": \"Smoke Diffusion\", \"path\": \"guumaster/smoke-diffusion\", \"prefix\": \"ssmoky \"},\n",
        "    #{\"name\": \"reasonableDrink Dreams\", \"path\": \"elRivx/reasonableDrink\", \"prefix\": \"reasonableDrink \"},\n",
        "]\n",
        "dreambooth_models = [{'name': 'disco-diffusion-style', 'token': 'a photo of ddfusion style'}, {'name': 'cat-toy', 'token': 'a photo of sks toy'}, {'name': 'herge-style', 'token': 'a photo of sks herge_style'}, {'name': 'alberto-pablo', 'token': 'a photo of sks Alberto'}, {'name': 'noggles-sd15-800-4e6', 'token': 'someone wearing sks glasses'}, {'name': 'spacecat', 'token': 'a photo of sks spacecat'}, {'name': 'pikachu', 'token': 'pikachu'}, {'name': 'kaltsit', 'token': 'kaltsit'}, {'name': 'robeez-baby-girl-water-shoes', 'token': 'a photo of sks  shoes'}, {'name': 'mertgunhan', 'token': 'mertgunhan'}, {'name': 'soydavidtapia', 'token': 'a photo of david tapia'}, {'name': 'spacecat0001', 'token': 'a photo of sks spacecat'}, {'name': 'noggles-glasses-600', 'token': 'a photo of a person wearing sks glasses'}, {'name': 'mario-action-figure', 'token': 'a photo of sks action figure'}, {'name': 'tattoo-design', 'token': 'line art sks tattoo design'}, {'name': 'danielveneco2', 'token': 'danielveneco'}, {'name': 'scarlet-witch-two', 'token': 'a photo of scarletwi person'}, {'name': 'angus-mcbride-style', 'token': 'angus mcbride style'}, {'name': 'mirtha-legrand', 'token': 'a photo of sks mirtha legrand'}, {'name': 'kiril', 'token': 'kiril'}, {'name': 'mr-potato-head', 'token': 'a photo of sks mr potato head'}, {'name': 'homelander', 'token': 'a photo of homelander guy'}, {'name': 'king-dog-sculpture', 'token': 'a photo of sks king dog sculpture'}, {'name': 'pedrocastillodonkey', 'token': 'a photo of PedroCastilloDonkey'}, {'name': 'xogren', 'token': 'a photo of xogren'}, {'name': 'emily-carroll-style', 'token': 'a detailed digital matte illustration by sks'}, {'name': 'sneaker', 'token': 'a photo of sks sneaker'}, {'name': 'rajj', 'token': 'a photo of sks man face'}, {'name': 'puuung', 'token': 'Puuung'}, {'name': 'partis', 'token': 'a photo of sks partis'}, {'name': 'alien-coral', 'token': 'a photo of sks alien coral'}, {'name': 'hensley-art-style', 'token': 'a painting in style of sks'}, {'name': 'tails-from-sonic', 'token': 'tails'}, {'name': 'ba-shiroko', 'token': 'a photo of sks shiroko'}, {'name': 'marina', 'token': 'marina'}, {'name': 'noggles-glasses-1200', 'token': 'a photo of a person wearing sks glasses'}, {'name': 'a-hat-in-time-girl', 'token': 'a render of sks'}, {'name': 'axolotee', 'token': 'a photo of sks Axolote'}, {'name': 'transparent-90s-console', 'token': 'a photo of sks handheld gaming console'}, {'name': 'andynsane', 'token': 'a photo of sks andynsane'}, {'name': 'tanidareal-v1', 'token': 'tanidareal'}, {'name': 'adventure-time-style', 'token': 'advtime style'}, {'name': 'sks-rv', 'token': 'a photo of sks rv'}, {'name': 'neff-voice-amp-2', 'token': 'a photo of sks neff voice amp #1'}, {'name': '27-from-mayonnaise-salesmen', 'token': 'a drawing of 27 from Mayonnaise SalesMen'}, {'name': 'baracus', 'token': 'b.a. baracus mr t'}, {'name': 'tahdig-rice', 'token': 'tahmricdig'}, {'name': 'angus-mcbride-style-v4', 'token': 'mcbride_style'}, {'name': 'the-witcher-game-ciri', 'token': 'a photo of a sks woman with white hair'}, {'name': 'paolo-bonolis', 'token': 'a photo of sks paolo bonolis'}, {'name': 'the-child', 'token': 'a photo of a mini australian shepherd with a slight underbite sks'}, {'name': 'gomber', 'token': 'a photo of sks toy'}, {'name': 'backpack', 'token': 'a photo of sks backpack'}, {'name': 'ricky-fort', 'token': 'a photo of sks ricky fort'}, {'name': 'mate', 'token': 'a photo of sks mate'}, {'name': 'zombie-head', 'token': 'a photo of sks zombie'}, {'name': 'leone-from-akame-ga-kill-v2', 'token': 'an anime woman character of sks'}, {'name': 'face2contra', 'token': 'a photo of sks face2contra'}, {'name': 'yakuza-0-kiryu-kazuma', 'token': 'photo of sks kiryu'}, {'name': 'gemba-cat', 'token': 'a photo of sks cat'}, {'name': 'angus-mcbride-v-3', 'token': 'angus mcbride style'}, {'name': 'california-gurls-music-video', 'token': 'caligurls'}, {'name': 'solo-levelling-art-style', 'token': 'sololeveling'}, {'name': 'blue-lightsaber-toy', 'token': 'a photo of sks toy'}, {'name': 'dmt-entity', 'token': 'a photo of sks DMT Entity'}, {'name': 'yingdream', 'token': 'a photo of an anime girl'}, {'name': 'kamenridergeats', 'token': 'a photo of kamenridergeats'}, {'name': 'quino', 'token': 'a photo of sks quino'}, {'name': 'digimon-adventure-anime-background-style', 'token': 'a landscape in sks style'}, {'name': 'evangelion-mech-unit-01', 'token': 'rendering of sks evangelion mech'}, {'name': 'elvis', 'token': 'elvis'}, {'name': 'musical-isotope', 'token': 'mi'}, {'name': 'tempa', 'token': 'a photo of sks Tempa'}, {'name': 'tempa2', 'token': 'a photo of sks Tempa'}, {'name': 'froggewut', 'token': 'a painting in the style of sks'}, {'name': 'smiling-friends-cartoon-style', 'token': 'a photo in style of sks'}, {'name': 'smario-world-map', 'token': 'a map in style of sks'}, {'name': 'edd', 'token': 'sks boy smiles'}, {'name': 'fang-yuan-002', 'token': 'an anime art of sks Fang_Yuan'}, {'name': 'langel', 'token': 'Langel'}, {'name': 'arthur-leywin', 'token': 'a photo of sks guy'}, {'name': 'kid-chameleon-character', 'token': 'kid-chameleon-character'}, {'name': 'road-to-ruin', 'token': 'starry night. sks themed level design. tiki ruins, stone statues, night sky and black silhouettes'}, {'name': 'vaporfades', 'token': 'an image in the style of sks'}, {'name': 'beard-oil-big-sur', 'token': 'a photo of sks beard oil'}, {'name': 'monero', 'token': 'a logo of sks'}, {'name': 'yagami-taichi-from-digimon-adventure-1999', 'token': 'an anime boy character of sks'}, {'name': 'duregar', 'token': 'a painting of sks character'}, {'name': 'pathfinder-iconics', 'token': 'drawing in the style of sks'}, {'name': 'tyxxxszv', 'token': 'tyxxxszv'}, {'name': 'Origtron', 'token': 'Entry not found'}, {'name': 'oleg-kog', 'token': 'oleg'}, {'name': 'mau-cat', 'token': 'a photo of sks cat'}, {'name': 'justinkrane-artwork', 'token': 'art by sks JustinKrane'}, {'name': 'little-mario-jumping', 'token': 'a screenshot of tiny sks character'}, {'name': 'blue-moo-moo', 'token': 'an image of sks creature'}, {'name': 'noggles-render-1k', 'token': 'a render of sks'}, {'name': 'metahuman-rkr', 'token': 'a photo of sks rkr'}, {'name': 'taras', 'token': 'photo of sks taras'}, {'name': 'rollerbeetle', 'token': 'a photo of rollerbeetle mount'}, {'name': 'joseph-russel-ammen', 'token': 'Joseph Russel Ammen'}, {'name': 'manybearsx', 'token': 'a photo of sks drawing'}, {'name': 'mexican-concha', 'token': 'a photo of sks Mexican Concha'}, {'name': 'angus-mcbride-style-v2', 'token': 'angus mcbride style'} ]\n",
        "\n",
        "def get_model(name):\n",
        "  #dropdown.Option(\"Stable Diffusion v1.5\"), dropdown.Option(\"Stable Diffusion v1.4\", dropdown.Option(\"Community Finetuned Model\", dropdown.Option(\"DreamBooth Library Model\"), dropdown.Option(\"Custom Model Path\")\n",
        "  if name == \"Stable Diffusion v2.1 x768\":\n",
        "    return {'name':'Stable Diffusion v2.1 x768', 'path':'stabilityai/stable-diffusion-2-1', 'prefix':'fp16'}\n",
        "  elif name == \"Stable Diffusion v2.1 x512\":\n",
        "    return {'name':'Stable Diffusion v2.1 x512', 'path':'stabilityai/stable-diffusion-2-1-base', 'prefix':''}\n",
        "  elif name == \"Stable Diffusion v2.0\":\n",
        "    return {'name':'Stable Diffusion v2.0', 'path':'stabilityai/stable-diffusion-2', 'prefix':'', 'revision': 'fp16'}\n",
        "  elif name == \"Stable Diffusion v2.0 x768\":\n",
        "    return {'name':'Stable Diffusion v2.0 x768', 'path':'stabilityai/stable-diffusion-2', 'prefix':'', 'revision': 'fp16'}\n",
        "  elif name == \"Stable Diffusion v2.0 x512\":\n",
        "    return {'name':'Stable Diffusion v2.0 x512', 'path':'stabilityai/stable-diffusion-2-base', 'prefix':'', 'revision': 'fp16'}\n",
        "  elif name == \"Stable Diffusion v1.5\":\n",
        "    return {'name':'Stable Diffusion v1.5', 'path':'runwayml/stable-diffusion-v1-5', 'prefix':'', 'revision': 'fp16'}\n",
        "  elif name == \"Stable Diffusion v1.4\":\n",
        "    return {'name':'Stable Diffusion v1.4', 'path':'CompVis/stable-diffusion-v1-4', 'prefix':'', 'revision': 'fp16'}\n",
        "  elif name == \"Community Finetuned Model\":\n",
        "    return get_finetuned_model(prefs['finetuned_model'])\n",
        "  elif name == \"DreamBooth Library Model\":\n",
        "    return get_dreambooth_model(prefs['dreambooth_model'])\n",
        "  elif name == \"Custom Model Path\":\n",
        "    return {'name':'Custom Model', 'path':prefs['custom_model'], 'prefix':''}\n",
        "  else:\n",
        "    return {'name':'', 'path':'', 'prefix':''}\n",
        "def get_finetuned_model(name):\n",
        "  for mod in finetuned_models:\n",
        "      if mod['name'] == name:\n",
        "        return mod\n",
        "  return {'name':'', 'path':'', 'prefix':''}\n",
        "def get_dreambooth_model(name):\n",
        "  for mod in dreambooth_models:\n",
        "      if mod['name'] == name:\n",
        "        return {'name':mod['name'], 'path':f'sd-dreambooth-library/{mod[\"name\"]}', 'prefix':mod['token']}\n",
        "  return {'name':'', 'path':'', 'prefix':''}\n",
        "\n",
        "def get_diffusers(page):\n",
        "    global scheduler, use_custom_scheduler, model_path, prefs, status\n",
        "    try:\n",
        "      import transformers\n",
        "      #print(f\"transformers=={transformers.__version__}\")\n",
        "      if transformers.__version__ == \"4.21.3\": #Workaround because CLIP-Interrogator required other version\n",
        "        run_process(\"pip uninstall -y git+https://github.com/pharmapsychotic/BLIP.git@lib#egg=blip\", realtime=False)\n",
        "        run_process(\"pip uninstall -y clip-interrogator\", realtime=False)\n",
        "        run_process(\"pip uninstall -y transformers\", realtime=False)\n",
        "        #run_process(\"pip uninstall -q transformers==4.21.3\", page=page, realtime=False)\n",
        "      if transformers.__version__ == \"4.23.1\": # Kandinsky conflict\n",
        "        run_process(\"pip uninstall -y transformers\", realtime=False)\n",
        "    except Exception:\n",
        "      pass\n",
        "    try:\n",
        "      from huggingface_hub import notebook_login, HfApi, HfFolder, login\n",
        "      from diffusers import StableDiffusionPipeline, logging\n",
        "    except ModuleNotFoundError as e:\n",
        "      run_process(\"pip install -q --upgrade git+https://github.com/huggingface/accelerate.git\", page=page)\n",
        "      run_process(\"pip install -q --upgrade git+https://github.com/Skquark/diffusers.git@main#egg=diffusers[torch]\", page=page)\n",
        "      run_process(\"pip install -q --upgrade git+https://github.com/huggingface/transformers\")\n",
        "      #run_process(\"pip install -q transformers==4.23.1\", page=page)\n",
        "      run_process(\"pip install -q --upgrade scipy ftfy\", page=page)\n",
        "      run_process('pip install -qq \"ipywidgets>=7,<8\"', page=page)\n",
        "      run_process(\"git config --global credential.helper store\", page=page)\n",
        "      if prefs['memory_optimization'] == 'Xformers Mem Efficient Attention':\n",
        "        # Still not the best way.  TODO: Fix importing, try ninja?\n",
        "        page.console_msg(\"Installing FaceBook's Xformers Memory Efficient Package...\")\n",
        "        run_process(\"pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\", page=page)\n",
        "        #run_process(\"pip install https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\", page=page)\n",
        "        page.banner.open = False\n",
        "        page.banner.update()\n",
        "      from huggingface_hub import notebook_login, HfApi, HfFolder, login\n",
        "      from diffusers import StableDiffusionPipeline, logging\n",
        "      pass\n",
        "    logging.set_verbosity_error()\n",
        "    if not os.path.exists(HfFolder.path_token):\n",
        "        #from huggingface_hub.commands.user import _login\n",
        "        #_login(HfApi(), token=prefs['HuggingFace_api_key'])\n",
        "        login(token=prefs['HuggingFace_api_key'], add_to_git_credential=True)\n",
        "    #if prefs['model_ckpt'] == \"Stable Diffusion v1.5\": model_path =  \"runwayml/stable-diffusion-v1-5\"\n",
        "    #elif prefs['model_ckpt'] == \"Stable Diffusion v1.4\": model_path =  \"CompVis/stable-diffusion-v1-4\"\n",
        "    model = get_model(prefs['model_ckpt'])\n",
        "    model_path = model['path']\n",
        "    scheduler = model_scheduler(model_path)\n",
        "    status['finetuned_model'] = False if model['name'].startswith(\"Stable\") else True\n",
        "\n",
        "def model_scheduler(model, big3=False):\n",
        "    scheduler_mode = prefs['scheduler_mode']\n",
        "    if scheduler_mode == \"K-LMS\":\n",
        "      from diffusers import LMSDiscreteScheduler\n",
        "      s = LMSDiscreteScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"PNDM\":\n",
        "      from diffusers import PNDMScheduler\n",
        "      s = PNDMScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"DDIM\":\n",
        "      from diffusers import DDIMScheduler\n",
        "      s = DDIMScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif big3:\n",
        "      from diffusers import DDIMScheduler\n",
        "      s = DDIMScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"DPM Solver\":\n",
        "      from diffusers import DPMSolverMultistepScheduler #\"hf-internal-testing/tiny-stable-diffusion-torch\"\n",
        "      s = DPMSolverMultistepScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"DPM Solver Singlestep\":\n",
        "      from diffusers import DPMSolverSinglestepScheduler\n",
        "      s = DPMSolverSinglestepScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"K-Euler Discrete\":\n",
        "      from diffusers import EulerDiscreteScheduler\n",
        "      s = EulerDiscreteScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"K-Euler Ancestrial\":\n",
        "      from diffusers import EulerAncestralDiscreteScheduler\n",
        "      s = EulerAncestralDiscreteScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"DPM Solver++\":\n",
        "      from diffusers import DPMSolverMultistepScheduler\n",
        "      s = DPMSolverMultistepScheduler(\n",
        "        beta_start=0.00085,\n",
        "        beta_end=0.012,\n",
        "        beta_schedule=\"scaled_linear\",\n",
        "        num_train_timesteps=1000,\n",
        "        trained_betas=None,\n",
        "        #predict_epsilon=True,\n",
        "        prediction_type=\"v_prediction\" if model.startswith('stabilityai') else \"epsilon\",\n",
        "        thresholding=False,\n",
        "        algorithm_type=\"dpmsolver++\",\n",
        "        solver_type=\"midpoint\",\n",
        "        #denoise_final=True,\n",
        "        lower_order_final=True,\n",
        "      )\n",
        "    elif scheduler_mode == \"Heun Discrete\":\n",
        "      from diffusers import HeunDiscreteScheduler\n",
        "      s = HeunDiscreteScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"K-DPM2 Ancestral\":\n",
        "      from diffusers import KDPM2AncestralDiscreteScheduler\n",
        "      s = KDPM2AncestralDiscreteScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"K-DPM2 Discrete\":\n",
        "      from diffusers import KDPM2DiscreteScheduler\n",
        "      s = KDPM2DiscreteScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"IPNDM\":\n",
        "      from diffusers import IPNDMScheduler\n",
        "      s = IPNDMScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    elif scheduler_mode == \"Score-SDE-Vp\":\n",
        "      from diffusers import ScoreSdeVpScheduler\n",
        "      s = ScoreSdeVpScheduler() #(num_train_timesteps=2000, beta_min=0.1, beta_max=20, sampling_eps=1e-3, tensor_format=\"np\")\n",
        "      use_custom_scheduler = True\n",
        "    elif scheduler_mode == \"Score-SDE-Ve\":\n",
        "      from diffusers import ScoreSdeVeScheduler\n",
        "      s = ScoreSdeVeScheduler() #(num_train_timesteps=2000, snr=0.15, sigma_min=0.01, sigma_max=1348, sampling_eps=1e-5, correct_steps=1, tensor_format=\"pt\"\n",
        "      use_custom_scheduler = True\n",
        "    elif scheduler_mode == \"DDPM\":\n",
        "      from diffusers import DDPMScheduler\n",
        "      s = DDPMScheduler(num_train_timesteps=1000, beta_start=0.0001, beta_end=0.02, beta_schedule=\"linear\", trained_betas=None, variance_type=\"fixed_small\", clip_sample=True, tensor_format=\"pt\")\n",
        "      use_custom_scheduler = True\n",
        "    elif scheduler_mode == \"Karras-Ve\":\n",
        "      from diffusers import KarrasVeScheduler\n",
        "      s = KarrasVeScheduler() #(sigma_min=0.02, sigma_max=100, s_noise=1.007, s_churn=80, s_min=0.05, s_max=50, tensor_format=\"pt\")\n",
        "      use_custom_scheduler = True\n",
        "    elif scheduler_mode == \"LMS\": #no more\n",
        "      from diffusers import LMSScheduler\n",
        "      s = LMSScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "      #(num_train_timesteps=1000, beta_start=0.0001, beta_end=0.02, beta_schedule=\"linear\", trained_betas=None, timestep_values=None, tensor_format=\"pt\")\n",
        "      use_custom_scheduler = True\n",
        "    #print(f\"Loaded Schedueler {scheduler_mode} {type(scheduler)}\")\n",
        "    else:\n",
        "      print(f\"Unknown scheduler request {scheduler_mode} - Using K-LMS\")\n",
        "      from diffusers import LMSDiscreteScheduler\n",
        "      s = LMSDiscreteScheduler.from_pretrained(model, subfolder=\"scheduler\")\n",
        "    return s\n",
        "\n",
        "\n",
        "torch_device = \"cuda\"\n",
        "try:\n",
        "    import torch\n",
        "except Exception:\n",
        "    print(\"Installing PyTorch with CUDA 1.17\")\n",
        "    run_sp(\"pip install -U --force-reinstall torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117\", realtime=False)\n",
        "    import torch\n",
        "    pass\n",
        "finally:\n",
        "    torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    if torch_device == \"cpu\": print(\"WARNING: CUDA is only available with CPU, so GPU tasks are limited. Can use Stability-API & OpenAI, but not Diffusers...\")\n",
        "import gc\n",
        "#from torch.amp.autocast_mode import autocast\n",
        "from random import random\n",
        "import time\n",
        "\n",
        "pb = ProgressBar(width=420, bar_height=8)\n",
        "total_steps = args['steps']\n",
        "def callback_fn(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n",
        "    callback_fn.has_been_called = True\n",
        "    global total_steps, pb\n",
        "    if total_steps is None: total_steps = timestep\n",
        "    if total_steps == 0: total_steps = len(latents)\n",
        "    percent = (step +1)/ total_steps\n",
        "    pb.value = percent\n",
        "    pb.tooltip = f\"[{step +1} / {total_steps}] (timestep: {timestep})\"\n",
        "    #print(f\"step: {step}, total: {total_steps}, latent: {len(latents)}\")\n",
        "    #if step == 0:\n",
        "        #latents = latents.detach().cpu().numpy()\n",
        "        #assert latents.shape == (1, 4, 64, 64)\n",
        "        #latents_slice = latents[0, -3:, -3:, -1]\n",
        "        #expected_slice = np.array([1.8285, 1.2857, -0.1024, 1.2406, -2.3068, 1.0747, -0.0818, -0.6520, -2.9506])\n",
        "        #assert np.abs(latents_slice.flatten() - expected_slice).max() < 1e-3\n",
        "    pb.update()\n",
        "\n",
        "def optimize_pipe(p, vae=True):\n",
        "    if prefs['sequential_cpu_offload']:\n",
        "      p.enable_sequential_cpu_offload()\n",
        "    if prefs['memory_optimization'] == 'Attention Slicing':\n",
        "      #if not model['name'].startswith('Stable Diffusion v2'): #TEMP hack until it updates my git with fix\n",
        "      if prefs['sequential_cpu_offload']:\n",
        "        p.enable_attention_slicing(1)\n",
        "      else:\n",
        "        p.enable_attention_slicing()\n",
        "    elif prefs['memory_optimization'] == 'Xformers Mem Efficient Attention':\n",
        "      p.enable_xformers_memory_efficient_attention()\n",
        "    if prefs['vae_slicing'] and vae:\n",
        "      p.enable_vae_slicing()\n",
        "    return p\n",
        "\n",
        "def get_text2image(page):\n",
        "    os.chdir(root_dir)\n",
        "    global pipe, unet, scheduler, prefs\n",
        "    def open_url(e):\n",
        "      page.launch_url(e.data)\n",
        "    if pipe is not None:\n",
        "        #print(\"Clearing the ol' pipe first...\")\n",
        "        del pipe\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        pipe = None\n",
        "    try:\n",
        "      if use_custom_scheduler:\n",
        "        from transformers import CLIPTextModel, CLIPTokenizer\n",
        "        from diffusers import AutoencoderKL, UNet2DConditionModel\n",
        "        # 1. Load the autoencoder model which will be used to decode the latents into image space. \n",
        "        vae = AutoencoderKL.from_pretrained(model_path, subfolder=\"vae\", use_auth_token=True)\n",
        "        # 2. Load the tokenizer and text encoder to tokenize and encode the text. \n",
        "        tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "        text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "        if prefs['higher_vram_mode']:\n",
        "          unet = UNet2DConditionModel.from_pretrained(model_path, subfolder=\"unet\", use_auth_token=True, device_map=\"auto\")\n",
        "        else:\n",
        "          unet = UNet2DConditionModel.from_pretrained(model_path, revision=\"fp16\", torch_dtype=torch.float16, subfolder=\"unet\", use_auth_token=True, device_map=\"auto\")\n",
        "        vae = vae.to(torch_device)\n",
        "        text_encoder = text_encoder.to(torch_device)\n",
        "        #if enable_attention_slicing:\n",
        "        #  unet.enable_attention_slicing() #slice_size\n",
        "        unet = unet.to(torch_device)\n",
        "      else:\n",
        "        #if status['finetuned_model']: pipe = get_txt2img_pipe()\n",
        "        #else:\n",
        "        pipe = get_lpw_pipe()\n",
        "    except EnvironmentError as e:\n",
        "      model = get_model(prefs['model_ckpt'])\n",
        "      model_url = f\"https://huggingface.co/{model['path']}\"\n",
        "      alert_msg(page, f'ERROR: Looks like you need to accept the HuggingFace {model[\"name\"]} Model Cards to use Checkpoint',\n",
        "                content=Markdown(f'[{model_url}]({model_url})<br>{e}', on_tap_link=open_url))\n",
        "\n",
        "# I thought it's what I wanted, but current implementation does same as mine but doesn't clear memory between\n",
        "def get_mega_pipe():\n",
        "  global pipe, scheduler, model_path, prefs\n",
        "  from diffusers import DiffusionPipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  \n",
        "  if prefs['higher_vram_mode']:\n",
        "    pipe = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"stable_diffusion_mega\", scheduler=scheduler, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"))\n",
        "    #pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"))\n",
        "  else:\n",
        "    pipe = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"stable_diffusion_mega\", scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"))\n",
        "    #pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"))\n",
        "  pipe = pipe.to(torch_device)\n",
        "  pipe = optimize_pipe(pipe)\n",
        "  pipe.set_progress_bar_config(disable=True)\n",
        "  return pipe\n",
        "\n",
        "def get_lpw_pipe():\n",
        "  global pipe, scheduler, model_path, prefs\n",
        "  from diffusers import DiffusionPipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  from diffusers import AutoencoderKL, UNet2DConditionModel\n",
        "  model = get_model(prefs['model_ckpt'])\n",
        "  os.chdir(root_dir)\n",
        "  #if not os.path.isfile(os.path.join(root_dir, 'lpw_stable_diffusion.py')):\n",
        "  #  run_sp(\"wget -q --show-progress --no-cache --backups=1 https://raw.githubusercontent.com/Skquark/diffusers/main/examples/community/lpw_stable_diffusion.py\")\n",
        "  #from lpw_stable_diffusion import StableDiffusionLongPromptWeightingPipeline\n",
        "  if prefs['higher_vram_mode'] or model['name'] == \"Stable Diffusion v2.1 x768\": #, revision=\"fp32\"\n",
        "    pipe = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"AlanB/lpw_stable_diffusion_mod\", scheduler=scheduler, cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None, torch_dtype=torch.float32, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\").to(torch_device), feature_extractor=None, requires_safety_checker=not prefs['disable_nsfw_filter'])\n",
        "  else:\n",
        "    if 'revision' in model:\n",
        "      pipe = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"AlanB/lpw_stable_diffusion_mod\", scheduler=scheduler, cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None, revision=model['revision'], torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\").to(torch_device), device_map=\"auto\", feature_extractor=None, requires_safety_checker=not prefs['disable_nsfw_filter'])\n",
        "    else:\n",
        "      if 'vae' in model:\n",
        "        from diffusers import AutoencoderKL, UNet2DConditionModel\n",
        "        vae = AutoencoderKL.from_pretrained(model_path, subfolder=\"vae\", torch_dtype=torch.float16)\n",
        "        unet = UNet2DConditionModel.from_pretrained(model_path, subfolder=\"unet\", torch_dtype=torch.float16)\n",
        "        pipe = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"AlanB/lpw_stable_diffusion_mod\", vae=vae, unet=unet, scheduler=scheduler, cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None, torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\").to(torch_device), device_map=\"auto\", feature_extractor=None, requires_safety_checker=not prefs['disable_nsfw_filter'])\n",
        "      else:\n",
        "        pipe = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"AlanB/lpw_stable_diffusion_mod\", scheduler=scheduler, cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None, torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\").to(torch_device), device_map=\"auto\", feature_extractor=None, requires_safety_checker=not prefs['disable_nsfw_filter'])\n",
        "    #pipe = DiffusionPipeline.from_pretrained(model_path, community=\"lpw_stable_diffusion\", scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"))\n",
        "  #if prefs['enable_attention_slicing']: pipe.enable_attention_slicing()\n",
        "  pipe = pipe.to(torch_device)\n",
        "  pipe = optimize_pipe(pipe)\n",
        "  pipe.set_progress_bar_config(disable=True)\n",
        "  return pipe\n",
        "\n",
        "def get_txt2img_pipe():\n",
        "  global pipe, scheduler, model_path, prefs, status\n",
        "  from diffusers import StableDiffusionPipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  #from diffusers import AutoencoderKL, UNet2DConditionModel\n",
        "  #if status['finetuned_model']:\n",
        "  #  vae = AutoencoderKL.from_pretrained(model_path, subfolder=\"vae\", torch_dtype=torch.float16)\n",
        "  #  unet = UNet2DConditionModel.from_pretrained(model_path, subfolder=\"unet\", torch_dtype=torch.float16)\n",
        "  pipe = optimize_pipe(pipe)\n",
        "  pipe.set_progress_bar_config(disable=True)\n",
        "  pipe = pipe.to(torch_device)\n",
        "  return pipe\n",
        "\n",
        "def get_unet_pipe():\n",
        "  global unet, scheduler, model_path, prefs\n",
        "  from transformers import CLIPTextModel, CLIPTokenizer\n",
        "  from diffusers import AutoencoderKL, UNet2DConditionModel\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  # 1. Load the autoencoder model which will be used to decode the latents into image space. \n",
        "  vae = AutoencoderKL.from_pretrained(model_path, subfolder=\"vae\")\n",
        "  # 2. Load the tokenizer and text encoder to tokenize and encode the text. \n",
        "  tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "  text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "  if prefs['higher_vram_mode']:\n",
        "    unet = UNet2DConditionModel.from_pretrained(model_path, subfolder=\"unet\", feature_extractor=None, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), device_map=\"auto\")\n",
        "  else:\n",
        "    unet = UNet2DConditionModel.from_pretrained(model_path, revision=\"fp16\", feature_extractor=None, torch_dtype=torch.float16, subfolder=\"unet\", safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), device_map=\"auto\")\n",
        "  vae = vae.to(torch_device)\n",
        "  text_encoder = text_encoder.to(torch_device)\n",
        "  #if enable_attention_slicing:\n",
        "  #  unet.enable_attention_slicing() #slice_size\n",
        "  unet = unet.to(torch_device)\n",
        "  return unet\n",
        "\n",
        "def get_interpolation(page):\n",
        "    from diffusers import DDIMScheduler, PNDMScheduler, LMSDiscreteScheduler\n",
        "    import torch, gc\n",
        "    global pipe_interpolation\n",
        "    torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    if pipe_interpolation is not None:\n",
        "      #print(\"Clearing the ol' pipe first...\")\n",
        "      del pipe_interpolation\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      pipe_interpolation = None\n",
        "\n",
        "    pipe_interpolation = get_interpolation_pipe()\n",
        "    run_process(\"pip install watchdog -q\", page=page, realtime=False)\n",
        "    status['loaded_interpolation'] = True\n",
        "\n",
        "def get_interpolation_pipe():\n",
        "    global pipe_interpolation, scheduler, model_path, prefs\n",
        "    from diffusers import StableDiffusionPipeline\n",
        "    from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "    os.chdir(root_dir)\n",
        "    if not os.path.isfile(os.path.join(root_dir, 'clip_guided_stable_diffusion.py')):\n",
        "      run_sp(\"wget -q --show-progress --no-cache --backups=1 https://raw.githubusercontent.com/Skquark/diffusers/main/examples/community/interpolate_stable_diffusion.py\")\n",
        "    from interpolate_stable_diffusion import StableDiffusionWalkPipeline\n",
        "    model = get_model(prefs['model_ckpt'])\n",
        "    if prefs['higher_vram_mode']:\n",
        "      pipe_interpolation = StableDiffusionWalkPipeline.from_pretrained(model_path, scheduler=scheduler, cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None)\n",
        "      #pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"))\n",
        "    else:\n",
        "      if 'revision' in model:\n",
        "        pipe_interpolation = StableDiffusionWalkPipeline.from_pretrained(model_path, scheduler=scheduler, cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None, revision=model['revision'], torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None)\n",
        "      else:\n",
        "        pipe_interpolation = StableDiffusionWalkPipeline.from_pretrained(model_path, scheduler=scheduler, cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None, torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None)\n",
        "      #pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"))\n",
        "    pipe_interpolation = pipe_interpolation.to(torch_device)\n",
        "    pipe_interpolation = optimize_pipe(pipe_interpolation, vae=False)\n",
        "    pipe_interpolation.set_progress_bar_config(disable=True)\n",
        "    return pipe_interpolation\n",
        "\n",
        "def get_image2image(page):\n",
        "    from diffusers import StableDiffusionInpaintPipeline, DDIMScheduler, PNDMScheduler, LMSDiscreteScheduler\n",
        "    import torch, gc\n",
        "    global pipe_img2img\n",
        "    def open_url(e):\n",
        "      page.launch_url(e.data)\n",
        "    torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    if pipe_img2img is not None:\n",
        "      #print(\"Clearing the ol' pipe first...\")\n",
        "      del pipe_img2img\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      pipe_img2img = None\n",
        "    try:\n",
        "      pipe_img2img = get_img2img_pipe()\n",
        "    except EnvironmentError:\n",
        "      model_url = f\"https://huggingface.co/{inpaint_model}\"\n",
        "      alert_msg(page, f'ERROR: Looks like you need to accept the HuggingFace Inpainting Model Card to use Checkpoint',\n",
        "                content=Markdown(f'[{model_url}]({model_url})', on_tap_link=open_url))\n",
        "    loaded_img2img = True\n",
        "\n",
        "def get_img2img_pipe():\n",
        "  global pipe_img2img, scheduler, model_path, inpaint_model, prefs, callback_fn\n",
        "  from diffusers import DiffusionPipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  \n",
        "  if prefs['higher_vram_mode']:\n",
        "    pipe_img2img = DiffusionPipeline.from_pretrained(\n",
        "        inpaint_model,\n",
        "        custom_pipeline=\"img2img_inpainting\",\n",
        "        scheduler=model_scheduler(inpaint_model),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None\n",
        "    )\n",
        "  else:\n",
        "      pipe_img2img = DiffusionPipeline.from_pretrained(\n",
        "      inpaint_model,\n",
        "      custom_pipeline=\"img2img_inpainting\",\n",
        "      scheduler=model_scheduler(inpaint_model),\n",
        "      cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "      revision=\"fp16\", \n",
        "      torch_dtype=torch.float16,\n",
        "      safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None)\n",
        "  pipe_img2img.to(torch_device)\n",
        "  #if prefs['enable_attention_slicing']: pipe_img2img.enable_attention_slicing() #slice_size\n",
        "  if prefs['sequential_cpu_offload']:\n",
        "    pipe_img2img.enable_sequential_cpu_offload()\n",
        "  pipe_img2img = optimize_pipe(pipe_img2img)\n",
        "  pipe_img2img.set_progress_bar_config(disable=True)\n",
        "  #def dummy(images, **kwargs): return images, False\n",
        "  #pipe_img2img.safety_checker = dummy\n",
        "  return pipe_img2img\n",
        "\n",
        "def get_imagic(page):\n",
        "    global pipe_imagic\n",
        "    if pipe_imagic is not None:\n",
        "        del pipe_imagic\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    pipe_imagic = get_imagic_pipe()\n",
        "\n",
        "def get_imagic_pipe():\n",
        "  global pipe_imagic, scheduler, model_path, prefs\n",
        "  from diffusers import DiffusionPipeline#, DDIMScheduler\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  #ddim = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "  #if prefs['higher_vram_mode']:\n",
        "  if True:\n",
        "    pipe_imagic = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"AlanB/imagic_stable_diffusion_mod\", scheduler=model_scheduler(model_path, big3=True), use_auth_token=True, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None)\n",
        "  else:\n",
        "    pipe_imagic = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"AlanB/imagic_stable_diffusion_mod\", scheduler=model_scheduler(model_path, big3=True), revision=\"fp16\", torch_dtype=torch.float16, safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None)\n",
        "  pipe_imagic = pipe_imagic.to(torch_device)\n",
        "  def dummy(images, **kwargs):\n",
        "    return images, False\n",
        "  if prefs['disable_nsfw_filter']:\n",
        "    pipe_imagic.safety_checker = dummy\n",
        "  pipe_imagic = optimize_pipe(pipe_imagic)\n",
        "  #pipe_imagic.set_progress_bar_config(disable=True)\n",
        "  return pipe_imagic\n",
        "\n",
        "def get_composable(page):\n",
        "    global pipe_composable\n",
        "    if pipe_composable is not None:\n",
        "        del pipe_composable\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    pipe_composable = get_composable_pipe()\n",
        "\n",
        "def get_composable_pipe():\n",
        "  global pipe_composable, scheduler, model_path, prefs\n",
        "  from diffusers import DiffusionPipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  \n",
        "  #if prefs['higher_vram_mode']:\n",
        "  if True:\n",
        "    pipe_composable = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"AlanB/composable_stable_diffusion_mod\", scheduler=model_scheduler(model_path, big3=True), use_auth_token=True, feature_extractor=None, safety_checker=None)\n",
        "  else:\n",
        "    pipe_composable = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"AlanB/composable_stable_diffusion_mod\", scheduler=model_scheduler(model_path, big3=True), revision=\"fp16\", torch_dtype=torch.float16, feature_extractor=None, safety_checker=None)\n",
        "  pipe_composable = pipe_composable.to(torch_device)\n",
        "  def dummy(images, **kwargs):\n",
        "    return images, False\n",
        "  if prefs['disable_nsfw_filter']:\n",
        "    pipe_composable.safety_checker = dummy\n",
        "  pipe_composable = optimize_pipe(pipe_composable)\n",
        "  #pipe_composable.set_progress_bar_config(disable=True)\n",
        "  return pipe_composable\n",
        "\n",
        "def get_versatile(page):\n",
        "    import torch, gc\n",
        "    global pipe_versatile_text2img\n",
        "    def open_url(e):\n",
        "      page.launch_url(e.data)\n",
        "    try:\n",
        "      pipe_versatile_text2img = get_versatile_text2img_pipe()\n",
        "    except Exception as er:\n",
        "      model_url = f\"https://huggingface.co/shi-labs/versatile-diffusion\"\n",
        "      alert_msg(page, f'ERROR: Looks like you need to accept the HuggingFace Versatile Diffusion Model Card to use Checkpoint',\n",
        "                content=Markdown(f'[{model_url}]({model_url})<br>{er}', on_tap_link=open_url))\n",
        "\n",
        "def get_versatile_pipe(): # Mega was taking up too much vram and crashing the system\n",
        "  global pipe_versatile, scheduler, model_path, prefs\n",
        "  from diffusers import VersatileDiffusionPipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  model_id = \"shi-labs/versatile-diffusion\"\n",
        "  if prefs['higher_vram_mode']:\n",
        "    pipe_versatile = VersatileDiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None\n",
        "    )\n",
        "  else:\n",
        "    pipe_versatile = VersatileDiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        #revision=\"fp16\", \n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None\n",
        "    )\n",
        "  pipe_versatile.to(torch_device)\n",
        "  pipeversatile = optimize_pipe(pipeversatile)\n",
        "  pipe_versatile.set_progress_bar_config(disable=True)\n",
        "  return pipe_versatile\n",
        "\n",
        "def get_versatile_text2img_pipe():\n",
        "  global pipe_versatile_text2img, scheduler, model_path, prefs\n",
        "  from diffusers import VersatileDiffusionTextToImagePipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  model_id = \"shi-labs/versatile-diffusion\"\n",
        "  if prefs['higher_vram_mode']:\n",
        "    pipe_versatile_text2img = VersatileDiffusionTextToImagePipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None\n",
        "    )\n",
        "  else:\n",
        "    pipe_versatile_text2img = VersatileDiffusionTextToImagePipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        #revision=\"fp16\", \n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None\n",
        "    )\n",
        "  pipe_versatile_text2img.to(torch_device)\n",
        "  pipe_versatile_text2img = optimize_pipe(pipe_versatile_text2img)\n",
        "  pipe_versatile_text2img.set_progress_bar_config(disable=True)\n",
        "  return pipe_versatile_text2img\n",
        "\n",
        "def get_versatile_variation_pipe():\n",
        "  global pipe_versatile_variation, scheduler, model_path, prefs\n",
        "  from diffusers import VersatileDiffusionImageVariationPipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  model_id = \"shi-labs/versatile-diffusion\"\n",
        "  if prefs['higher_vram_mode']:\n",
        "    pipe_versatile_variation = VersatileDiffusionImageVariationPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None\n",
        "    )\n",
        "  else:\n",
        "    pipe_versatile_variation = VersatileDiffusionImageVariationPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        #revision=\"fp16\", \n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None\n",
        "    )\n",
        "  pipe_versatile_variation.to(torch_device)\n",
        "  pipe_versatile_variation = optimize_pipe(pipe_versatile_variation)\n",
        "  pipe_versatile_variation.set_progress_bar_config(disable=True)\n",
        "  return pipe_versatile_variation\n",
        "\n",
        "def get_versatile_dualguided_pipe():\n",
        "  global pipe_versatile_dualguided, scheduler, model_path, prefs\n",
        "  from diffusers import VersatileDiffusionDualGuidedPipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  model_id = \"shi-labs/versatile-diffusion\"\n",
        "  if prefs['higher_vram_mode']:\n",
        "    pipe_versatile_dualguided = VersatileDiffusionDualGuidedPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None\n",
        "    )\n",
        "  else:\n",
        "    pipe_versatile_dualguided = VersatileDiffusionDualGuidedPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        #revision=\"fp16\", \n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"), feature_extractor=None\n",
        "    )\n",
        "  pipe_versatile_dualguided.to(torch_device)\n",
        "  pipe_versatile_dualguided = optimize_pipe(pipe_versatile_dualguided)\n",
        "  pipe_versatile_dualguided.set_progress_bar_config(disable=True)\n",
        "  return pipe_versatile_dualguided\n",
        "\n",
        "def get_safe(page):\n",
        "    import torch, gc\n",
        "    global pipe_safe\n",
        "    def open_url(e):\n",
        "      page.launch_url(e.data)\n",
        "    if pipe_safe is not None:\n",
        "      #print(\"Clearing the ol' pipe first...\")\n",
        "      del pipe_safe\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      pipe_safe = None\n",
        "    try:\n",
        "      pipe_safe = get_safe_pipe()\n",
        "    except Exception as er:\n",
        "      model_url = f\"https://huggingface.co/AIML-TUDA/stable-diffusion-safe\"\n",
        "      alert_msg(page, f'ERROR: Looks like you need to accept the HuggingFace Safe Model Card to use Checkpoint. Reinstall after accepting TOS.',\n",
        "                content=Markdown(f'[{model_url}]({model_url})<br>{er}', on_tap_link=open_url))\n",
        "\n",
        "def get_safe_pipe():\n",
        "  global pipe_safe, scheduler, model_path, prefs, callback_fn\n",
        "  from diffusers import StableDiffusionPipelineSafe\n",
        "  from diffusers.pipelines.stable_diffusion_safe import StableDiffusionPipelineSafe\n",
        "  #from diffusers.pipelines.safety_checker import SafeStableDiffusionPipelineSafe\n",
        "  #from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  model_id = \"AIML-TUDA/stable-diffusion-safe\"\n",
        "  #if prefs['higher_vram_mode']:\n",
        "  if True:\n",
        "    pipe_safe = StableDiffusionPipelineSafe.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        safety_checker=None# if prefs['disable_nsfw_filter'] else SafeStableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"),\n",
        "    )\n",
        "  else:\n",
        "      pipe_safe = StableDiffusionPipelineSafe.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        revision=\"fp16\", \n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None# if prefs['disable_nsfw_filter'] else SafeStableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\")\n",
        "      )\n",
        "  pipe_safe.to(torch_device)\n",
        "  pipe_safe = optimize_pipe(pipe_safe, vae=False)\n",
        "  pipe_safe.set_progress_bar_config(disable=True)\n",
        "  return pipe_safe\n",
        "\n",
        "def get_upscale(page):\n",
        "    import torch, gc\n",
        "    global pipe_upscale\n",
        "    def open_url(e):\n",
        "      page.launch_url(e.data)\n",
        "    if pipe_upscale is None:\n",
        "      try:\n",
        "        pipe_upscale = get_upscale_pipe()\n",
        "      except Exception as er:\n",
        "        model_url = f\"https://huggingface.co/{model_path}\"\n",
        "        alert_msg(page, f'ERROR: Looks like you need to accept the HuggingFace Upscale Model Card to use Checkpoint',\n",
        "                  content=Markdown(f'[{model_url}]({model_url})<br>{er}', on_tap_link=open_url))\n",
        "\n",
        "def get_upscale_pipe():\n",
        "  global pipe_upscale, scheduler, prefs\n",
        "  from diffusers import StableDiffusionUpscalePipeline\n",
        "  model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
        "  if prefs['higher_vram_mode']:\n",
        "    pipe_upscale = StableDiffusionUpscalePipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id, big3=True),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        #safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"),\n",
        "    )\n",
        "  else:\n",
        "    pipe_upscale = StableDiffusionUpscalePipeline.from_pretrained(\n",
        "      model_id,\n",
        "      scheduler=model_scheduler(model_id, big3=True),\n",
        "      cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "      revision=\"fp16\", \n",
        "      torch_dtype=torch.float16,\n",
        "      #safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\")\n",
        "    )\n",
        "  pipe_upscale.to(torch_device)\n",
        "  pipe_upscale = optimize_pipe(pipe_upscale, vae=False)\n",
        "  pipe_upscale.set_progress_bar_config(disable=True)\n",
        "  return pipe_upscale\n",
        "\n",
        "def get_clip(page):\n",
        "    global pipe_clip_guided, model_path\n",
        "    #os.chdir(root_dir)\n",
        "    #if not os.path.isfile(os.path.join(root_dir, 'clip_guided_stable_diffusion.py')):\n",
        "    #  run_sp(\"wget -q --show-progress --no-cache --backups=1 https://raw.githubusercontent.com/Skquark/diffusers/c16761e9d94a3374710110ba5e3087cb9f8ba906/examples/community/clip_guided_stable_diffusion.py\")\n",
        "    #from clip_guided_stable_diffusion import *\n",
        "\n",
        "    if pipe_clip_guided is not None:\n",
        "        #print(\"Clearing out old CLIP Guided pipeline before reloading.\")\n",
        "        del pipe_clip_guided\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    pipe_clip_guided = get_clip_guided_pipe()\n",
        "\n",
        "def get_clip_guided_pipe():\n",
        "    global pipe_clip_guided, scheduler_clip, prefs\n",
        "    from diffusers import DiffusionPipeline\n",
        "    from diffusers import LMSDiscreteScheduler, PNDMScheduler, StableDiffusionPipeline\n",
        "    from transformers import CLIPModel, CLIPFeatureExtractor #, CLIPGuidedStableDiffusion\n",
        "    '''pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "        model_path,\n",
        "        torch_dtype=torch.float16,\n",
        "        revision=\"fp16\",\n",
        "    )'''\n",
        "    if isinstance(scheduler, LMSDiscreteScheduler) or isinstance(scheduler, PNDMScheduler):\n",
        "      scheduler_clip = scheduler\n",
        "    else:\n",
        "      scheduler_clip = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "    model = get_model(prefs['model_ckpt'])\n",
        "\n",
        "    clip_model = CLIPModel.from_pretrained(prefs['clip_model_id'], torch_dtype=torch.float16)\n",
        "    feature_extractor = CLIPFeatureExtractor.from_pretrained(prefs['clip_model_id'])\n",
        "\n",
        "    if 'revision' in model:\n",
        "      pipe_clip_guided = DiffusionPipeline.from_pretrained(\n",
        "              model_path,\n",
        "              custom_pipeline=\"AlanB/clip_guided_stable_diffusion_mod\",\n",
        "              clip_model=clip_model,\n",
        "              feature_extractor=feature_extractor,\n",
        "              scheduler=model_scheduler(model_path, big3=True),\n",
        "              cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "              safety_checker=None,\n",
        "              torch_dtype=torch.float16,\n",
        "              revision=model['revision'],\n",
        "              #device_map=\"auto\",\n",
        "          )\n",
        "    else:\n",
        "      pipe_clip_guided = DiffusionPipeline.from_pretrained(model_path, custom_pipeline=\"AlanB/clip_guided_stable_diffusion_mod\", clip_model=clip_model, feature_extractor=feature_extractor, scheduler=model_scheduler(model_path, big3=True), safety_checker=None, cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None, torch_dtype=torch.float16)\n",
        "    pipe_clip_guided = pipe_clip_guided.to(torch_device)\n",
        "    '''\n",
        "    pipe_clip_guided = CLIPGuidedStableDiffusion(\n",
        "        unet=pipeline.unet,\n",
        "        vae=pipeline.vae,\n",
        "        tokenizer=pipeline.tokenizer,\n",
        "        text_encoder=pipeline.text_encoder,\n",
        "        scheduler=scheduler_clip,\n",
        "        clip_model=clip_model,\n",
        "        feature_extractor=feature_extractor,\n",
        "    )'''\n",
        "    pipe_clip_guided = optimize_pipe(pipe_clip_guided, vae=False)\n",
        "    return pipe_clip_guided\n",
        "\n",
        "def get_repaint(page):\n",
        "    global pipe_repaint\n",
        "    if pipe_repaint is not None:\n",
        "        #print(\"Clearing out old CLIP Guided pipeline before reloading.\")\n",
        "        del pipe_repaint\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    pipe_repaint = get_repaint_pipe()\n",
        "\n",
        "def get_repaint_pipe():\n",
        "    global pipe_repaint\n",
        "    from diffusers import UNet2DModel, RePaintScheduler, RePaintPipeline\n",
        "    #model = get_model(prefs['model_ckpt'])\n",
        "    #model_path = model['path']\n",
        "    model_id = \"google/ddpm-ema-celebahq-256\"\n",
        "    unet = UNet2DModel.from_pretrained(model_id)\n",
        "    repaint_scheduler = RePaintScheduler.from_pretrained(model_id)\n",
        "    pipe_repaint = RePaintPipeline(unet=unet, scheduler=repaint_scheduler).to(torch_device)\n",
        "    return pipe_repaint\n",
        "\n",
        "def get_depth2img(page):\n",
        "  global pipe_depth\n",
        "  pipe_depth = get_depth_pipe()\n",
        "\n",
        "def get_depth_pipe():\n",
        "  global pipe_depth, prefs\n",
        "  from diffusers import StableDiffusionDepth2ImgPipeline\n",
        "  from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "  model_id = \"stabilityai/stable-diffusion-2-depth\"\n",
        "  if prefs['higher_vram_mode']:\n",
        "    pipe_depth = StableDiffusionDepth2ImgPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "    )\n",
        "  else:\n",
        "    pipe_depth = StableDiffusionDepth2ImgPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        scheduler=model_scheduler(model_id),\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        revision=\"fp16\", \n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "  pipe_depth.to(torch_device)\n",
        "  pipe_depth = optimize_pipe(pipe_depth, vae=False)\n",
        "  pipe_depth.set_progress_bar_config(disable=True)\n",
        "  return pipe_depth\n",
        "\n",
        "SD_sampler = None\n",
        "def get_stability(page):\n",
        "    global prefs, SD_sampler#, stability_api\n",
        "    '''try:\n",
        "      from stability_sdk import client\n",
        "      import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
        "    except ImportError as e:\n",
        "      run_process(\"pip install stability-sdk -q\", page=page)\n",
        "      from stability_sdk import client\n",
        "      import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
        "      pass\n",
        "    stability_api = client.StabilityInference(\n",
        "        key=prefs['Stability_api_key'], \n",
        "        verbose=True,\n",
        "        engine=prefs['model_checkpoint']# if prefs['model_checkpoint'] == \"stable-diffusion-v1-5\" else \"stable-diffusion-v1\",\n",
        "    )\n",
        "    SD_sampler = client.get_sampler_from_str(prefs['generation_sampler'].lower())'''\n",
        "    # New way, other is obsolete\n",
        "    import requests\n",
        "    api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
        "    stability_url = f\"{api_host}/v1alpha/engines/list\" #user/account\"\n",
        "    response = requests.get(stability_url, headers={\"Authorization\": prefs['Stability_api_key']})\n",
        "    if response.status_code != 200:\n",
        "      alert_msg(page, \"ERROR with Stability-ai: \" + str(response.text))\n",
        "      return\n",
        "    payload = response.json()\n",
        "    #print(str(payload))\n",
        "    status['installed_stability'] = True\n",
        "\n",
        "'''\n",
        "def update_stability():\n",
        "    global SD_sampler, stability_api\n",
        "    from stability_sdk import client\n",
        "    stability_api = client.StabilityInference(\n",
        "        key=prefs['Stability_api_key'], \n",
        "        verbose=True,\n",
        "        engine=prefs['model_checkpoint']\n",
        "    )\n",
        "    SD_sampler = client.get_sampler_from_str(prefs['generation_sampler'].lower())\n",
        "'''\n",
        "def get_ESRGAN(page):\n",
        "    os.chdir(dist_dir)\n",
        "    run_process(f\"git clone https://github.com/xinntao/Real-ESRGAN.git -q\", page=page, cwd=dist_dir)\n",
        "    os.chdir(os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "    run_process(\"pip install basicsr --quiet\", page=page, cwd=os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "    run_process(\"pip install facexlib --quiet\", page=page, cwd=os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "    run_process(\"pip install gfpgan --quiet\", page=page, cwd=os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "    run_process(f\"pip install -r requirements.txt --quiet\", page=page, realtime=False, cwd=os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "    run_process(f\"python setup.py develop --quiet\", page=page, realtime=False, cwd=os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "    run_process(f\"wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models --quiet\", page=page, cwd=os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "\n",
        "concepts = [{'name': 'cat-toy', 'token': 'cat-toy'}, {'name': 'madhubani-art', 'token': 'madhubani-art'}, {'name': 'birb-style', 'token': 'birb-style'}, {'name': 'indian-watercolor-portraits', 'token': 'watercolor-portrait'}, {'name': 'xyz', 'token': 'xyz'}, {'name': 'poolrooms', 'token': 'poolrooms'}, {'name': 'cheburashka', 'token': 'cheburashka'}, {'name': 'hours-style', 'token': 'hours'}, {'name': 'turtlepics', 'token': 'henry-leonardi'}, {'name': 'karl-s-lzx-1', 'token': 'lzx'}, {'name': 'canary-cap', 'token': 'canary-cap'}, {'name': 'ti-junglepunk-v0', 'token': 'jungle-punk'}, {'name': 'mafalda-character', 'token': 'mafalda-quino'}, {'name': 'magic-pengel', 'token': 'magic-pengel'}, {'name': 'schloss-mosigkau', 'token': 'ralph'}, {'name': 'cubex', 'token': 'cube'}, {'name': 'covid-19-rapid-test', 'token': 'covid-test'}, {'name': 'character-pingu', 'token': 'character-pingu'}, {'name': '2814-roth', 'token': '2814Roth'}, {'name': 'vkuoo1', 'token': 'style-vkuoo1'}, {'name': 'ina-art', 'token': ''}, {'name': 'monte-novo', 'token': 'monte novo cutting board'}, {'name': 'interchanges', 'token': 'xchg'}, {'name': 'walter-wick-photography', 'token': 'walter-wick'}, {'name': 'arcane-style-jv', 'token': 'arcane-style-jv'}, {'name': 'w3u', 'token': 'w3u'}, {'name': 'smiling-friend-style', 'token': 'smilingfriends-cartoon'}, {'name': 'dr-livesey', 'token': 'dr-livesey'}, {'name': 'monster-girl', 'token': 'monster-girl'}, {'name': 'abstract-concepts', 'token': 'art-style'}, {'name': 'reeducation-camp', 'token': 'reeducation-camp'}, {'name': 'miko-3-robot', 'token': 'miko-3'}, {'name': 'party-girl', 'token': 'party-girl'}, {'name': 'dicoo', 'token': 'Dicoo'}, {'name': 'kuvshinov', 'token': 'kuvshinov'}, {'name': 'mass', 'token': 'mass'}, {'name': 'ldr', 'token': 'ldr'}, {'name': 'hub-city', 'token': 'HubCity'}, {'name': 'masyunya', 'token': 'masyunya'}, {'name': 'david-moreno-architecture', 'token': 'dm-arch'}, {'name': 'lolo', 'token': 'lolo'}, {'name': 'apulian-rooster-v0-1', 'token': 'apulian-rooster-v0.1'}, {'name': 'fractal', 'token': 'fractal'}, {'name': 'nebula', 'token': 'nebula'}, {'name': 'ldrs', 'token': 'ldrs'}, {'name': 'art-brut', 'token': 'art-brut'}, {'name': 'malika-favre-art-style', 'token': 'malika-favre'}, {'name': 'line-art', 'token': 'line-art'}, {'name': 'shrunken-head', 'token': 'shrunken-head'}, {'name': 'bonzi-monkey', 'token': 'bonzi'}, {'name': 'herge-style', 'token': 'herge'}, {'name': 'johnny-silverhand', 'token': 'johnny-silverhand'}, {'name': 'linnopoke', 'token': 'linnopoke'}, {'name': 'koko-dog', 'token': 'koko-dog'}, {'name': 'stuffed-penguin-toy', 'token': 'pengu-toy'}, {'name': 'monster-toy', 'token': 'monster-toy'}, {'name': 'dong-ho', 'token': 'dong-ho'}, {'name': 'orangejacket', 'token': 'orangejacket'}, {'name': 'fergal-cat', 'token': 'fergal-cat'}, {'name': 'summie-style', 'token': 'summie-style'}, {'name': 'chonkfrog', 'token': 'chonkfrog'}, {'name': 'alberto-mielgo', 'token': 'street'}, {'name': 'lucky-luke', 'token': 'lucky-luke'}, {'name': 'zdenek-art', 'token': 'zdenek-artwork'}, {'name': 'star-tours-posters', 'token': 'star-tours'}, {'name': 'huang-guang-jian', 'token': 'huang-guang-jian'}, {'name': 'painting', 'token': 'will'}, {'name': 'line-style', 'token': 'line-style'}, {'name': 'venice', 'token': 'venice'}, {'name': 'russian', 'token': 'Russian'}, {'name': 'tony-diterlizzi-s-planescape-art', 'token': 'tony-diterlizzi-planescape'}, {'name': 'moeb-style', 'token': 'moe-bius'}, {'name': 'amine', 'token': 'ayna'}, {'name': 'kojima-ayami', 'token': 'KOJIMA'}, {'name': 'dong-ho2', 'token': 'dong-ho-2'}, {'name': 'ruan-jia', 'token': 'ruan-jia'}, {'name': 'purplefishli', 'token': 'purplefishli'}, {'name': 'cry-baby-style', 'token': 'cry-baby'}, {'name': 'between2-mt-fade', 'token': 'b2MTfade'}, {'name': 'mtl-longsky', 'token': 'mtl-longsky'}, {'name': 'scrap-style', 'token': 'style-chewie'}, {'name': 'tela-lenca', 'token': 'tela-lenca'}, {'name': 'zillertal-can', 'token': 'zillertal-ipa'}, {'name': 'shu-doll', 'token': 'shu-doll'}, {'name': 'eastward', 'token': 'eastward'}, {'name': 'chuck-walton', 'token': 'Chuck_Walton'}, {'name': 'chucky', 'token': 'merc'}, {'name': 'smw-map', 'token': 'smw-map'}, {'name': 'erwin-olaf-style', 'token': 'erwin-olaf'}, {'name': 'maurice-quentin-de-la-tour-style', 'token': 'maurice'}, {'name': 'dan-seagrave-art-style', 'token': 'dan-seagrave'}, {'name': 'drive-scorpion-jacket', 'token': 'drive-scorpion-jacket'}, {'name': 'dark-penguin-pinguinanimations', 'token': 'darkpenguin-robot'}, {'name': 'rd-paintings', 'token': 'rd-painting'}, {'name': 'borderlands', 'token': 'borderlands'}, {'name': 'depthmap', 'token': 'depthmap'}, {'name': 'lego-astronaut', 'token': 'lego-astronaut'}, {'name': 'transmutation-circles', 'token': 'tcircle'}, {'name': 'mycat', 'token': 'mycat'}, {'name': 'ilya-shkipin', 'token': 'ilya-shkipin-style'}, {'name': 'moxxi', 'token': 'moxxi'}, {'name': 'riker-doll', 'token': 'rikerdoll'}, {'name': 'apex-wingman', 'token': 'wingman-apex'}, {'name': 'naf', 'token': 'nal'}, {'name': 'handstand', 'token': 'handstand'}, {'name': 'vb-mox', 'token': 'vb-mox'}, {'name': 'pixel-toy', 'token': 'pixel-toy'}, {'name': 'olli-olli', 'token': 'olli-olli'}, {'name': 'floral', 'token': 'ntry not foun'}, {'name': 'minecraft-concept-art', 'token': 'concept'}, {'name': 'yb-anime', 'token': 'anime-character'}, {'name': 'ditko', 'token': 'cat-toy'}, {'name': 'disquieting-muses', 'token': 'muses'}, {'name': 'ned-flanders', 'token': 'flanders'}, {'name': 'fluid-acrylic-jellyfish-creatures-style-of-carl-ingram-art', 'token': 'jelly-core'}, {'name': 'ic0n', 'token': 'ic0n'}, {'name': 'pyramidheadcosplay', 'token': 'Cos-Pyramid'}, {'name': 'phc', 'token': 'Cos-Pyramid'}, {'name': 'og-mox-style', 'token': 'og-mox-style'}, {'name': 'klance', 'token': 'klance'}, {'name': 'john-blanche', 'token': 'john-blanche'}, {'name': 'cowboy', 'token': 'cowboyStyle'}, {'name': 'darkpenguinanimatronic', 'token': 'penguin-robot'}, {'name': 'doener-red-line-art', 'token': 'dnr'}, {'name': 'style-of-marc-allante', 'token': 'Marc_Allante'}, {'name': 'crybaby-style-2-0', 'token': 'crybaby2'}, {'name': 'werebloops', 'token': 'werebloops'}, {'name': 'xbh', 'token': 'xbh'}, {'name': 'unfinished-building', 'token': 'unfinished-building'}, {'name': 'teelip-ir-landscape', 'token': 'teelip-ir-landscape'}, {'name': 'road-to-ruin', 'token': 'RtoR'}, {'name': 'piotr-jablonski', 'token': 'piotr-jablonski'}, {'name': 'jamiels', 'token': 'jamiels'}, {'name': 'tomcat', 'token': 'tom-cat'}, {'name': 'meyoco', 'token': 'meyoco'}, {'name': 'nixeu', 'token': 'nixeu'}, {'name': 'tnj', 'token': 'tnj'}, {'name': 'cute-bear', 'token': 'cute-bear'}, {'name': 'leica', 'token': 'leica'}, {'name': 'anime-boy', 'token': 'myAItestShota'}, {'name': 'garfield-pizza-plush', 'token': 'garfield-plushy'}, {'name': 'design', 'token': 'design'}, {'name': 'mikako-method', 'token': 'm-m'}, {'name': 'cornell-box', 'token': 'cornell-box'}, {'name': 'sculptural-style', 'token': 'diaosu'}, {'name': 'aavegotchi', 'token': 'aave-gotchi'}, {'name': 'swamp-choe-2', 'token': 'cat-toy'}, {'name': 'super-nintendo-cartridge', 'token': 'snesfita-object'}, {'name': 'garfield-pizza-plush-v2', 'token': 'garfield-plushy'}, {'name': 'rickyart', 'token': 'RickyArt'}, {'name': 'eye-of-agamotto', 'token': 'eye-aga'}, {'name': 'freddy-fazbear', 'token': 'freddy-fazbear'}, {'name': 'glass-pipe', 'token': 'glass-sherlock'}, {'name': 'black-waifu', 'token': 'black-waifu'}, {'name': 'roy-lichtenstein', 'token': 'roy-lichtenstein'}, {'name': 'ugly-sonic', 'token': 'ugly-sonic'}, {'name': 'glow-forest', 'token': 'dark-forest'}, {'name': 'painted-student', 'token': 'painted_student'}, {'name': 'salmonid', 'token': 'salmonid'}, {'name': 'huayecai820-greyscale', 'token': 'huayecaigreyscale-style'}, {'name': 'arthur1', 'token': 'arthur1'}, {'name': 'huckleberry', 'token': 'huckleberry'}, {'name': 'collage3', 'token': 'Collage3'}, {'name': 'spritual-monsters', 'token': 'spritual-monsters'}, {'name': 'baldi', 'token': 'baldi'}, {'name': 'tcirle', 'token': 'tcircle'}, {'name': 'pantone-milk', 'token': 'pantone-milk'}, {'name': 'retropixelart-pinguin', 'token': 'retropixelart-style'}, {'name': 'doose-s-realistic-art-style', 'token': 'doose-realistic'}, {'name': 'grit-toy', 'token': 'grit-toy'}, {'name': 'pink-beast-pastelae-style', 'token': 'pinkbeast'}, {'name': 'mikako-methodi2i', 'token': 'm-mi2i'}, {'name': 'aj-fosik', 'token': 'AJ-Fosik'}, {'name': 'collage-cutouts', 'token': 'collage-cutouts'}, {'name': 'cute-cat', 'token': 'cute-bear'}, {'name': 'kaleido', 'token': 'kaleido'}, {'name': 'xatu', 'token': 'xatu-pokemon'}, {'name': 'a-female-hero-from-the-legend-of-mir', 'token': ' <female-hero> from The Legend of Mi'}, {'name': 'cologne', 'token': 'cologne-dom'}, {'name': 'wlop-style', 'token': 'wlop-style'}, {'name': 'larrette', 'token': 'larrette'}, {'name': 'bert-muppet', 'token': 'bert-muppet'}, {'name': 'my-hero-academia-style', 'token': 'MHA style'}, {'name': 'vcr-classique', 'token': 'vcr_c'}, {'name': 'xatu2', 'token': 'xatu-test'}, {'name': 'tela-lenca2', 'token': 'tela-lenca'}, {'name': 'dragonborn', 'token': 'dragonborn'}, {'name': 'mate', 'token': 'mate'}, {'name': 'alien-avatar', 'token': 'alien-avatar'}, {'name': 'pastelartstyle', 'token': 'Arzy'}, {'name': 'kings-quest-agd', 'token': 'ings-quest-ag'}, {'name': 'doge-pound', 'token': 'doge-pound'}, {'name': 'type', 'token': 'typeface'}, {'name': 'fileteado-porteno', 'token': 'fileteado-porteno'}, {'name': 'bullvbear', 'token': 'bullVBear'}, {'name': 'freefonix-style', 'token': 'Freefonix'}, {'name': 'garcon-the-cat', 'token': 'garcon-the-cat'}, {'name': 'better-collage3', 'token': 'C3'}, {'name': 'metagabe', 'token': 'metagabe'}, {'name': 'ggplot2', 'token': 'ggplot2'}, {'name': 'yoshi', 'token': 'yoshi'}, {'name': 'illustration-style', 'token': 'illustration-style'}, {'name': 'centaur', 'token': 'centaur'}, {'name': 'zoroark', 'token': 'zoroark'}, {'name': 'bad_Hub_Hugh', 'token': 'HubHugh'}, {'name': 'irasutoya', 'token': 'irasutoya'}, {'name': 'liquid-light', 'token': 'lls'}, {'name': 'zaneypixelz', 'token': 'zaneypixelz'}, {'name': 'tubby', 'token': 'tubby'}, {'name': 'atm-ant', 'token': 'atm-ant'}, {'name': 'fang-yuan-001', 'token': 'fang-yuan'}, {'name': 'dullboy-caricature', 'token': 'dullboy-cari'}, {'name': 'bada-club', 'token': 'bada-club'}, {'name': 'zaney', 'token': 'zaney'}, {'name': 'a-tale-of-two-empires', 'token': 'two-empires'}, {'name': 'dabotap', 'token': 'dabotap'}, {'name': 'harley-quinn', 'token': 'harley-quinn'}, {'name': 'vespertine', 'token': 'Vesp'}, {'name': 'ricar', 'token': 'ricard'}, {'name': 'conner-fawcett-style', 'token': 'badbucket'}, {'name': 'ingmar-bergman', 'token': 'ingmar-bergman'}, {'name': 'poutine-dish', 'token': 'poutine-qc'}, {'name': 'shev-linocut', 'token': 'shev-linocut'}, {'name': 'grifter', 'token': 'grifter'}, {'name': 'dog', 'token': 'Winston'}, {'name': 'tangles', 'token': 'cora-tangle'}, {'name': 'lost-rapper', 'token': 'lost-rapper'}, {'name': 'eddie', 'token': 'ddi'}, {'name': 'thunderdome-covers', 'token': 'thunderdome'}, {'name': 'she-mask', 'token': 'she-mask'}, {'name': 'chillpill', 'token': 'Chillpill'}, {'name': 'robertnava', 'token': 'robert-nava'}, {'name': 'looney-anime', 'token': 'looney-anime'}, {'name': 'axe-tattoo', 'token': 'axe-tattoo'}, {'name': 'fireworks-over-water', 'token': 'firework'}, {'name': 'collage14', 'token': 'C14'}, {'name': 'green-tent', 'token': 'green-tent'}, {'name': 'dtv-pkmn', 'token': 'dtv-pkm2'}, {'name': 'crinos-form-garou', 'token': 'crinos'}, {'name': '8bit', 'token': '8bit'}, {'name': 'tubby-cats', 'token': 'tubby'}, {'name': 'travis-bedel', 'token': 'bedelgeuse2'}, {'name': 'uma', 'token': 'uma'}, {'name': 'ie-gravestone', 'token': 'internet-explorer-gravestone'}, {'name': 'colossus', 'token': 'colossus'}, {'name': 'uma-style-classic', 'token': 'uma'}, {'name': 'collage3-hubcity', 'token': 'C3Hub'}, {'name': 'goku', 'token': 'goku'}, {'name': 'galaxy-explorer', 'token': 'galaxy-explorer'}, {'name': 'rl-pkmn-test', 'token': 'rl-pkmn'}, {'name': 'naval-portrait', 'token': 'naval-portrait'}, {'name': 'daycare-attendant-sun-fnaf', 'token': 'biblic-sun-fnaf'}, {'name': 'reksio-dog', 'token': 'reksio-dog'}, {'name': 'breakcore', 'token': 'reakcor'}, {'name': 'junji-ito-artstyle', 'token': 'junji-ito-style'}, {'name': 'gram-tops', 'token': 'gram-tops'}, {'name': 'henjo-techno-show', 'token': 'HENJOTECHNOSHOW'}, {'name': 'trash-polka-artstyle', 'token': 'trash-polka-style'}, {'name': 'faraon-love-shady', 'token': ''}, {'name': 'trigger-studio', 'token': 'Trigger Studio'}, {'name': 'tb303', 'token': '\"tb303'}, {'name': 'neon-pastel', 'token': 'neon-pastel'}, {'name': 'fursona', 'token': 'fursona-2'}, {'name': 'sterling-archer', 'token': 'archer-style'}, {'name': 'captain-haddock', 'token': 'captain-haddock'}, {'name': 'my-mug', 'token': 'my-mug'}, {'name': 'joe-whiteford-art-style', 'token': 'joe-whiteford-artstyle'}, {'name': 'on-kawara', 'token': 'on-kawara'}, {'name': 'hours-sentry-fade', 'token': 'Hours_Sentry'}, {'name': 'rektguy', 'token': 'rektguy'}, {'name': 'dyoudim-style', 'token': 'DyoudiM-style'}, {'name': 'kaneoya-sachiko', 'token': 'Kaneoya'}, {'name': 'retro-girl', 'token': 'retro-girl'}, {'name': 'buddha-statue', 'token': 'buddha-statue'}, {'name': 'hitokomoru-style-nao', 'token': 'hitokomoru-style'}, {'name': 'plant-style', 'token': 'plant'}, {'name': 'cham', 'token': 'cham'}, {'name': 'mayor-richard-irvin', 'token': 'Richard_Irvin'}, {'name': 'sd-concepts-library-uma-meme', 'token': 'uma-object-full'}, {'name': 'uma-meme', 'token': 'uma-object-full'}, {'name': 'thunderdome-cover', 'token': 'thunderdome-cover'}, {'name': 'sem-mac2n', 'token': 'SEM_Mac2N'}, {'name': 'hoi4', 'token': 'hoi4'}, {'name': 'hd-emoji', 'token': 'HDemoji-object'}, {'name': 'lumio', 'token': 'lumio'}, {'name': 't-skrang', 'token': 'tskrang'}, {'name': 'agm-style-nao', 'token': 'agm-style'}, {'name': 'uma-meme-style', 'token': 'uma-meme-style'}, {'name': 'retro-mecha-rangers', 'token': 'aesthetic'}, {'name': 'babushork', 'token': 'babushork'}, {'name': 'qpt-atrium', 'token': 'QPT_ATRIUM'}, {'name': 'sushi-pixel', 'token': 'sushi-pixel'}, {'name': 'osrsmini2', 'token': ''}, {'name': 'ttte', 'token': 'ttte-2'}, {'name': 'atm-ant-2', 'token': 'atm-ant'}, {'name': 'dan-mumford', 'token': 'dan-mumford'}, {'name': 'renalla', 'token': 'enall'}, {'name': 'cow-uwu', 'token': 'cow-uwu'}, {'name': 'one-line-drawing', 'token': 'lineart'}, {'name': 'inuyama-muneto-style-nao', 'token': 'inuyama-muneto-style'}, {'name': 'altvent', 'token': 'AltVent'}, {'name': 'accurate-angel', 'token': 'accurate-angel'}, {'name': 'mtg-card', 'token': 'mtg-card'}, {'name': 'ddattender', 'token': 'ddattender'}, {'name': 'thalasin', 'token': 'thalasin-plus'}, {'name': 'moebius', 'token': 'moebius'}, {'name': 'liqwid-aquafarmer', 'token': 'aquafarmer'}, {'name': 'onepunchman', 'token': 'OnePunch'}, {'name': 'kawaii-colors', 'token': 'kawaii-colors-style'}, {'name': 'naruto', 'token': 'Naruto'}, {'name': 'backrooms', 'token': 'Backrooms'}, {'name': 'a-hat-kid', 'token': 'hatintime-kid'}, {'name': 'furrpopasthetic', 'token': 'furpop'}, {'name': 'RINGAO', 'token': ''}, {'name': 'csgo-awp-texture-map', 'token': 'csgo_awp_texture'}, {'name': 'luinv2', 'token': 'luin-waifu'}, {'name': 'hydrasuit', 'token': 'hydrasuit'}, {'name': 'milady', 'token': 'milady'}, {'name': 'ganyu-genshin-impact', 'token': 'ganyu'}, {'name': 'wayne-reynolds-character', 'token': 'warcharport'}, {'name': 'david-firth-artstyle', 'token': 'david-firth-artstyle'}, {'name': 'seraphimmoonshadow-art', 'token': 'seraphimmoonshadow-art'}, {'name': 'osrstiny', 'token': 'osrstiny'}, {'name': 'lugal-ki-en', 'token': 'lugal-ki-en'}, {'name': 'seamless-ground', 'token': 'seamless-ground'}, {'name': 'sewerslvt', 'token': 'ewerslv'}, {'name': 'diaosu-toy', 'token': 'diaosu-toy'}, {'name': 'sakimi-style', 'token': 'sakimi'}, {'name': 'rj-palmer', 'token': 'rj-palmer'}, {'name': 'harmless-ai-house-style-1', 'token': 'bee-style'}, {'name': 'harmless-ai-1', 'token': 'bee-style'}, {'name': 'yerba-mate', 'token': 'yerba-mate'}, {'name': 'bella-goth', 'token': 'bella-goth'}, {'name': 'bobs-burgers', 'token': 'bobs-burgers'}, {'name': 'jamie-hewlett-style', 'token': 'hewlett'}, {'name': 'belen', 'token': 'belen'}, {'name': 'shvoren-style', 'token': 'shvoren-style'}, {'name': 'gymnastics-leotard-v2', 'token': 'gymnastics-leotard2'}, {'name': 'rd-chaos', 'token': 'rd-chaos'}, {'name': 'armor-concept', 'token': 'armor-concept'}, {'name': 'ouroboros', 'token': 'ouroboros'}, {'name': 'm-geo', 'token': 'm-geo'}, {'name': 'Akitsuki', 'token': ''}, {'name': 'uzumaki', 'token': 'NARUTO'}, {'name': 'sorami-style', 'token': 'sorami-style'}, {'name': 'lxj-o4', 'token': 'csp'}, {'name': 'she-hulk-law-art', 'token': 'shehulk-style'}, {'name': 'led-toy', 'token': 'led-toy'}, {'name': 'durer-style', 'token': 'drr-style'}, {'name': 'hiten-style-nao', 'token': 'hiten-style-nao'}, {'name': 'mechasoulall', 'token': 'mechasoulall'}, {'name': 'wish-artist-stile', 'token': 'wish-style'}, {'name': 'max-foley', 'token': 'max-foley'}, {'name': 'loab-style', 'token': 'loab-style'}, {'name': '3d-female-cyborgs', 'token': 'A female cyborg'}, {'name': 'r-crumb-style', 'token': 'rcrumb'}, {'name': 'paul-noir', 'token': 'paul-noir'}, {'name': 'cgdonny1', 'token': 'donny1'}, {'name': 'valorantstyle', 'token': 'valorant'}, {'name': 'loab-character', 'token': 'loab-character'}, {'name': 'Atako', 'token': ''}, {'name': 'threestooges', 'token': 'threestooges'}, {'name': 'dsmuses', 'token': 'DSmuses'}, {'name': 'fish', 'token': 'fish'}, {'name': 'glass-prism-cube', 'token': 'glass-prism-cube'}, {'name': 'elegant-flower', 'token': 'elegant-flower'}, {'name': 'hanfu-anime-style', 'token': 'hanfu-anime-style'}, {'name': 'green-blue-shanshui', 'token': 'green-blue shanshui'}, {'name': 'lizardman', 'token': 'laceholderTokenLizardma'}, {'name': 'rail-scene', 'token': 'rail-pov'}, {'name': 'lula-13', 'token': 'lula-13'}, {'name': 'laala-character', 'token': 'laala'}, {'name': 'margo', 'token': 'dog-margo'}, {'name': 'carrascharacter', 'token': 'Carras'}, {'name': 'vietstoneking', 'token': 'vietstoneking'}, {'name': 'rhizomuse-machine-bionic-sculpture', 'token': ''}, {'name': 'rcrumb-portraits-style', 'token': 'rcrumb-portraits'}, {'name': 'mu-sadr', 'token': '783463b'}, {'name': 'bozo-22', 'token': 'bozo-22'}, {'name': 'skyfalls', 'token': 'SkyFalls'}, {'name': 'zk', 'token': ''}, {'name': 'tudisco', 'token': 'cat-toy'}, {'name': 'kogecha', 'token': 'kogecha'}, {'name': 'ori-toor', 'token': 'ori-toor'}, {'name': 'isabell-schulte-pviii-style', 'token': 'isabell-schulte-p8-style'}, {'name': 'rilakkuma', 'token': 'rilakkuma'}, {'name': 'indiana', 'token': 'indiana'}, {'name': 'black-and-white-design', 'token': 'PM_style'}, {'name': 'isabell-schulte-pviii-1024px-1500-steps-style', 'token': 'isabell-schulte-p8-style-1024p-1500s'}, {'name': 'fold-structure', 'token': 'fold-geo'}, {'name': 'brunnya', 'token': 'Brunnya'}, {'name': 'jos-de-kat', 'token': 'kat-jos'}, {'name': 'singsing-doll', 'token': 'singsing'}, {'name': 'singsing', 'token': 'singsing'}, {'name': 'isabell-schulte-pviii-12tiles-3000steps-style', 'token': 'isabell-schulte-p8-style-12tiles-3000s'}, {'name': 'f-22', 'token': 'f-22'}, {'name': 'jin-kisaragi', 'token': 'jin-kisaragi'}, {'name': 'depthmap-style', 'token': 'depthmap'}, {'name': 'crested-gecko', 'token': 'crested-gecko'}, {'name': 'grisstyle', 'token': 'gris'}, {'name': 'ikea-fabler', 'token': 'ikea-fabler'}, {'name': 'joe-mad', 'token': 'joe-mad'}, {'name': 'boissonnard', 'token': 'boissonnard'}, {'name': 'overprettified', 'token': 'overprettified'}, {'name': 'all-rings-albuns', 'token': 'rings-all-albuns'}, {'name': 'shiny-polyman', 'token': 'shiny-polyman'}, {'name': 'scarlet-witch', 'token': 'sw-mom'}, {'name': 'wojaks-now', 'token': 'red-wojak'}, {'name': 'carasibana', 'token': 'carasibana'}, {'name': 'towerplace', 'token': 'TowerPlace'}, {'name': 'cumbia-peruana', 'token': 'cumbia-peru'}, {'name': 'bloo', 'token': 'owl-guy'}, {'name': 'dog-django', 'token': 'dog-django'}, {'name': 'facadeplace', 'token': 'FacadePlace'}, {'name': 'blue-zombie', 'token': 'blue-zombie'}, {'name': 'blue-zombiee', 'token': 'blue-zombie'}, {'name': 'jinjoon-lee-they', 'token': 'jinjoon_lee_they'}, {'name': 'ralph-mcquarrie', 'token': 'ralph-mcquarrie'}, {'name': 'hiyuki-chan', 'token': 'hiyuki-chan'}, {'name': 'isabell-schulte-pviii-4tiles-6000steps', 'token': 'isabell-schulte-p8-style-4tiles-6000s'}, {'name': 'liliana', 'token': 'liliana'}, {'name': 'morino-hon-style', 'token': 'morino-hon'}, {'name': 'artist-yukiko-kanagai', 'token': 'Yukiko Kanagai '}, {'name': 'wheatland', 'token': ''}, {'name': 'm-geoo', 'token': 'm-geo'}, {'name': 'wheatland-arknight', 'token': 'golden-wheats-fields'}, {'name': 'mokoko', 'token': 'mokoko'}, {'name': '001glitch-core', 'token': '01glitch_cor'}, {'name': 'stardew-valley-pixel-art', 'token': 'pixelart-stardew'}, {'name': 'isabell-schulte-pviii-4tiles-500steps', 'token': 'isabell-schulte-p8-style-4tiles-500s'}, {'name': 'anime-girl', 'token': 'anime-girl'}, {'name': 'heather', 'token': 'eather'}, {'name': 'rail-scene-style', 'token': 'rail-pov'}, {'name': 'quiesel', 'token': 'quiesel'}, {'name': 'matthew-stone', 'token': 'atthew-ston'}, {'name': 'dreamcore', 'token': 'dreamcore'}, {'name': 'pokemon-conquest-sprites', 'token': 'poke-conquest'}, {'name': 'tili-concept', 'token': 'tili'}, {'name': 'nouns-glasses', 'token': 'nouns glasses'}, {'name': 'shigure-ui-style', 'token': 'shigure-ui'}, {'name': 'pen-ink-portraits-bennorthen', 'token': 'ink-portrait-by-BenNorthern'}, {'name': 'nikodim', 'token': 'nikodim'}, {'name': 'ori', 'token': 'Ori'}, {'name': 'anya-forger', 'token': 'anya-forger'}, {'name': 'lavko', 'token': 'lavko'}, {'name': 'fasina', 'token': 'Fasina'}, {'name': 'uma-clean-object', 'token': 'uma-clean-object'}, {'name': 'wojaks-now-now-now', 'token': 'red-wojak'}, {'name': 'memnarch-mtg', 'token': 'mtg-memnarch'}, {'name': 'tonal1', 'token': 'Tonal'}, {'name': 'tesla-bot', 'token': 'tesla-bot'}, {'name': 'red-glasses', 'token': 'red-glasses'}, {'name': 'csgo-awp-object', 'token': 'csgo_awp'}, {'name': 'stretch-re1-robot', 'token': 'stretch'}, {'name': 'isabell-schulte-pv-pvii-3000steps', 'token': 'isabell-schulte-p5-p7-style-3000s'}, {'name': 'insidewhale', 'token': 'InsideWhale'}, {'name': 'noggles', 'token': 'noggles'}, {'name': 'isometric-tile-test', 'token': 'iso-tile'}, {'name': 'bamse-og-kylling', 'token': 'bamse-kylling'}, {'name': 'marbling-art', 'token': 'marbling-art'}, {'name': 'joemad', 'token': 'joemad'}, {'name': 'bamse', 'token': 'bamse'}, {'name': 'dq10-anrushia', 'token': 'anrushia'}, {'name': 'test', 'token': 'AIO'}, {'name': 'naoki-saito', 'token': 'naoki_saito'}, {'name': 'raichu', 'token': 'raichu'}, {'name': 'child-zombie', 'token': 'child-zombie'}, {'name': 'yf21', 'token': 'YF21'}, {'name': 'titan-robot', 'token': 'titan'}, {'name': 'cyberpunk-lucy', 'token': 'cyberpunk-lucy'}, {'name': 'giygas', 'token': 'giygas'}, {'name': 'david-martinez-cyberpunk', 'token': 'david-martinez-cyberpunk'}, {'name': 'phan-s-collage', 'token': 'pcollage'}, {'name': 'jojo-bizzare-adventure-manga-lineart', 'token': 'JoJo_lineart'}, {'name': 'homestuck-sprite', 'token': 'homestuck-sprite'}, {'name': 'kogatan-shiny', 'token': 'ogata'}, {'name': 'moo-moo', 'token': 'moomoo'}, {'name': 'detectivedinosaur1', 'token': 'dd1'}, {'name': 'arcane-face', 'token': 'arcane-face'}, {'name': 'sherhook-painting', 'token': 'sherhook'}, {'name': 'isabell-schulte-pviii-1-image-style', 'token': 'isabell-schulte-p8-1-style'}, {'name': 'dicoo2', 'token': 'dicoo'}, {'name': 'hrgiger-drmacabre', 'token': 'barba'}, {'name': 'babau', 'token': 'babau'}, {'name': 'darkplane', 'token': 'DarkPlane'}, {'name': 'wildkat', 'token': 'wildkat'}, {'name': 'half-life-2-dog', 'token': 'hl-dog'}, {'name': 'outfit-items', 'token': 'outfit-items'}, {'name': 'midjourney-style', 'token': 'midjourney-style'}, {'name': 'puerquis-toy', 'token': 'puerquis'}, {'name': 'maus', 'token': 'Maus'}, {'name': 'jetsetdreamcastcovers', 'token': 'jet'}, {'name': 'karan-gloomy', 'token': 'karan'}, {'name': 'yoji-shinkawa-style', 'token': 'yoji-shinkawa'}, {'name': 'million-live-akane-15k', 'token': 'akane'}, {'name': 'million-live-akane-3k', 'token': 'akane'}, {'name': 'sherhook-painting-v2', 'token': 'sherhook'}, {'name': 'gba-pokemon-sprites', 'token': 'GBA-Poke-Sprites'}, {'name': 'gim', 'token': 'grimes-album-style'}, {'name': 'char-con', 'token': 'char-con'}, {'name': 'bluebey', 'token': 'bluebey'}, {'name': 'homestuck-troll', 'token': 'homestuck-troll'}, {'name': 'million-live-akane-shifuku-3k', 'token': 'akane'}, {'name': 'thegeneral', 'token': 'bobknight'}, {'name': 'million-live-spade-q-object-3k', 'token': 'spade_q'}, {'name': 'million-live-spade-q-style-3k', 'token': 'spade_q'}, {'name': 'ibere-thenorio', 'token': 'ibere-thenorio'}, {'name': 'yinit', 'token': 'init-dropca'}, {'name': 'bee', 'token': 'b-e-e'}, {'name': 'pixel-mania', 'token': 'pixel-mania'}, {'name': 'sunfish', 'token': 'SunFish'}, {'name': 'test2', 'token': 'AIOCARD'}, {'name': 'pool-test', 'token': 'pool_test'}, {'name': 'mokoko-seed', 'token': 'mokoko-seed'}, {'name': 'isabell-schulte-pviii-4-tiles-1-lr-3000-steps-style', 'token': 'isabell-schulte-p8-4tiles-1lr-300s-style'}, {'name': 'ghostproject-men', 'token': 'ghostsproject-style'}, {'name': 'phan', 'token': 'phan'}, {'name': 'chen-1', 'token': 'chen-1'}, {'name': 'bluebey-2', 'token': 'bluebey'}, {'name': 'waterfallshadow', 'token': 'WaterfallShadow'}, {'name': 'chop', 'token': 'Le Petit Prince'}, {'name': 'sintez-ico', 'token': 'sintez-ico'}, {'name': 'carlitos-el-mago', 'token': 'carloscarbonell'}, {'name': 'david-martinez-edgerunners', 'token': 'david-martinez-edgerunners'}, {'name': 'isabell-schulte-pviii-4-tiles-3-lr-5000-steps-style', 'token': 'isabell-schulte-p8-4tiles-3lr-5000s-style'}, {'name': 'guttestreker', 'token': 'guttestreker'}, {'name': 'ransom', 'token': 'ransom'}, {'name': 'museum-by-coop-himmelblau', 'token': 'coop himmelblau museum'}, {'name': 'coop-himmelblau', 'token': 'coop himmelblau'}, {'name': 'yesdelete', 'token': 'yesdelete'}, {'name': 'conway-pirate', 'token': 'conway'}, {'name': 'ilo-kunst', 'token': 'ilo-kunst'}, {'name': 'yilanov2', 'token': 'yilanov'}, {'name': 'dr-strange', 'token': 'dr-strange'}, {'name': 'hubris-oshri', 'token': 'Hubris'}, {'name': 'osaka-jyo', 'token': 'osaka-jyo'}, {'name': 'paolo-bonolis', 'token': 'paolo-bonolis'}, {'name': 'repeat', 'token': 'repeat'}, {'name': 'geggin', 'token': 'geggin'}, {'name': 'lex', 'token': 'lex'}, {'name': 'osaka-jyo2', 'token': 'osaka-jyo2'}, {'name': 'owl-house', 'token': 'owl-house'}, {'name': 'nazuna', 'token': 'nazuna'}, {'name': 'thorneworks', 'token': 'Thorneworks'}, {'name': 'kysa-v-style', 'token': 'kysa-v-style'}, {'name': 'senneca', 'token': 'Senneca'}, {'name': 'zero-suit-samus', 'token': 'zero-suit-samus'}, {'name': 'kanv1', 'token': 'KAN'}, {'name': 'dlooak', 'token': 'dlooak'}, {'name': 'wire-angels', 'token': 'wire-angels'}, {'name': 'mizkif', 'token': 'mizkif'}, {'name': 'brittney-williams-art', 'token': 'Brittney_Williams'}, {'name': 'wheelchair', 'token': 'wheelchair'}, {'name': 'yuji-himukai-style', 'token': 'Yuji Himukai-Style'}, {'name': 'cindlop', 'token': 'cindlop'}, {'name': 'sas-style', 'token': 'smooth-aesthetic-style'}, {'name': 'remert', 'token': 'Remert'}, {'name': 'alex-portugal', 'token': 'alejandro-portugal'}, {'name': 'explosions-cat', 'token': 'explosions-cat'}, {'name': 'onzpo', 'token': 'onzpo'}, {'name': 'eru-chitanda-casual', 'token': 'c-eru-chitanda'}, {'name': 'poring-ragnarok-online', 'token': 'poring-ro'}, {'name': 'cg-bearded-man', 'token': 'LH-Keeper'}, {'name': 'ba-shiroko', 'token': 'shiroko'}, {'name': 'at-wolf-boy-object', 'token': 'AT-Wolf-Boy-Object'}, {'name': 'fairytale', 'token': 'fAIrytale'}, {'name': 'kira-sensei', 'token': 'kira-sensei'}, {'name': 'kawaii-girl-plus-style', 'token': 'kawaii_girl'}, {'name': 'kawaii-girl-plus-object', 'token': 'kawaii_girl'}, {'name': 'boris-anderson', 'token': 'boris-anderson'}, {'name': 'medazzaland', 'token': 'edazzalan'}, {'name': 'duranduran', 'token': 'uranDura'}, {'name': 'crbart', 'token': 'crbart'}, {'name': 'happy-person12345', 'token': 'Happy-Person12345'}, {'name': 'fzk', 'token': 'fzk'}, {'name': 'rishusei-style', 'token': 'crishusei-style'}, {'name': 'felps', 'token': 'Felps'}, {'name': 'plen-ki-mun', 'token': 'plen-ki-mun'}, {'name': 'babs-bunny', 'token': 'babs_bunny'}, {'name': 'james-web-space-telescope', 'token': 'James-Web-Telescope'}, {'name': 'blue-haired-boy', 'token': 'Blue-Haired-Boy'}, {'name': '80s-anime-ai', 'token': '80s-anime-AI'}, {'name': 'spider-gwen', 'token': 'spider-gwen'}, {'name': 'takuji-kawano', 'token': 'takuji-kawano'}, {'name': 'fractal-temple-style', 'token': 'fractal-temple'}, {'name': 'sanguo-guanyu', 'token': 'sanguo-guanyu'}, {'name': 's1m-naoto-ohshima', 'token': 's1m-naoto-ohshima'}, {'name': 'kawaii-girl-plus-style-v1-1', 'token': 'kawaii'}, {'name': 'nathan-wyatt', 'token': 'Nathan-Wyatt'}, {'name': 'kasumin', 'token': 'kasumin'}, {'name': 'happy-person12345-assets', 'token': 'Happy-Person12345-assets'}, {'name': 'oleg-kuvaev', 'token': 'oleg-kuvaev'}, {'name': 'kanovt', 'token': 'anov'}, {'name': 'lphr-style', 'token': 'lphr-style'}, {'name': 'concept-art', 'token': 'concept-art'}, {'name': 'trust-support', 'token': 'trust'}, {'name': 'altyn-helmet', 'token': 'Altyn'}, {'name': '80s-anime-ai-being', 'token': 'anime-AI-being'}, {'name': 'baluchitherian', 'token': 'baluchiter'}, {'name': 'pineda-david', 'token': 'pineda-david'}, {'name': 'ohisashiburi-style', 'token': 'ohishashiburi-style'}, {'name': 'crb-portraits', 'token': 'crbportrait'}, {'name': 'i-love-chaos', 'token': 'chaos'}, {'name': 'alex-thumbnail-object-2000-steps', 'token': 'alex'}, {'name': '852style-girl', 'token': '852style-girl'}, {'name': 'nomad', 'token': 'nomad'}, {'name': 'new-priests', 'token': 'new-priest'}, {'name': 'liminalspaces', 'token': 'liminal image'}, {'name': 'aadhav-face', 'token': 'aadhav-face'}, {'name': 'jang-sung-rak-style', 'token': 'Jang-Sung-Rak-style'}, {'name': 'mattvidpro', 'token': 'mattvidpro'}, {'name': 'chungus-poodl-pet', 'token': 'poodl-chungus-big'}, {'name': 'liminal-spaces-2-0', 'token': 'iminal imag'}, {'name': 'crb-surrealz', 'token': 'crbsurreal'}, {'name': 'final-fantasy-logo', 'token': 'final-fantasy-logo'}, {'name': 'canadian-goose', 'token': 'canadian-goose'}, {'name': 'scratch-project', 'token': 'scratch-project'}, {'name': 'lazytown-stephanie', 'token': 'azytown-stephani'}, {'name': 'female-kpop-singer', 'token': 'female-kpop-star'}, {'name': 'aleyna-tilki', 'token': 'aleyna-tilki'}, {'name': 'other-mother', 'token': 'ther-mothe'}, {'name': 'beldam', 'token': 'elda'}, {'name': 'button-eyes', 'token': 'utton-eye'}, {'name': 'alisa', 'token': 'alisa-selezneva'}, {'name': 'im-poppy', 'token': 'm-popp'}, {'name': 'fractal-flame', 'token': 'fractal-flame'}, {'name': 'Exodus-Styling', 'token': 'Exouds-Style'}, {'name': '8sconception', 'token': '80s-car'}, {'name': 'christo-person', 'token': 'christo'}, {'name': 'slm', 'token': 'c-w388'}, {'name': 'meze-audio-elite-headphones', 'token': 'meze-elite'}, {'name': 'fox-purple', 'token': 'foxi-purple'}, {'name': 'roblox-avatar', 'token': 'roblox-avatar'}, {'name': 'toy-bonnie-plush', 'token': 'toy-bonnie-plush'}, {'name': 'alf', 'token': 'alf'}, {'name': 'wojak', 'token': 'oja'}, {'name': 'animalve3-1500seq', 'token': 'diodio'}, {'name': 'muxoyara', 'token': 'muxoyara'}, {'name': 'selezneva-alisa', 'token': 'selezneva-alisa'}, {'name': 'ayush-spider-spr', 'token': 'spr-mn'}, {'name': 'natasha-johnston', 'token': 'natasha-johnston'}, {'name': 'nard-style', 'token': 'nard'}, {'name': 'kirby', 'token': 'kirby'}, {'name': 'el-salvador-style-style', 'token': 'el-salvador-style'}, {'name': 'rahkshi-bionicle', 'token': 'rahkshi-bionicle'}, {'name': 'masyanya', 'token': 'masyanya'}, {'name': 'command-and-conquer-remastered-cameos', 'token': 'command_and_conquer_remastered_cameos'}, {'name': 'lucario', 'token': 'lucario'}, {'name': 'bruma', 'token': 'Bruma-the-cat'}, {'name': 'nissa-revane', 'token': 'nissa-revane'}, {'name': 'tamiyo', 'token': 'tamiyo'}, {'name': 'pascalsibertin', 'token': 'pascalsibertin'}, {'name': 'chandra-nalaar', 'token': 'chandra-nalaar'}, {'name': 'sam-yang', 'token': 'sam-yang'}, {'name': 'kiora', 'token': 'kiora'}, {'name': 'wedding', 'token': 'wedding1'}, {'name': 'arwijn', 'token': 'rwij'}, {'name': 'gba-fe-class-cards', 'token': 'lasscar'}, {'name': 'painted-by-silver-of-999', 'token': 'cat-toy'}, {'name': 'painted-by-silver-of-999-2', 'token': 'girl-painted-by-silver-of-999'}, {'name': 'toyota-sera', 'token': 'toyota-sera'}, {'name': 'vraska', 'token': 'vraska'}, {'name': 'mystical-nature', 'token': ''}, {'name': 'cartoona-animals', 'token': 'cartoona-animals'}, {'name': 'amogus', 'token': 'amogus'}, {'name': 'kinda-sus', 'token': 'amogus'}, {'name': 'xuna', 'token': 'Xuna'}, {'name': 'pion-by-august-semionov', 'token': 'pion'}, {'name': 'rikiart', 'token': 'rick-art'}, {'name': 'jacqueline-the-unicorn', 'token': 'jacqueline'}, {'name': 'flaticon-lineal-color', 'token': 'flaticon-lineal-color'}, {'name': 'test-epson', 'token': 'epson-branch'}, {'name': 'orientalist-art', 'token': 'orientalist-art'}, {'name': 'ki', 'token': 'ki-mars'}, {'name': 'fnf-boyfriend', 'token': 'fnf-boyfriend'}, {'name': 'phoenix-01', 'token': 'phoenix-style'}, {'name': 'society-finch', 'token': 'society-finch'}, {'name': 'rikiboy-art', 'token': 'Rikiboy-Art'}, {'name': 'flatic', 'token': 'flat-ct'}, {'name': 'logo-with-face-on-shield', 'token': 'logo-huizhang'}, {'name': 'elspeth-tirel', 'token': 'elspeth-tirel'}, {'name': 'zero', 'token': 'zero'}, {'name': 'willy-hd', 'token': 'willy_character'}, {'name': 'kaya-ghost-assasin', 'token': 'kaya-ghost-assasin'}, {'name': 'starhavenmachinegods', 'token': 'StarhavenMachineGods'}, {'name': 'namine-ritsu', 'token': 'namine-ritsu'}, {'name': 'mildemelwe-style', 'token': 'mildemelwe'}, {'name': 'nahiri', 'token': 'nahiri'}, {'name': 'ghost-style', 'token': 'ghost'}, {'name': 'arq-render', 'token': 'arq-style'}, {'name': 'saheeli-rai', 'token': 'saheeli-rai'}, {'name': 'youpi2', 'token': 'youpi'}, {'name': 'youtooz-candy', 'token': 'youtooz-candy'}, {'name': 'beholder', 'token': 'beholder'}, {'name': 'progress-chip', 'token': 'progress-chip'}, {'name': 'lofa', 'token': 'lofa'}, {'name': 'huatli', 'token': 'huatli'}, {'name': 'vivien-reid', 'token': 'vivien-reid'}, {'name': 'wedding-HandPainted', 'token': ''}, {'name': 'sims-2-portrait', 'token': 'sims2-portrait'}, {'name': 'flag-ussr', 'token': 'flag-ussr'}, {'name': 'cortana', 'token': 'cortana'}, {'name': 'azura-from-vibrant-venture', 'token': 'azura'}, {'name': 'liliana-vess', 'token': 'liliana-vess'}, {'name': 'dreamy-painting', 'token': 'dreamy-painting'}, {'name': 'munch-leaks-style', 'token': 'munch-leaks-style'}, {'name': 'gta5-artwork', 'token': 'gta5-artwork'}, {'name': 'xioboma', 'token': 'xi-obama'}, {'name': 'ashiok', 'token': 'ashiok'}, {'name': 'Aflac-duck', 'token': 'aflac duck'}, {'name': 'toho-pixel', 'token': 'toho-pixel'}, {'name': 'alicebeta', 'token': 'Alice-style'}, {'name': 'cute-game-style', 'token': 'cute-game-style'}, {'name': 'a-yakimova', 'token': 'a-yakimova'}, {'name': 'anime-background-style', 'token': 'anime-background-style'}, {'name': 'uliana-kudinova', 'token': 'liana-kudinov'}, {'name': 'msg', 'token': 'MSG69'}, {'name': 'gio', 'token': 'gio-single'}, {'name': 'smooth-pencils', 'token': ''}, {'name': 'pintu', 'token': 'pintu-dog'}, {'name': 'marty6', 'token': 'marty6'}, {'name': 'marty', 'token': 'marty'}, {'name': 'xi', 'token': 'JinpingXi'}, {'name': 'captainkirb', 'token': 'captainkirb'}, {'name': 'urivoldemort', 'token': 'uriboldemort'}, {'name': 'anime-background-style-v2', 'token': 'anime-background-style-v2'}, {'name': 'hk-peach', 'token': 'hk-peach'}, {'name': 'hk-goldbuddha', 'token': 'hk-goldbuddha'}, {'name': 'edgerunners-style', 'token': 'edgerunners-style-av'}, {'name': 'warhammer-40k-drawing-style', 'token': 'warhammer40k-drawing-style'}, {'name': 'hk-opencamera', 'token': 'hk-opencamera'}, {'name': 'hk-breakfast', 'token': 'hk-breakfast'}, {'name': 'iridescent-illustration-style', 'token': 'iridescent-illustration-style'}, {'name': 'edgerunners-style-v2', 'token': 'edgerunners-style-av-v2'}, {'name': 'leif-jones', 'token': 'leif-jones'}, {'name': 'hk-buses', 'token': 'hk-buses'}, {'name': 'hk-goldenlantern', 'token': 'hk-goldenlantern'}, {'name': 'hk-hkisland', 'token': 'hk-hkisland'}, {'name': 'hk-leaves', 'token': ''}, {'name': 'hk-oldcamera', 'token': 'hk-oldcamera'}, {'name': 'frank-frazetta', 'token': 'rank franzett'}, {'name': 'obama-based-on-xi', 'token': 'obama> <JinpingXi'}, {'name': 'hk-vintage', 'token': ''}, {'name': 'degods', 'token': 'degods'}, {'name': 'dishonored-portrait-styles', 'token': 'portrait-style-dishonored'}, {'name': 'manga-style', 'token': 'manga'}, {'name': 'degodsheavy', 'token': 'degods-heavy'}, {'name': 'teferi', 'token': 'teferi'}, {'name': 'car-toy-rk', 'token': 'car-toy'}, {'name': 'anders-zorn', 'token': 'anders-zorn'}, {'name': 'rayne-weynolds', 'token': 'rayne-weynolds'}, {'name': 'hk-bamboo', 'token': 'hk-bamboo'}, {'name': 'hk-betweenislands', 'token': 'hk-betweenislands'}, {'name': 'hk-bicycle', 'token': 'hk-bicycle'}, {'name': 'hk-blackandwhite', 'token': 'hk-blackandwhite'}, {'name': 'pjablonski-style', 'token': 'pjablonski-style'}, {'name': 'hk-market', 'token': 'hk-market'}, {'name': 'hk-phonevax', 'token': 'hk-phonevax'}, {'name': 'hk-clouds', 'token': 'hk-cloud'}, {'name': 'hk-streetpeople', 'token': 'hk-streetpeople'}, {'name': 'iridescent-photo-style', 'token': 'iridescent-photo-style'}, {'name': 'color-page', 'token': 'coloring-page'}, {'name': 'hoi4-leaders', 'token': 'HOI4-Leader'}, {'name': 'franz-unterberger', 'token': 'franz-unterberger'}, {'name': 'angus-mcbride-style', 'token': 'angus-mcbride-style'}, {'name': 'happy-chaos', 'token': 'happychaos'}, {'name': 'gt-color-paint-2', 'token': 'my-color-paint-GT'}, {'name': 'smurf-style', 'token': 'smurfy'}, {'name': 'coraline', 'token': 'coraline'}, {'name': 'terraria-style', 'token': 'terr-sty'}, {'name': 'ettblackteapot', 'token': 'my-teapot'}, {'name': 'gibasachan-v0.1', 'token': 'gibasachan'}, {'name': 'kodakvision500t', 'token': 'kodakvision_500T'}, {'name': 'obama-based-on-xi', 'token': 'obama'}, {'name': 'obama-self-2', 'token': 'Obama'}]\n",
        "\n",
        "def get_concept(name):\n",
        "  for con in concepts:\n",
        "      if con['name'] == name:\n",
        "        return con\n",
        "  return {'name':'', 'token':''}\n",
        "\n",
        "def get_conceptualizer(page):\n",
        "    from huggingface_hub import hf_hub_download\n",
        "    from diffusers import StableDiffusionPipeline\n",
        "    from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "    from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "    global pipe_conceptualizer\n",
        "    repo_id_embeds = f\"sd-concepts-library/{prefs['concepts_model']}\"\n",
        "    embeds_url = \"\" #Add the URL or path to a learned_embeds.bin file in case you have one\n",
        "    placeholder_token_string = \"\" #Add what is the token string in case you are uploading your own embed\n",
        "\n",
        "    downloaded_embedding_folder = os.path.join(root_dir, \"downloaded_embedding\")\n",
        "    if not os.path.exists(downloaded_embedding_folder):\n",
        "      os.mkdir(downloaded_embedding_folder)\n",
        "    try:\n",
        "      if(not embeds_url):\n",
        "        embeds_path = hf_hub_download(repo_id=repo_id_embeds, filename=\"learned_embeds.bin\")\n",
        "        token_path = hf_hub_download(repo_id=repo_id_embeds, filename=\"token_identifier.txt\")\n",
        "        shutil.copy(embeds_path, downloaded_embedding_folder)\n",
        "        shutil.copy(token_path, downloaded_embedding_folder)\n",
        "        with open(f'{downloaded_embedding_folder}/token_identifier.txt', 'r') as file:\n",
        "          placeholder_token_string = file.read()\n",
        "      else:\n",
        "        run_sp(f\"wget -q -O {downloaded_embedding_folder}/learned_embeds.bin {embeds_url}\")\n",
        "        #!wget -q -O $downloaded_embedding_folder/learned_embeds.bin $embeds_url\n",
        "    except Exception as e:\n",
        "      alert_msg(page, f\"Error getting concept. May need to accept model at https://huggingface.co/sd-concepts-library/{prefs['concepts_model']}\", content=Text(e))\n",
        "      return\n",
        "    learned_embeds_path = f\"{downloaded_embedding_folder}/learned_embeds.bin\"\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(model_path, subfolder=\"tokenizer\")\n",
        "    text_encoder = CLIPTextModel.from_pretrained(model_path, subfolder=\"text_encoder\", torch_dtype=torch.float16)\n",
        "    def load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, token=None):\n",
        "      loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n",
        "      trained_token = list(loaded_learned_embeds.keys())[0]\n",
        "      embeds = loaded_learned_embeds[trained_token]\n",
        "      dtype = text_encoder.get_input_embeddings().weight.dtype\n",
        "      embeds.to(dtype)\n",
        "      token = token if token is not None else trained_token\n",
        "      num_added_tokens = tokenizer.add_tokens(token)\n",
        "      if num_added_tokens == 0:\n",
        "        alert_msg(page, f\"The tokenizer already contains the token {token}. Please pass a different `token` that is not already in the tokenizer.\")\n",
        "        return\n",
        "      text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "      token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "      text_encoder.get_input_embeddings().weight.data[token_id] = embeds\n",
        "    try:\n",
        "      load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer)\n",
        "    except Exception as e:\n",
        "      alert_msg(page, f\"Error Loading Concept\", content=Text(e))\n",
        "      return\n",
        "    pipe_conceptualizer = StableDiffusionPipeline.from_pretrained(\n",
        "        model_path,\n",
        "        revision=\"fp16\",\n",
        "        torch_dtype=torch.float16,\n",
        "        text_encoder=text_encoder,\n",
        "        tokenizer=tokenizer,\n",
        "        cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None,\n",
        "        safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"),\n",
        "    )\n",
        "    pipe_conceptualizer = optimize_pipe(pipe_conceptualizer, vae=False)\n",
        "    pipe_conceptualizer.set_progress_bar_config(disable=True)\n",
        "    pipe_conceptualizer = pipe_conceptualizer.to(torch_device)\n",
        "    return pipe_conceptualizer\n",
        "\n",
        "def get_dreamfusion(page):\n",
        "    os.chdir(root_dir)\n",
        "    run_process(\"git clone https://github.com/ashawkey/stable-dreamfusion.git -q\", page=page)\n",
        "    os.chdir(os.path.join(root_dir, \"stable-dreamfusion\"))\n",
        "    run_process(\"pip install -r requirements.txt -q\", page=page)\n",
        "    run_process(\"pip install git+https://github.com/NVlabs/nvdiffrast/ -q\", page=page)\n",
        "    os.chdir(root_dir)\n",
        "    \n",
        "def run_dreamfusion(page):\n",
        "    global dreamfusion_prefs, status\n",
        "    def add_to_dreamfusion_output(o):\n",
        "      page.dreamfusion_output.controls.append(o)\n",
        "      page.dreamfusion_output.update()\n",
        "    def clear_last():\n",
        "      #page.dreamfusion_output.controls = []\n",
        "      del page.dreamfusion_output.controls[-1]\n",
        "      page.dreamfusion_output.update()\n",
        "    if not status['installed_diffusers']:\n",
        "      alert_msg(page, \"You must Install HuggingFace Diffusers Pipeline before running...\")\n",
        "      return\n",
        "    if not bool(dreamfusion_prefs[\"prompt_text\"].strip()):\n",
        "      alert_msg(page, \"You must enter a simple prompt to generate 3D model from...\")\n",
        "      return\n",
        "    page.dreamfusion_output.controls = []\n",
        "    page.dreamfusion_output.update()\n",
        "    if not status['installed_dreamfusion']:\n",
        "      add_to_dreamfusion_output(Row([ProgressRing(), Text(\"Installing Stable DreamFusion 3D Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "      get_dreamfusion(page)\n",
        "      status['installed_dreamfusion'] = True\n",
        "      clear_last()\n",
        "    def convert(seconds):\n",
        "      seconds = seconds % (24 * 3600)\n",
        "      hour = seconds // 3600\n",
        "      seconds %= 3600\n",
        "      minutes = seconds // 60\n",
        "      seconds %= 60\n",
        "      return \"%d:%02d\" % (hour, minutes)\n",
        "    estimate = convert(int(dreamfusion_prefs[\"training_iters\"] * 0.7))\n",
        "    add_to_dreamfusion_output(Text(\"Generating your 3D model, this'll take a while...  Estimating \" + estimate))\n",
        "    add_to_dreamfusion_output(ProgressBar())\n",
        "    df_path = os.path.join(root_dir, \"stable-dreamfusion\")\n",
        "    os.chdir(df_path)\n",
        "    run_str = f'python main.py -O --text \"{dreamfusion_prefs[\"prompt_text\"]}\" --workspace {dreamfusion_prefs[\"workspace\"]} --iters {dreamfusion_prefs[\"training_iters\"]} --lr {dreamfusion_prefs[\"learning_rate\"]} --w {dreamfusion_prefs[\"training_nerf_resolution\"]} --h {dreamfusion_prefs[\"training_nerf_resolution\"]} --seed {dreamfusion_prefs[\"seed\"]} --lambda_entropy {dreamfusion_prefs[\"lambda_entropy\"]} --ckpt {dreamfusion_prefs[\"checkpoint\"]} --save_mesh --max_steps {dreamfusion_prefs[\"max_steps\"]}'\n",
        "    print(run_str)\n",
        "    torch.cuda.empty_cache()\n",
        "    try:\n",
        "      run_process(run_str, page=page)\n",
        "    except:\n",
        "      clear_last()\n",
        "      alert_msg(page, \"Error running DreamFusion, probably Out of Memory. Adjust settings & try again.\")\n",
        "      return\n",
        "    clear_last()\n",
        "    add_to_dreamfusion_output(Text(\"Finished generating obj model, texture and video... Hope it's good.\"))\n",
        "    df_out = os.path.join(df_path, dreamfusion_prefs[\"workspace\"])\n",
        "    if storage_type == \"Colab Google Drive\":\n",
        "      dreamfusion_out = os.path.join(prefs['image_output'].rpartition(slash)[0], 'dreamfusion_out', dreamfusion_prefs[\"workspace\"])\n",
        "      #os.makedirs(dreamfusion_out, exist_ok=True)\n",
        "      if os.path.exists(dreamfusion_out):\n",
        "        dreamfusion_out = available_folder(os.path.join(prefs['image_output'].rpartition(slash)[0], 'dreamfusion_out'), dreamfusion_prefs[\"workspace\"], 1)\n",
        "      shutil.copytree(df_out, dreamfusion_out)\n",
        "      add_to_dreamfusion_output(Text(f\"Saved to {dreamfusion_out}\"))\n",
        "    else:\n",
        "      add_to_dreamfusion_output(Text(f\"Saved to {df_out}\"))\n",
        "    # TODO: PyDrive2\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "\n",
        "def clear_img2img_pipe():\n",
        "  global pipe_img2img\n",
        "  if pipe_img2img is not None:\n",
        "    #print(\"Clearing out img2img pipeline for more VRAM\")\n",
        "    del pipe_img2img\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_img2img = None\n",
        "def clear_txt2img_pipe():\n",
        "  global pipe\n",
        "  if pipe is not None:\n",
        "    #print(\"Clearing out text2img pipeline for more VRAM\")\n",
        "    del pipe\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe = None\n",
        "def clear_unet_pipe():\n",
        "  global unet\n",
        "  if unet is not None:\n",
        "    #print(\"Clearing out unet custom pipeline for more VRAM\")\n",
        "    del unet\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    unet = None\n",
        "def clear_clip_guided_pipe():\n",
        "  global pipe_clip_guided\n",
        "  if pipe_clip_guided is not None:\n",
        "    #print(\"Clearing out CLIP Guided pipeline for more VRAM\")\n",
        "    del pipe_clip_guided\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_clip_guided = None\n",
        "def clear_conceptualizer_pipe():\n",
        "  global pipe_conceptualizer\n",
        "  if pipe_conceptualizer is not None:\n",
        "    #print(\"Clearing out CLIP Guided pipeline for more VRAM\")\n",
        "    del pipe_conceptualizer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_conceptualizer = None\n",
        "def clear_repaint_pipe():\n",
        "  global pipe_repaint\n",
        "  if pipe_repaint is not None:\n",
        "    del pipe_repaint\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_repaint = None\n",
        "def clear_imagic_pipe():\n",
        "  global pipe_imagic\n",
        "  if pipe_imagic is not None:\n",
        "    del pipe_imagic\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_imagic = None\n",
        "def clear_composable_pipe():\n",
        "  global pipe_composable\n",
        "  if pipe_composable is not None:\n",
        "    del pipe_composable\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_composable = None\n",
        "def clear_versatile_pipe():\n",
        "  global pipe_versatile\n",
        "  if pipe_versatile is not None:\n",
        "    del pipe_versatile\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_versatile = None\n",
        "def clear_versatile_text2img_pipe():\n",
        "  global pipe_versatile_text2img\n",
        "  if pipe_versatile_text2img is not None:\n",
        "    del pipe_versatile_text2img\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_versatile_text2img = None\n",
        "def clear_versatile_variation_pipe():\n",
        "  global pipe_versatile_variation\n",
        "  if pipe_versatile_variation is not None:\n",
        "    del pipe_versatile_variation\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_versatile_variation = None\n",
        "def clear_versatile_dualguided_pipe():\n",
        "  global pipe_versatile_dualguided\n",
        "  if pipe_versatile_dualguided is not None:\n",
        "    del pipe_versatile_dualguided\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_versatile_dualguided = None\n",
        "def clear_depth_pipe():\n",
        "  global pipe_depth\n",
        "  if pipe_depth is not None:\n",
        "    del pipe_depth\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_depth = None\n",
        "def clear_safe_pipe():\n",
        "  global pipe_safe\n",
        "  if pipe_safe is not None:\n",
        "    del pipe_safe\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_safe = None\n",
        "def clear_upscale_pipe():\n",
        "  global pipe_upscale\n",
        "  if pipe_upscale is not None:\n",
        "    del pipe_upscale\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_upscale = None\n",
        "def clear_image_variation_pipe():\n",
        "  global pipe_image_variation\n",
        "  if pipe_image_variation is not None:\n",
        "    del pipe_image_variation\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    pipe_image_variation = None\n",
        "def clear_pipes(allbut=None):\n",
        "    but = [] if allbut == None else [allbut] if type(allbut) is str else allbut\n",
        "    if not 'txt2img' in but: clear_txt2img_pipe()\n",
        "    if not 'img2img' in but: clear_img2img_pipe()\n",
        "    if not 'unet' in but: clear_unet_pipe()\n",
        "    if not 'clip_guided' in but: clear_clip_guided_pipe()\n",
        "    if not 'conceptualizer' in but: clear_conceptualizer_pipe()\n",
        "    if not 'repaint' in but: clear_repaint_pipe()\n",
        "    if not 'imagic' in but: clear_imagic_pipe()\n",
        "    if not 'composable': clear_composable_pipe()\n",
        "    if not 'versatile_text2img' in but: clear_versatile_text2img_pipe()\n",
        "    if not 'versatile_variation' in but: clear_versatile_variation_pipe()\n",
        "    if not 'versatile_dualguided' in but: clear_versatile_dualguided_pipe()\n",
        "    if not 'depth' in but: clear_depth_pipe()\n",
        "    if not 'safe' in but: clear_safe_pipe()\n",
        "    if not 'upscale' in but: clear_upscale_pipe()\n",
        "    if not 'image_variation' in but: clear_image_variation_pipe()\n",
        "\n",
        "import base64\n",
        "def get_base64(image_path):\n",
        "    with open(image_path, \"rb\") as img_file:\n",
        "        my_string = base64.b64encode(img_file.read()).decode('utf-8')\n",
        "        return my_string\n",
        "\n",
        "def available_file(folder, name, idx, ext='png'):\n",
        "  available = False\n",
        "  while not available:\n",
        "    # Todo, check if using PyDrive2\n",
        "    if os.path.isfile(os.path.join(folder, f'{name}-{idx}.{ext}')):\n",
        "      idx += 1\n",
        "    else: available = True\n",
        "  return os.path.join(folder, f'{name}-{idx}.{ext}')\n",
        "\n",
        "def available_folder(folder, name, idx):\n",
        "  available = False\n",
        "  while not available:\n",
        "    if os.path.isdir(os.path.join(folder, f'{name}-{idx}')):\n",
        "      idx += 1\n",
        "    else: available = True\n",
        "  return os.path.join(folder, f'{name}-{idx}')\n",
        "\n",
        "#import asyncio\n",
        "#async \n",
        "def start_diffusion(page):\n",
        "  global pipe, unet, pipe_img2img, pipe_clip_guided, pipe_interpolation, pipe_conceptualizer, pipe_imagic, pipe_depth, pipe_composable, pipe_versatile_text2img, pipe_versatile_variation, pipe_versatile_dualguided, pipe_safe, pipe_upscale\n",
        "  global SD_sampler, stability_api, total_steps, pb, prefs, args, total_steps\n",
        "  def prt(line, update=True):\n",
        "    if type(line) == str:\n",
        "      line = Text(line)\n",
        "    try:\n",
        "      page.imageColumn.controls.append(line)\n",
        "      if update:\n",
        "        page.imageColumn.update()\n",
        "    except Exception:\n",
        "      clear_image_output()\n",
        "      pass\n",
        "    if update:\n",
        "      page.Images.update()\n",
        "  def clear_last(update=True):\n",
        "    del page.imageColumn.controls[-1]\n",
        "    if update:\n",
        "      page.imageColumn.update()\n",
        "      page.Images.update()\n",
        "  abort_run = False\n",
        "  def abort_diffusion(e):\n",
        "    nonlocal abort_run\n",
        "    abort_run = True\n",
        "    page.snd_error.play()\n",
        "    page.snd_delete.play()\n",
        "  def callback_cancel(cancel) -> None:\n",
        "    callback_cancel.has_been_called = True\n",
        "    if abort_run:\n",
        "      return True\n",
        "  def download_image(e):\n",
        "    if is_Colab:\n",
        "      print(f\"{type(e.control.data)} {e.control.data}\")\n",
        "      from google.colab import files\n",
        "      if os.path.isfile(e.control.data):\n",
        "        files.download(e.control.data)\n",
        "      else:\n",
        "        time.sleep(5)\n",
        "        files.download(e.control.data)\n",
        "  def clear_image_output():\n",
        "    for co in reversed(page.imageColumn.controls):\n",
        "      del co\n",
        "    page.imageColumn.controls.clear()\n",
        "    try:\n",
        "      page.imageColumn.update()\n",
        "    except Exception as e:\n",
        "      try:\n",
        "        page.imageColumn = Column([], auto_scroll=True, scroll=ScrollMode.AUTO)\n",
        "      except Exception as er:\n",
        "        alert_msg(page, f\"ERROR: Problem Clearing Image Output List. May need to stop script and restart app to recover, sorry...\", content=Text(f'{e}\\n{er}'))\n",
        "        page.Images = buildImages(page)\n",
        "        pass\n",
        "      page.update()\n",
        "      pass\n",
        "# Why getting Exception: control with ID '_3607' not found when re-running after error\n",
        "  #page.Images.content.controls = []\n",
        "  clear_image_output()\n",
        "  pb.width=page.width - 50\n",
        "  prt(Row([Text(\"‚ñ∂Ô∏è   Running Stable Diffusion on Batch Prompts List\", style=TextThemeStyle.TITLE_LARGE), IconButton(icon=icons.CANCEL, tooltip=\"Abort Current Diffusion Run\", on_click=abort_diffusion)], alignment=MainAxisAlignment.SPACE_BETWEEN))\n",
        "  import string, shutil, random, gc, io, json\n",
        "  from collections import ChainMap\n",
        "  import PIL\n",
        "  from PIL import Image as PILImage\n",
        "  from PIL.PngImagePlugin import PngInfo\n",
        "  import numpy as np\n",
        "  from contextlib import contextmanager, nullcontext\n",
        "  import copy\n",
        "\n",
        "  if status['installed_diffusers']:\n",
        "    from diffusers import StableDiffusionPipeline\n",
        "  os.chdir(stable_dir)\n",
        "  generator = None\n",
        "  clear_repaint_pipe()\n",
        "  output_files = []\n",
        "  retry_attempts_if_NSFW = prefs['retry_attempts']\n",
        "  #if (prefs['use_Stability_api'] and status['installed_stability']) or bool(not status['installed_diffusers'] and status['installed_stability']):\n",
        "  #  update_stability()\n",
        "  last_seed = args['seed']\n",
        "  if args['seed'] < 1 or args['seed'] is None:\n",
        "    rand_seed = random.randint(0,2147483647)\n",
        "    if not (prefs['use_Stability_api'] or (not status['installed_diffusers'] and status['installed_stability'])):\n",
        "      if use_custom_scheduler:\n",
        "        generator = torch.manual_seed(rand_seed)\n",
        "      else:\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(rand_seed)\n",
        "    last_seed = rand_seed\n",
        "  else:\n",
        "    if not (prefs['use_Stability_api'] or (not status['installed_diffusers'] and status['installed_stability'])):\n",
        "      if use_custom_scheduler:\n",
        "        generator = torch.manual_seed(args['seed'])\n",
        "      else:\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(args['seed'])\n",
        "  strikes = 0\n",
        "  p_idx = 0\n",
        "  if prefs['centipede_prompts_as_init_images']:\n",
        "    os.makedirs(os.path.join(root_dir, 'init_images'), exist_ok=True)\n",
        "  last_image = None\n",
        "  updated_prompts = []\n",
        "  model = get_model(prefs['model_ckpt'])\n",
        "  if not (prefs[\"use_interpolation\"] and status['installed_interpolation']):\n",
        "    for p in prompts:\n",
        "      pr = None\n",
        "      arg = {}\n",
        "      if type(p) == list or type(p) == str:\n",
        "        pr = p\n",
        "        arg = args.copy()\n",
        "      elif isinstance(p, Dream):\n",
        "        pr = p.prompt\n",
        "        arg = merge_dict(args, p.arg)\n",
        "      else: prt(f'Unknown item in list of type {type(p)}')\n",
        "      #print(str(arg))\n",
        "      arg['width'] = int(arg['width'])\n",
        "      arg['height'] = int(arg['height'])\n",
        "      arg['seed'] = int(arg['seed'])\n",
        "      arg['guidance_scale'] = float(arg['guidance_scale'])\n",
        "      arg['batch_size'] = int(arg['batch_size'])\n",
        "      arg['n_iterations'] = int(arg['n_iterations'])\n",
        "      arg['steps'] = int(arg['steps'])\n",
        "      arg['eta'] = float(arg['eta'])\n",
        "      arg['init_image_strength'] = float(arg['init_image_strength'])\n",
        "      p.arg = arg\n",
        "      iterations = arg['n_iterations']\n",
        "      updated_prompts.append(p)\n",
        "      if iterations > 1:\n",
        "        #print(f\"Iterating {iterations} times - {pr}\")\n",
        "        for d in range(iterations - 1):\n",
        "          new_dream = None\n",
        "          if isinstance(p, Dream):\n",
        "            new_dream = copy.copy(p)\n",
        "            new_dream.prompt = pr[0] if type(pr) == list else pr\n",
        "            new_arg = new_dream.arg.copy()\n",
        "            new_arg['seed'] = random.randint(0,2147483647)\n",
        "            new_arg['n_iterations'] = 1\n",
        "            new_dream.arg = new_arg\n",
        "            #new_dream.arg['seed'] = random.randint(0,4294967295)\n",
        "          else:\n",
        "            new_dream = Dream(p, seed=random.randint(0,2147483647), n_iterations=1)\n",
        "          new_dream.arg['n_iterations'] = 1\n",
        "          #prompts.insert(p_idx+1, new_dream)\n",
        "          updated_prompts.append(new_dream)\n",
        "\n",
        "    if bool(model['prefix']):\n",
        "      if model['prefix'][-1] != ' ':\n",
        "        model['prefix'] = model['prefix'] + ' '\n",
        "    for p in updated_prompts:\n",
        "      pr = \"\"\n",
        "      images = None\n",
        "      usable_image = True\n",
        "      arg = {}\n",
        "      if type(p) == list or type(p) == str:\n",
        "        pr = model['prefix'] + p\n",
        "        arg = args.copy()\n",
        "      elif isinstance(p, Dream):\n",
        "        pr = model['prefix'] + p.prompt\n",
        "        arg = merge_dict(args, p.arg)\n",
        "      else: prt(f\"Unknown object {type(p)} in the prompt list\")\n",
        "      if arg['batch_size'] > 1:\n",
        "        pr = [pr] * arg['batch_size']\n",
        "        if bool(arg['negative_prompt']):\n",
        "          arg['negative_prompt'] = [arg['negative_prompt']] * arg['batch_size']\n",
        "      if last_seed != arg['seed']:\n",
        "        if arg['seed'] < 1 or arg['seed'] is None:\n",
        "          rand_seed = random.randint(0,2147483647)\n",
        "          if not (prefs['use_Stability_api'] or (not status['installed_diffusers'] and status['installed_stability'])):\n",
        "            if use_custom_scheduler:\n",
        "              generator = torch.manual_seed(rand_seed)\n",
        "            else:\n",
        "              generator = torch.Generator(\"cuda\").manual_seed(rand_seed)\n",
        "          arg['seed'] = rand_seed\n",
        "        else:\n",
        "          if not(prefs['use_Stability_api'] or (not status['installed_diffusers'] and status['installed_stability'])):\n",
        "            if use_custom_scheduler:\n",
        "              generator = torch.manual_seed(arg['seed'])\n",
        "            else:\n",
        "              generator = torch.Generator(\"cuda\").manual_seed(arg['seed'])\n",
        "        last_seed = arg['seed']\n",
        "      if prefs['centipede_prompts_as_init_images'] and last_image is not None:\n",
        "        arg['init_image'] = last_image\n",
        "      p_count = f'[{p_idx + 1} of {len(updated_prompts)}]  '\n",
        "      #if p_idx % 30 == 0 and p_idx > 1:\n",
        "      #  clear_output()\n",
        "      #  print(f\"{Color.BEIGE2}Cleared console display due to memory limit in console logging.  Images still saving.{Color.END}\")\n",
        "      prt(Divider(height=6, thickness=2), update=False)\n",
        "      prt(Row([Text(p_count), Text(pr[0] if type(pr) == list else pr, expand=True, weight=FontWeight.BOLD), Text(f'seed: {arg[\"seed\"]}   ')]))\n",
        "      time.sleep(0.1)\n",
        "      page.auto_scrolling(False)\n",
        "      #prt(p_count + ('‚îÄ' * 90))\n",
        "      #prt(f'{pr[0] if type(pr) == list else pr} - seed:{arg[\"seed\"]}')\n",
        "      total_steps = arg['steps']\n",
        "      \n",
        "      if prefs['use_Stability_api'] or bool(arg['use_Stability'] or (not status['installed_diffusers'] and status['installed_stability'])):\n",
        "        if not status['installed_stability']:\n",
        "          alert_msg(page, f\"ERROR: To use Stability-API, you must run the install it first and have proper API key\")\n",
        "          return\n",
        "        else:\n",
        "          prt('Stablity API Diffusion ')# + ('‚îÄ' * 100))\n",
        "          #print(f'\"{SD_prompt}\", height={SD_height}, width={SD_width}, steps={SD_steps}, cfg_scale={SD_guidance_scale}, seed={SD_seed}, sampler={generation_sampler}')\n",
        "          #strikes = 0\n",
        "          images = []\n",
        "          arg['width'] = multiple_of_64(arg['width'])\n",
        "          arg['height'] = multiple_of_64(arg['height'])\n",
        "          prt(pb)\n",
        "          import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
        "          answers = response = None\n",
        "          \n",
        "          import requests\n",
        "          from io import BytesIO\n",
        "          import base64\n",
        "          api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
        "          engine_id = prefs['model_checkpoint']# if prefs['model_checkpoint'] == \"stable-diffusion-v1-5\" else \"stable-diffusion-v1\"\n",
        "          url = f\"{api_host}/v1alpha/generation/{engine_id}/\"#image-to-image\"\n",
        "          headers = {\n",
        "              'Content-Type': 'application/json',\n",
        "              'Accept': 'application/json',#'image/png',\n",
        "              'Authorization': prefs['Stability_api_key'],\n",
        "          }\n",
        "          payload = {\n",
        "              \"cfg_scale\": arg['guidance_scale'],\n",
        "              \"clip_guidance_preset\": prefs['clip_guidance_preset'],\n",
        "              \"height\": arg['height'],\n",
        "              \"width\": arg['width'],\n",
        "              \"sampler\": prefs['generation_sampler'],\n",
        "              \"samples\": arg['batch_size'],\n",
        "              \"seed\": arg['seed'],\n",
        "              \"steps\": arg['steps'],\n",
        "              \"text_prompts\": [\n",
        "                  {\n",
        "                      \"text\": pr,\n",
        "                      \"weight\": 1\n",
        "                  }\n",
        "              ],\n",
        "          }\n",
        "          if bool(arg['negative_prompt']):\n",
        "            payload['text_prompts'].append({\"text\": arg['negative_prompt'], \"weight\": -1})\n",
        "\n",
        "          if bool(arg['mask_image']) or (bool(arg['init_image']) and arg['alpha_mask']):\n",
        "            if not bool(arg['init_image']):\n",
        "              clear_last()\n",
        "              prt(f\"ERROR: You have not selected an init_image to go with your image mask..\")\n",
        "              continue\n",
        "            if arg['init_image'].startswith('http'):\n",
        "              response = requests.get(arg['init_image'])\n",
        "              init_img = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "            else:\n",
        "              if os.path.isfile(arg['init_image']):\n",
        "                init_img = PILImage.open(arg['init_image'])\n",
        "              else: \n",
        "                clear_last()\n",
        "                prt(f\"ERROR: Couldn't find your init_image {arg['init_image']}\")\n",
        "            init_img = init_img.resize((arg['width'], arg['height']))\n",
        "            buff = BytesIO()\n",
        "            init_img.save(buff, format=\"PNG\")\n",
        "            buff.seek(0)\n",
        "            img_str = io.BufferedReader(buff).read()\n",
        "            #init_image = preprocess(init_img)\n",
        "            if not arg['alpha_mask']:\n",
        "              if arg['mask_image'].startswith('http'):\n",
        "                response = requests.get(arg['mask_image'])\n",
        "                mask_img = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "              else:\n",
        "                if os.path.isfile(arg['mask_image']):\n",
        "                  mask_img = PILImage.open(arg['mask_image'])\n",
        "                else:\n",
        "                  clear_last()\n",
        "                  prt(f\"ERROR: Couldn't find your mask_image {arg['mask_image']}\")\n",
        "              mask = mask_img.resize((arg['width'], arg['height']))\n",
        "\n",
        "              buff = BytesIO()\n",
        "              mask.save(buff, format=\"PNG\")\n",
        "              buff.seek(0)\n",
        "              mask_str = io.BufferedReader(buff).read()\n",
        "            payload[\"step_schedule_end\"] = 0.01\n",
        "            payload[\"step_schedule_start\"] = 1 - arg['init_image_strength']\n",
        "            files = {\n",
        "                'init_image': img_str,#base64.b64encode(init_img.tobytes()).decode(),#open(init_img, 'rb'),\n",
        "                #'mask_image': mask_str,\n",
        "                'mask_source': \"init-image-alpha\" if arg['alpha_mask'] else \"mask-image-black\" if arg['invert_mask'] else \"mask-image-white\",\n",
        "                'options': (None, json.dumps(payload)),\n",
        "            }\n",
        "            if not arg['alpha_mask']:\n",
        "              files['mask_image'] = mask_str\n",
        "            #engine_id = prefs['model_checkpoint'] if prefs['model_checkpoint'] == \"stable-diffusion-v1-5\" else \"stable-diffusion-v1\"\n",
        "            response = requests.post(url+\"inpainting\", headers=headers, files=files)\n",
        "            #answers = stability_api.generate(prompt=pr, height=arg['height'], width=arg['width'], mask_image=mask, init_image=init_img, start_schedule= 1 - arg['init_image_strength'], steps=arg['steps'], cfg_scale=arg['guidance_scale'], samples=arg['batch_size'], safety=not prefs[\"disable_nsfw_filter\"], seed=arg['seed'], sampler=SD_sampler)\n",
        "          elif bool(arg['init_image']):\n",
        "            if arg['init_image'].startswith('http'):\n",
        "              response = requests.get(arg['init_image'])\n",
        "              init_img = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "            else:\n",
        "              if os.path.isfile(arg['init_image']):\n",
        "                init_img = PILImage.open(arg['init_image']).convert(\"RGB\")\n",
        "              else:\n",
        "                clear_last()\n",
        "                prt(f\"ERROR: Couldn't find your init_image {arg['init_image']}\")\n",
        "            init_img = init_img.resize((arg['width'], arg['height']))\n",
        "            \n",
        "            buff = BytesIO()\n",
        "            init_img.save(buff, format=\"PNG\")\n",
        "            buff.seek(0)\n",
        "            img_str = io.BufferedReader(buff).read()\n",
        "            #img_str = open(buff.read(), 'rb') #base64.b64encode(buff.getvalue())  init_img.tobytes(\"raw\")\n",
        "            payload[\"step_schedule_end\"] = 0.01\n",
        "            payload[\"step_schedule_start\"] = 1 - arg['init_image_strength']\n",
        "            files = {\n",
        "                'init_image': img_str,#base64.b64encode(init_img.tobytes()).decode(),#open(init_img, 'rb'),\n",
        "                'options': (None, json.dumps(payload)),\n",
        "            }\n",
        "            response = requests.post(url+\"image-to-image\", headers=headers, files=files)\n",
        "            #answers = stability_api.generate(prompt=pr, height=arg['height'], width=arg['width'], init_image=init_img, start_schedule= 1 - arg['init_image_strength'], steps=arg['steps'], cfg_scale=arg['guidance_scale'], samples=arg['batch_size'], safety=not prefs[\"disable_nsfw_filter\"], seed=arg['seed'], sampler=SD_sampler)\n",
        "          else:\n",
        "            response = requests.post(url+\"text-to-image\", headers=headers, json=payload)\n",
        "            #answers = stability_api.generate(prompt=pr, height=arg['height'], width=arg['width'], steps=arg['steps'], cfg_scale=arg['guidance_scale'], seed=arg['seed'], samples=arg['batch_size'], safety=False, sampler=SD_sampler)\n",
        "          clear_last(update=False)\n",
        "          clear_last()\n",
        "          if response != None:\n",
        "            if response.status_code != 200:\n",
        "              if response.status_code == 402:\n",
        "                alert_msg(page, \"Stability-API ERROR: Insufficient Credit Balance. Reload at DreamStudio.com...\", content=Text(str(response.text)))\n",
        "                return\n",
        "              else:\n",
        "                prt(f\"Stability-API ERROR {response.status_code}: \" + str(response.text))\n",
        "                continue\n",
        "            #with open(output_file, \"wb\") as f:\n",
        "            #  f.write(response.content)\n",
        "            artifacts = json.loads(response.content)\n",
        "            for resp in artifacts['artifacts']:\n",
        "              #print(f'{type(resp)} - {resp[\"seed\"]}')\n",
        "              if resp == None: continue\n",
        "              images.append(PILImage.open(io.BytesIO(base64.b64decode(resp['base64']))))\n",
        "            #print(f'{type(response.content)} {response.content}')\n",
        "          if answers != None:\n",
        "            for resp in answers:\n",
        "              for artifact in resp.artifacts:\n",
        "                #print(\"Artifact reason: \" + str(artifact.finish_reason))\n",
        "                if artifact.finish_reason == generation.FILTER:         \n",
        "                  usable_image = False\n",
        "                if artifact.finish_reason == generation.ARTIFACT_TEXT:         \n",
        "                  usable_image = False\n",
        "                  prt(f\"Couldn't process NSFW text in prompt.  Can't retry so change your request.\")\n",
        "                if artifact.type == generation.ARTIFACT_IMAGE:\n",
        "                  images.append(PILImage.open(io.BytesIO(artifact.binary)))\n",
        "\n",
        "      else:\n",
        "        #from torch.amp.autocast_mode import autocast\n",
        "        #precision_scope = autocast if prefs['precision']==\"autocast\" else nullcontext\n",
        "        try:\n",
        "          if use_custom_scheduler and not bool(arg['init_image']) and not bool(arg['mask_image']) and not bool(arg['prompt2']):\n",
        "            # Not implemented correctly anymore, old code but might reuse custom\n",
        "            text_input = tokenizer(pr[0] if type(pr) == list else pr, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
        "            with torch.no_grad():\n",
        "              text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]# We'll also get the unconditional text embeddings for classifier-free guidance, which are just the embeddings for the padding token (empty text). They need to have the same shape as the conditional text_embeddings (batch_size and seq_length)\n",
        "            max_length = text_input.input_ids.shape[-1]\n",
        "            uncond_input = tokenizer([\"\"] * arg['batch_size'], padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
        "            with torch.no_grad():\n",
        "              uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]   #For classifier-free guidance, we need to do two forward passes. One with the conditioned input (`text_embeddings`), and another with the unconditional embeddings (`uncond_embeddings`). In practice, we can concatenate both into a single batch to avoid doing two forward passes.\n",
        "\n",
        "            text_embeddings = torch.cat([uncond_embeddings, text_embeddings])#Generate the intial random noise.\n",
        "            #if generator:\n",
        "            #latents = torch.randn((arg['batch_size'], unet.in_channels, arg['height'], arg['width']), generator=generator)\n",
        "            latents = torch.randn((arg['batch_size'], unet.in_channels, arg['height'] // 8,  arg['width'] // 8), generator=generator)\n",
        "            #else:\n",
        "            #  latents = torch.randn((batch_size, unet.in_channels, arg['height'] // 8, arg['width'] // 8))\n",
        "            latents = latents.to(torch_device)\n",
        "            latents.shape\n",
        "            #Cool  64√ó64  is expected. The model will transform this latent representation (pure noise) into a 512 √ó 512 image later on.\n",
        "            #Next, we initialize the scheduler with our chosen num_inference_steps. This will compute the sigmas and exact time step values to be used during the denoising process.\n",
        "            scheduler.set_timesteps(arg['steps'])#The K-LMS scheduler needs to multiple the `latents` by its `sigma` values. Let's do this here\n",
        "            if prefs['scheduler_mode'] == \"K-LMS\" or prefs['scheduler_mode'] == \"Score-SDE-Vp\":\n",
        "              latents = latents * scheduler.sigmas[0]#We are ready to write the denoising loop.\n",
        "            from tqdm.auto import tqdm\n",
        "            clear_pipes(\"unet\")\n",
        "            if unet is None:\n",
        "              unet = get_unet_pipe()\n",
        "            #with precision_scope(\"cuda\"):\n",
        "            #with autocast(\"cuda\"):\n",
        "            for i, t in tqdm(enumerate(scheduler.timesteps)):\n",
        "              # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
        "              latent_model_input = torch.cat([latents] * 2)\n",
        "              if prefs['scheduler_mode'] == \"K-LMS\" or prefs['scheduler_mode'] == \"Score-SDE-Vp\":\n",
        "                sigma = scheduler.sigmas[i]\n",
        "                latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5)\n",
        "              # predict the noise residual\n",
        "              if prefs['scheduler_mode'] == \"DDPM\":\n",
        "                #TODO: Work in progress, still not perfect\n",
        "                noisy_sample = torch.randn(1, unet.config.in_channels, unet.config.sample_size, unet.config.sample_size)\n",
        "                noisy_residual = unet(sample=noisy_sample, timestep=2)[\"sample\"]\n",
        "                less_noisy_sample = scheduler.step(model_output=noisy_residual, timestep=2, sample=noisy_sample)[\"prev_sample\"]\n",
        "                less_noisy_sample.shape\n",
        "              with torch.no_grad():\n",
        "                noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).images\n",
        "              # perform guidance\n",
        "              noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "              noise_pred = noise_pred_uncond + arg['guidance_scale'] * (noise_pred_text - noise_pred_uncond)\n",
        "              # compute the previous noisy sample x_t -> x_t-1\n",
        "              latents = scheduler.step(noise_pred, i, latents)[\"prev_sample\"]#We now use the vae to decode the generated latents back into the image.\n",
        "            # scale and decode the image latents with vae\n",
        "            latents = 1 / 0.18215 * latents\n",
        "            with torch.no_grad():\n",
        "              image = vae.decode(latents)\n",
        "            image = (image / 2 + 0.5).clip(0, 1)\n",
        "            image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
        "            uint8_images = (image * 255).round().astype(\"uint8\")\n",
        "            #for img in uint8_images: images.append(Image.fromarray(img))\n",
        "            images = [PILImage.fromarray(img) for img in uint8_images]\n",
        "          else:\n",
        "            if bool(arg['use_clip_guided_model']) and status['installed_clip']:\n",
        "              if bool(arg['init_image']) or bool(arg['mask_image']):\n",
        "                #raise ValueError(\"Cannot use CLIP Guided Model with init or mask image yet.\")\n",
        "                alert_msg(page, \"Cannot use CLIP Guided Model with init or mask image yet.\")\n",
        "                return\n",
        "              clear_pipes(\"clip_guided\")\n",
        "              if pipe_clip_guided is None:\n",
        "                prt(Row([ProgressRing(), Text(\"Initializing CLIP-Guided Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                pipe_clip_guided = get_clip_guided_pipe()\n",
        "                clear_last()\n",
        "              clip_prompt = arg[\"clip_prompt\"] if arg[\"clip_prompt\"].strip() != \"\" else None\n",
        "              if bool(arg[\"unfreeze_unet\"]):\n",
        "                pipe_clip_guided.unfreeze_unet()\n",
        "              else:\n",
        "                pipe_clip_guided.freeze_unet()\n",
        "              if bool(arg[\"unfreeze_vae\"]):\n",
        "                pipe_clip_guided.unfreeze_vae()\n",
        "              else:\n",
        "                pipe_clip_guided.freeze_vae()\n",
        "              # TODO: Figure out why it's broken with use_cutouts=False and doesn't generate, hacking it True for now\n",
        "              arg[\"use_cutouts\"] = True \n",
        "              page.auto_scrolling(False)\n",
        "              prt(pb)\n",
        "              images = pipe_clip_guided(pr, height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], clip_prompt=clip_prompt, clip_guidance_scale=arg[\"clip_guidance_scale\"], num_cutouts=int(arg[\"num_cutouts\"]) if arg[\"use_cutouts\"] else None, use_cutouts=arg[\"use_cutouts\"], generator=generator).images\n",
        "              clear_last()\n",
        "              page.auto_scrolling(True)\n",
        "            elif bool(prefs['use_conceptualizer']) and status['installed_conceptualizer']:\n",
        "              clear_pipes(\"conceptualizer\")\n",
        "              if pipe_conceptualizer is None:\n",
        "                prt(Row([ProgressRing(), Text(\"Initializing Conceptualizer Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                pipe_conceptualizer = get_conceptualizer(page)\n",
        "                clear_last()\n",
        "              total_steps = arg['steps']\n",
        "              page.auto_scrolling(False)\n",
        "              prt(pb)\n",
        "              images = pipe_conceptualizer(prompt=pr, negative_prompt=arg['negative_prompt'], height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              clear_last()\n",
        "              page.auto_scrolling(True)\n",
        "            elif bool(arg['mask_image']) or (not bool(arg['mask_image']) and bool(arg['init_image']) and bool(arg['alpha_mask'])):\n",
        "              if not bool(arg['init_image']):\n",
        "                alert_msg(page, f\"ERROR: You have not selected an init_image to go with your image mask..\")\n",
        "                return\n",
        "              #if pipe_inpainting is None:\n",
        "              #  pipe_inpainting = get_inpainting_pipe()\n",
        "              if prefs['use_inpaint_model'] and status['installed_img2img']:\n",
        "                clear_pipes(\"img2img\")\n",
        "                if pipe_img2img is None:\n",
        "                  prt(Row([ProgressRing(), Text(\"Initializing Inpaint Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                  pipe_img2img = get_img2img_pipe()\n",
        "                  clear_last()\n",
        "              else:\n",
        "                clear_pipes(\"txt2img\")\n",
        "                if pipe is None:\n",
        "                  prt(Row([ProgressRing(), Text(\"Initializing Long Prompt Weighting Inpaint Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                  pipe = get_txt2img_pipe()\n",
        "                  clear_last()\n",
        "              '''if pipe_img2img is None:\n",
        "                try:\n",
        "                  pipe_img2img = get_img2img_pipe()\n",
        "                except NameError:\n",
        "                  prt(f\"{Color.RED}You must install the image2image Pipeline above.{Color.END}\")\n",
        "                finally:\n",
        "                  raise NameError(\"You must install the image2image Pipeline above\")'''\n",
        "              import requests\n",
        "              from io import BytesIO\n",
        "              if arg['init_image'].startswith('http'):\n",
        "                response = requests.get(arg['init_image'])\n",
        "                init_img = PILImage.open(BytesIO(response.content))\n",
        "              else:\n",
        "                if os.path.isfile(arg['init_image']):\n",
        "                  init_img = PILImage.open(arg['init_image'])\n",
        "                else: prt(f\"ERROR: Couldn't find your init_image {arg['init_image']}\")\n",
        "              if bool(arg['alpha_mask']):\n",
        "                init_img = init_img.convert(\"RGBA\")\n",
        "              else:\n",
        "                init_img = init_img.convert(\"RGB\")\n",
        "              init_img = init_img.resize((arg['width'], arg['height']))\n",
        "              #init_image = preprocess(init_img)\n",
        "              mask_img = None\n",
        "              if not bool(arg['mask_image']) and bool(arg['alpha_mask']):\n",
        "                mask_img = init_img.convert('RGBA')\n",
        "                red, green, blue, alpha = PILImage.Image.split(init_img)\n",
        "                mask_img = alpha.convert('L')\n",
        "              else:\n",
        "                if arg['mask_image'].startswith('http'):\n",
        "                  response = requests.get(arg['mask_image'])\n",
        "                  mask_img = PILImage.open(BytesIO(response.content))\n",
        "                else:\n",
        "                  if os.path.isfile(arg['mask_image']):\n",
        "                    mask_img = PILImage.open(arg['mask_image'])\n",
        "                  else: prt(f\"ERROR: Couldn't find your mask_image {arg['mask_image']}\")\n",
        "              if arg['invert_mask'] and not arg['alpha_mask']:\n",
        "                from PIL import ImageOps\n",
        "                mask_img = ImageOps.invert(mask_img.convert('RGB'))\n",
        "              mask_img = mask_img.convert(\"L\")\n",
        "              mask_img = mask_img.resize((arg['width'], arg['height']), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "              #mask = mask_img.resize((arg['width'], arg['height']))\n",
        "              #mask = np.array(mask).astype(np.float32) / 255.0\n",
        "              #mask = np.tile(mask,(4,1,1))\n",
        "              #mask = mask[None].transpose(0, 1, 2, 3)\n",
        "              #mask[np.where(mask != 0.0 )] = 1.0 #make sure mask is actually valid\n",
        "              #mask_img = torch.from_numpy(mask)\n",
        "              page.auto_scrolling(False)\n",
        "              prt(pb)\n",
        "              #with autocast(\"cuda\"):\n",
        "              if prefs['use_inpaint_model'] and status['installed_img2img']:\n",
        "                images = pipe_img2img(prompt=pr, negative_prompt=arg['negative_prompt'], mask_image=mask_img, image=init_img, strength= 1 - arg['init_image_strength'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              else:\n",
        "                images = pipe.inpaint(prompt=pr, negative_prompt=arg['negative_prompt'], mask_image=mask_img, image=init_img, strength= 1 - arg['init_image_strength'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              clear_last()\n",
        "              page.auto_scrolling(True)\n",
        "            elif bool(arg['init_image']):\n",
        "              if not status['installed_txt2img'] and not (prefs['use_imagic'] and status['installed_imagic']) and not (prefs['use_depth2img'] and status['installed_depth2img']):\n",
        "                alert_msg(page, f\"CRITICAL ERROR: You have not installed the image2image pipeline yet.  Run in the Installer..\")\n",
        "                continue\n",
        "              if prefs['use_versatile'] and status['installed_versatile']:\n",
        "                if len(pr.strip()) > 2: # Find another way to know the difference\n",
        "                  clear_pipes(\"versatile_dualguided\")\n",
        "                  if pipe_versatile_dualguided is None:\n",
        "                    prt(Row([ProgressRing(), Text(\"Initializing Versatile Dual-Guided Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                    pipe_versatile_dualguided = get_versatile_dualguided_pipe()\n",
        "                    clear_last()\n",
        "                else:\n",
        "                  clear_pipes(\"versatile_variation\")\n",
        "                  if pipe_versatile_variation is None:\n",
        "                    prt(Row([ProgressRing(), Text(\"Initializing Versatile Image Variation Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                    pipe_versatile_variation = get_versatile_variation_pipe()\n",
        "                    clear_last()\n",
        "              elif prefs['use_depth2img'] and status['installed_depth2img']:\n",
        "                clear_pipes(\"depth\")\n",
        "                if pipe_depth is None:\n",
        "                  prt(Row([ProgressRing(), Text(\"Initializing SD2 Depth2Image Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                  pipe_depth = get_depth_pipe()\n",
        "                  clear_last()\n",
        "              elif prefs['use_inpaint_model'] and status['installed_img2img']:\n",
        "                clear_pipes(\"img2img\")\n",
        "                if pipe_img2img is None:\n",
        "                  prt(Row([ProgressRing(), Text(\"Initializing Inpaint Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                  pipe_img2img = get_img2img_pipe()\n",
        "                  clear_last()\n",
        "              elif prefs['use_imagic'] and status['installed_imagic']:\n",
        "                clear_pipes(\"imagic\")\n",
        "                if pipe_imagic is None:\n",
        "                  prt(Row([ProgressRing(), Text(\"Initializing iMagic Image2Image Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                  pipe_imagic = get_imagic_pipe()\n",
        "                  clear_last()\n",
        "              else:\n",
        "                clear_pipes(\"txt2img\")\n",
        "                if pipe is None:\n",
        "                  prt(Row([ProgressRing(), Text(\"Initializing Long Prompt Weighting Image2Image Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                  pipe = get_txt2img_pipe()\n",
        "                  clear_last()\n",
        "              '''if pipe_img2img is None:\n",
        "                try:\n",
        "                  pipe_img2img = get_img2img_pipe()\n",
        "                except NameError:\n",
        "                  prt(f\"{Color.RED}You must install the image2image Pipeline above.{Color.END}\")\n",
        "                  raise NameError(\"You must install the image2image Pipeline above\")'''\n",
        "                #finally:\n",
        "              import requests\n",
        "              from io import BytesIO\n",
        "              if arg['init_image'].startswith('http'):\n",
        "                response = requests.get(arg['init_image'])\n",
        "                init_img = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "              else:\n",
        "                if os.path.isfile(arg['init_image']):\n",
        "                  init_img = PILImage.open(arg['init_image']).convert(\"RGB\")\n",
        "                else: alert_msg(page, f\"ERROR: Couldn't find your init_image {arg['init_image']}\")\n",
        "              init_img = init_img.resize((arg['width'], arg['height']))\n",
        "              #init_image = preprocess(init_img)\n",
        "              #white_mask = PILImage.new(\"RGB\", (arg['width'], arg['height']), (255, 255, 255))\n",
        "              page.auto_scrolling(False)\n",
        "              prt(pb)\n",
        "              #with autocast(\"cuda\"):\n",
        "              #images = pipe_img2img(prompt=pr, negative_prompt=arg['negative_prompt'], init_image=init_img, mask_image=white_mask, strength= 1 - arg['init_image_strength'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              if prefs['use_versatile'] and status['installed_versatile']:\n",
        "                if len(pr.strip()) > 2:\n",
        "                  images = pipe_versatile_dualguided(prompt=pr, negative_prompt=arg['negative_prompt'], image=init_img, text_to_image_strength= arg['init_image_strength'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "                else:\n",
        "                  images = pipe_versatile_variation(negative_prompt=arg['negative_prompt'], image=init_img, num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              elif prefs['use_depth2img'] and status['installed_depth2img']:\n",
        "                images = pipe_depth(prompt=pr, negative_prompt=arg['negative_prompt'], image=init_img, strength=arg['init_image_strength'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              elif prefs['use_inpaint_model'] and status['installed_img2img']:\n",
        "                white_mask = PILImage.new(\"RGB\", (arg['width'], arg['height']), (255, 255, 255))\n",
        "                images = pipe_img2img(prompt=pr, negative_prompt=arg['negative_prompt'], image=init_img, mask_image=white_mask, strength= 1 - arg['init_image_strength'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              elif prefs['use_imagic'] and status['installed_imagic']:\n",
        "                #only one element tensors can be converted to Python scalars\n",
        "                total_steps = None\n",
        "                res = pipe_imagic.train(pr, init_img, num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "                images = []\n",
        "                # TODO: alpha= arguments to customize which to make\n",
        "                total_steps = 0\n",
        "                res = pipe_imagic(alpha=1, callback=callback_fn, callback_steps=1)\n",
        "                images.append(res.images[0])\n",
        "                res = pipe_imagic(alpha=1.5, callback=callback_fn, callback_steps=1)\n",
        "                images.append(res.images[0])\n",
        "                res = pipe_imagic(alpha=2, callback=callback_fn, callback_steps=1)\n",
        "                images.append(res.images[0])\n",
        "              else:\n",
        "                images = pipe.img2img(prompt=pr, negative_prompt=arg['negative_prompt'], image=init_img, strength= 1 - arg['init_image_strength'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              clear_last()\n",
        "              page.auto_scrolling(True)\n",
        "            elif bool(arg['prompt2']):\n",
        "              if pipe is None:\n",
        "                pipe = get_txt2img_pipe()\n",
        "              #with precision_scope(\"cuda\"):\n",
        "              #    with torch.no_grad():\n",
        "              images_tween = pipe.lerp_between_prompts(pr, arg[\"prompt2\"], length = arg['tweens'], save=False, height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator)\n",
        "              #print(str(images_tween))\n",
        "              images = images_tween['images']\n",
        "              #images = pipe(pr, height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator)[\"sample\"]\n",
        "            else:\n",
        "              if prefs['use_composable'] and status['installed_composable']:\n",
        "                clear_pipes(\"composable\")\n",
        "                if pipe_composable is None:\n",
        "                  prt(Row([ProgressRing(), Text(\"Initializing Composable Text2Image Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                  pipe_composable = get_composable_pipe()\n",
        "                  clear_last()\n",
        "              elif prefs['use_versatile'] and status['installed_versatile']:\n",
        "                clear_pipes(\"versatile_text2img\")\n",
        "                if pipe_versatile_text2img is None:\n",
        "                  prt(Row([ProgressRing(), Text(\"Initializing Versatile Text2Image Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                  pipe_versatile_text2img = get_versatile_text2img_pipe()\n",
        "                  clear_last()\n",
        "              elif prefs['use_safe'] and status['installed_safe']:\n",
        "                clear_pipes(\"safe\")\n",
        "                if pipe_safe is None:\n",
        "                  prt(Row([ProgressRing(), Text(\"Initializing Safe Stable Diffusion Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                  pipe_safe = get_safe_pipe()\n",
        "                  clear_last()\n",
        "              elif pipe is None:\n",
        "                clear_pipes(\"txt2img\")\n",
        "                prt(Row([ProgressRing(), Text(\"Initializing Long Prompt Weighting Text2Image Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "                pipe = get_txt2img_pipe()\n",
        "                clear_last()\n",
        "              '''with io.StringIO() as buf, redirect_stdout(buf):\n",
        "                get_text2image(page)\n",
        "                output = buf.getvalue()\n",
        "                page.Images.content.controls.append(Text(output.strip())\n",
        "                page.Images.content.update()\n",
        "                page.Images.update()\n",
        "                page.update()'''\n",
        "              total_steps = arg['steps']\n",
        "              page.auto_scrolling(False)\n",
        "              prt(pb)\n",
        "              if prefs['use_composable'] and status['installed_composable']:\n",
        "                weights = arg['negative_prompt'] #\" 1 | 1\"  # Equal weight to each prompt. Can be negative\n",
        "                if not bool(weights):\n",
        "                  segments = len(pr.split('|'))\n",
        "                  weights = '|'.join(['1' * segments])\n",
        "                images = pipe_composable(pr, height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], weights=weights, generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              elif prefs['use_versatile'] and status['installed_versatile']:\n",
        "                images = pipe_versatile_text2img(prompt=pr, negative_prompt=arg['negative_prompt'], height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              elif prefs['use_safe'] and status['installed_safe']:\n",
        "                from diffusers.pipelines.stable_diffusion_safe import SafetyConfig\n",
        "                s = prefs['safety_config']\n",
        "                safety = SafetyConfig.WEAK if s == 'Weak' else SafetyConfig.MEDIUM if s == 'Medium' else SafetyConfig.STRONG if s == 'Strong' else SafetyConfig.MAX if s == 'Max' else SafetyConfig.STRONG \n",
        "                images = pipe_safe(prompt=pr, negative_prompt=arg['negative_prompt'], height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1, **safety).images\n",
        "              else:\n",
        "                images = pipe(prompt=pr, negative_prompt=arg['negative_prompt'], height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], generator=generator, callback=callback_fn, callback_steps=1).images\n",
        "              '''if prefs['precision'] == \"autocast\":\n",
        "                with autocast(\"cuda\"):\n",
        "                  images = pipe(pr, height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], seed = arg['seed'], generator=generator, callback=callback_fn, callback_steps=1)[\"sample\"]\n",
        "              else:\n",
        "                with precision_scope(\"cuda\"):\n",
        "                  with torch.no_grad():\n",
        "                    images = pipe(pr, height=arg['height'], width=arg['width'], num_inference_steps=arg['steps'], guidance_scale=arg['guidance_scale'], eta=arg['eta'], seed = arg['seed'], generator=generator, callback=callback_fn, callback_steps=1)[\"sample\"]'''\n",
        "              clear_last()\n",
        "              page.auto_scrolling(True)\n",
        "        except RuntimeError as e:\n",
        "          clear_last()\n",
        "          if 'out of memory' in str(e):\n",
        "            alert_msg(page, f\"CRITICAL ERROR: GPU ran out of memory! Flushing memory to save session... Try reducing image size.\", content=Text(str(e)))\n",
        "            pass\n",
        "          else:\n",
        "            alert_msg(page, f\"RUNTIME ERROR: Unknown error processing image. Check parameters and try again. Restart app if persists.\", content=Text(str(e)))\n",
        "            pass\n",
        "        except Exception as e:\n",
        "          alert_msg(page, f\"EXCEPTION ERROR: Unknown error processing image. Check parameters and try again. Restart app if persists.\", content=Text(str(e)))\n",
        "          pass\n",
        "        finally:\n",
        "          gc.collect()\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "      txt2img_output = stable_dir #f'{stable_dir}/stable-diffusion/outputs/txt2img-samples'\n",
        "      batch_output = prefs['image_output']\n",
        "      if bool(prefs['batch_folder_name']):\n",
        "        txt2img_output = os.path.join(stable_dir, prefs['batch_folder_name'])\n",
        "        batch_output = os.path.join(prefs['image_output'], prefs['batch_folder_name'])\n",
        "      if not os.path.exists(txt2img_output):\n",
        "        os.makedirs(txt2img_output)\n",
        "      if save_to_GDrive or storage_type == \"Colab Google Drive\":\n",
        "        if not os.path.exists(batch_output):\n",
        "          os.makedirs(batch_output)\n",
        "      elif storage_type == \"PyDrive Google Drive\": # TODO: I'm not getting the parent folder id right, their docs got confusing\n",
        "        newFolder = gdrive.CreateFile({'title': prefs['batch_folder_name'], \"parents\": [{\"kind\": \"drive#fileLink\", \"id\": prefs['image_output']}],\"mimeType\": \"application/vnd.google-apps.folder\"})\n",
        "        newFolder.Upload()\n",
        "        batch_output = newFolder\n",
        "      else:\n",
        "        if not os.path.exists(batch_output):\n",
        "          os.makedirs(batch_output)\n",
        "\n",
        "      filename = format_filename(pr[0] if type(pr) == list else pr)\n",
        "      if images is None:\n",
        "        prt(f\"ERROR: Problem generating images, check your settings and run above blocks again, or report the error to Skquark if it really seems broken.\")\n",
        "        images = []\n",
        "\n",
        "      idx = num = 0\n",
        "      for image in images:\n",
        "        cur_seed = arg['seed']\n",
        "        if idx > 0:\n",
        "          cur_seed += idx\n",
        "          i_count = f'  ({idx + 1} of {len(images)})  '\n",
        "          prt(Row([Text(i_count), Text(pr[0] if type(pr) == list else pr, expand=True, weight=FontWeight.BOLD), Text(f'seed: {cur_seed}   ')]))\n",
        "          #prt(f'{pr[0] if type(pr) == list else pr} - seed:{cur_seed}')\n",
        "        seed_suffix = \"\" if not prefs['file_suffix_seed'] else f\"-{cur_seed}\"\n",
        "        if prefs['use_imagic'] and status['installed_imagic'] and bool(arg['init_image'] and not bool(arg['mask_image'])):\n",
        "          if idx == 0: seed_suffix += '-alpha_1'\n",
        "          if idx == 1: seed_suffix += '-alpha_1_5'\n",
        "          if idx == 2: seed_suffix += '-alpha_2'\n",
        "        fname = f'{prefs[\"file_prefix\"]}{filename}{seed_suffix}'\n",
        "        image_path = available_file(txt2img_output, fname, idx)\n",
        "        num = int(image_path.rpartition('-')[2].partition('.')[0])\n",
        "        #image_path = os.path.join(txt2img_output, f'{fname}-{idx}.png')\n",
        "        image.save(image_path)\n",
        "        #print(f'size:{os.path.getsize(f\"{fname}-{idx}.png\")}')\n",
        "        if os.path.getsize(image_path) < 2000 or not usable_image: #False: #not sum(image.convert(\"L\").getextrema()) in (0, 2): #image.getbbox():#\n",
        "          os.remove(os.path.join(txt2img_output, f'{fname}-{num}.png'))\n",
        "          if strikes >= retry_attempts_if_NSFW:\n",
        "            if retry_attempts_if_NSFW != 0: prt(\"Giving up on finding safe image...\")\n",
        "            strikes = 0\n",
        "            continue\n",
        "          else: strikes += 1\n",
        "          new_dream = None\n",
        "          if isinstance(p, Dream):\n",
        "            new_dream = p\n",
        "            new_dream.prompt = pr[0] if type(pr) == list else pr\n",
        "            new_dream.arg['seed'] = random.randint(0,4294967295)\n",
        "          else:\n",
        "            new_dream = Dream(p, arg=dict(seed=random.randint(0,4294967295)))\n",
        "          updated_prompts.insert(p_idx+1, new_dream)\n",
        "          prt(f\"Filtered NSFW image, retrying prompt with new seed. Attempt {strikes} of {retry_attempts_if_NSFW}...\")\n",
        "          continue\n",
        "        else: strikes = 0\n",
        "        #if not prefs['display_upscaled_image'] or not prefs['apply_ESRGAN_upscale']:\n",
        "          #print(f\"Image path:{image_path}\")\n",
        "          #time.sleep(0.4)\n",
        "          #prt(Row([Img(src=image_path, width=arg['width'], height=arg['height'], fit=ImageFit.FILL, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "          #display(image)\n",
        "        #if bool(batch_folder_name):\n",
        "        #  fpath = os.path.join(txt2img_output, batch_folder_name, f'{fname}-{idx}.png')\n",
        "        #fpath = os.path.join(txt2img_output, f'{fname}-{idx}.png')\n",
        "        #fpath = available_file(txt2img_output, fname, idx)\n",
        "        fpath = image_path\n",
        "        if txt2img_output != batch_output:\n",
        "          new_file = available_file(batch_output, fname, num)\n",
        "        else:\n",
        "          new_file = image_path\n",
        "        #print(f'fpath: {fpath} - idx: {idx}')\n",
        "        if prefs['centipede_prompts_as_init_images']:\n",
        "          shutil.copy(fpath, os.path.join(root_dir, 'init_images'))\n",
        "          last_image = os.path.join(root_dir, 'init_images', f'{fname}-{num}.png')\n",
        "        if not prefs['display_upscaled_image'] or not prefs['apply_ESRGAN_upscale']:\n",
        "          #print(f\"Image path:{image_path}\")\n",
        "          upscaled_path = new_file #os.path.join(batch_output if save_to_GDrive else txt2img_output, new_file)\n",
        "          time.sleep(0.2)\n",
        "          #prt(Row([GestureDetector(content=Img(src_base64=get_base64(fpath), width=arg['width'], height=arg['height'], fit=ImageFit.FILL, gapless_playback=True), data=new_file, on_long_press_end=download_image, on_secondary_tap=download_image)], alignment=MainAxisAlignment.CENTER))\n",
        "          prt(Row([GestureDetector(content=Img(src=fpath, width=arg['width'], height=arg['height'], fit=ImageFit.FILL, gapless_playback=True), data=new_file, on_long_press_end=download_image, on_secondary_tap=download_image)], alignment=MainAxisAlignment.CENTER))\n",
        "          time.sleep(0.3)\n",
        "          #display(image)\n",
        "        if prefs['use_upscale'] and status['installed_upscale']:\n",
        "          clear_pipes(['upscale'])\n",
        "          if pipe_upscale == None:\n",
        "            prt(Row([ProgressRing(), Text(\"Initializing Stable Diffusion 2 Upscale Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "            pipe_upscale = get_upscale_pipe()\n",
        "            clear_last()\n",
        "          prt(Row([Text(\"Upscaling 4X\"), pb]))\n",
        "          try:\n",
        "            output = pipe_upscale(prompt=pr, image=image, guidance_scale=arg['guidance_scale'], generator=generator, noise_level=prefs['upscale_noise_level'], callback=callback_fn, callback_steps=1)\n",
        "            output.images[0].save(fpath)\n",
        "            clear_upscale()\n",
        "          except Exception as e:\n",
        "            alert_msg(page, \"Error Upscaling Image.  Most likely out of Memory... Reduce image size to less than 512px.\", content=Text(e))\n",
        "            pass\n",
        "          clear_last()\n",
        "          #clear_upscale_pipe()\n",
        "        if prefs['apply_ESRGAN_upscale'] and status['installed_ESRGAN']:\n",
        "          w = int(arg['width'] * prefs[\"enlarge_scale\"])\n",
        "          h = int(arg['height'] * prefs[\"enlarge_scale\"])\n",
        "          prt(Row([Text(f'Enlarging {prefs[\"enlarge_scale\"]}X to {w}x{h}')], alignment=MainAxisAlignment.CENTER))\n",
        "          os.chdir(os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "          upload_folder = 'upload'\n",
        "          result_folder = 'results'     \n",
        "          if os.path.isdir(upload_folder):\n",
        "              shutil.rmtree(upload_folder)\n",
        "          if os.path.isdir(result_folder):\n",
        "              shutil.rmtree(result_folder)\n",
        "          os.mkdir(upload_folder)\n",
        "          os.mkdir(result_folder)\n",
        "          short_name = f'{fname[:80]}-{num}.png'\n",
        "          dst_path = os.path.join(dist_dir, 'Real-ESRGAN', upload_folder, short_name)\n",
        "          #print(f'Moving {fpath} to {dst_path}')\n",
        "          #shutil.move(fpath, dst_path)\n",
        "          shutil.copy(fpath, dst_path)\n",
        "          faceenhance = ' --face_enhance' if prefs[\"face_enhance\"] else ''\n",
        "          #python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --outscale {enlarge_scale}{faceenhance}\n",
        "          run_sp(f'python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --outscale {prefs[\"enlarge_scale\"]}{faceenhance}', cwd=os.path.join(dist_dir, 'Real-ESRGAN'), realtime=False)\n",
        "          out_file = short_name.rpartition('.')[0] + '_out.png'\n",
        "          #print(f'move {root_dir}Real-ESRGAN/{result_folder}/{out_file} to {fpath}')\n",
        "          #shutil.move(f'{root_dir}Real-ESRGAN/{result_folder}/{out_file}', fpath)\n",
        "          shutil.move(os.path.join(dist_dir, 'Real-ESRGAN', result_folder, out_file), fpath)\n",
        "          # !python inference_realesrgan.py --model_path experiments/pretrained_models/RealESRGAN_x4plus.pth --input upload --netscale 4 --outscale 3.5 --half --face_enhance\n",
        "          os.chdir(stable_dir)\n",
        "          clear_last(update=False)\n",
        "        \n",
        "        config_json = arg.copy()\n",
        "        del config_json['batch_size']\n",
        "        del config_json['n_iterations']\n",
        "        del config_json['precision']\n",
        "        config_json['prompt'] = pr[0] if type(pr) == list else pr\n",
        "        config_json['sampler'] = prefs['generation_sampler'] if prefs['use_Stability_api'] else prefs['scheduler_mode']\n",
        "        if bool(prefs['meta_ArtistName']): config_json['artist'] = prefs['meta_ArtistName']\n",
        "        if bool(prefs['meta_Copyright']): config_json['copyright'] = prefs['meta_Copyright']\n",
        "        if prefs['use_Stability_api']: del config_json['eta']\n",
        "        del config_json['use_Stability']\n",
        "        if not bool(config_json['negative_prompt']): del config_json['negative_prompt']\n",
        "        if not bool(config_json['prompt2']):\n",
        "          del config_json['prompt2']\n",
        "          del config_json['tweens']\n",
        "        if not bool(config_json['init_image']):\n",
        "          del config_json['init_image']\n",
        "          del config_json['init_image_strength']\n",
        "          del config_json['alpha_mask']\n",
        "        if not bool(config_json['mask_image']):\n",
        "          del config_json['mask_image']\n",
        "          del config_json['invert_mask']\n",
        "        if not bool(config_json['use_clip_guided_model']):\n",
        "          del config_json[\"use_clip_guided_model\"]\n",
        "          del config_json[\"clip_prompt\"]\n",
        "          del config_json[\"clip_guidance_scale\"]\n",
        "          del config_json[\"num_cutouts\"]\n",
        "          del config_json[\"use_cutouts\"]\n",
        "          del config_json[\"unfreeze_unet\"]\n",
        "          del config_json[\"unfreeze_vae\"]\n",
        "        else:\n",
        "          config_json[\"clip_model_id\"] = prefs['clip_model_id']\n",
        "        if prefs['apply_ESRGAN_upscale']:\n",
        "          config_json['upscale'] = f\"Upscaled {prefs['enlarge_scale']}x with ESRGAN\" + (\" with GFPGAN Face-Enhance\" if prefs['face_enhance'] else \"\")\n",
        "        sampler_str = prefs['generation_sampler'] if prefs['use_Stability_api'] else prefs['scheduler_mode']\n",
        "        config_json['scheduler_mode'] = sampler_str\n",
        "        config_json['model_path'] = model_path\n",
        "        if prefs['save_image_metadata']:\n",
        "          img = PILImage.open(fpath)\n",
        "          metadata = PngInfo()\n",
        "          metadata.add_text(\"artist\", prefs['meta_ArtistName'])\n",
        "          metadata.add_text(\"copyright\", prefs['meta_Copyright'])\n",
        "          metadata.add_text(\"software\", \"Stable Diffusion Deluxe\" + f\", upscaled {prefs['enlarge_scale']}x with ESRGAN\" if prefs['apply_ESRGAN_upscale'] else \"\")\n",
        "          metadata.add_text(\"title\", pr[0] if type(pr) == list else pr)\n",
        "          if prefs['save_config_in_metadata']:\n",
        "            config = f\"prompt: {pr[0] if type(pr) == list else pr}, seed: {cur_seed}, steps: {arg['steps']}, CGS: {arg['guidance_scale']}, iterations: {arg['n_iterations']}\" + f\", eta: {arg['eta']}\" if not prefs['use_Stability_api'] else \"\"\n",
        "            config += f\", sampler: {sampler_str}\"\n",
        "            if bool(arg['init_image']): config += f\", init_image: {arg['init_image']}, init_image_strength: {arg['init_image_strength']}\"\n",
        "            metadata.add_text(\"config\", config)\n",
        "            #metadata.add_text(\"prompt\", p)\n",
        "            metadata.add_text(\"config_json\", json.dumps(config_json, ensure_ascii=True, indent=4))\n",
        "          img.save(fpath, pnginfo=metadata)\n",
        "\n",
        "        #new_file = available_file(batch_output if save_to_GDrive else txt2img_output, fname, idx)\n",
        "        #new_file = fname #.rpartition('.')[0] #f'{file_prefix}{filename}'\n",
        "        #if os.path.isfile(os.path.join(batch_output if save_to_GDrive else txt2img_output, f'{new_file}-{idx}.png')):\n",
        "        #  new_file += '-' + random.choice(string.ascii_letters) + random.choice(string.ascii_letters)\n",
        "        #new_file += f'-{idx}.png'\n",
        "        if save_to_GDrive:\n",
        "          shutil.copy(fpath, new_file)#os.path.join(batch_output, new_file))\n",
        "          #shutil.move(fpath, os.path.join(batch_output, new_file))\n",
        "        elif storage_type == \"PyDrive Google Drive\":\n",
        "          #batch_output\n",
        "          out_file = gdrive.CreateFile({'title': new_file})\n",
        "          out_file.SetContentFile(fpath)\n",
        "          out_file.Upload()\n",
        "        elif bool(prefs['image_output']):\n",
        "          shutil.copy(fpath, new_file)#os.path.join(batch_output, new_file))\n",
        "        if prefs['save_config_json']:\n",
        "          json_file = new_file.rpartition('.')[0] + '.json'\n",
        "          with open(os.path.join(stable_dir, json_file), \"w\") as f:\n",
        "            json.dump(config_json, f, ensure_ascii=False, indent=4)\n",
        "          if save_to_GDrive:\n",
        "            shutil.copy(os.path.join(stable_dir, json_file), os.path.join(batch_output, json_file))\n",
        "          elif storage_type == \"PyDrive Google Drive\":\n",
        "            #batch_output\n",
        "            out_file = gdrive.CreateFile({'title': json_file})\n",
        "            out_file.SetContentFile(os.path.join(stable_dir, json_file))\n",
        "            out_file.Upload()\n",
        "        output_files.append(os.path.join(batch_output if save_to_GDrive else txt2img_output, new_file))\n",
        "        if prefs['display_upscaled_image'] and prefs['apply_ESRGAN_upscale']:\n",
        "          upscaled_path = os.path.join(batch_output if save_to_GDrive else txt2img_output, new_file)\n",
        "          time.sleep(0.4)\n",
        "          #prt(Row([GestureDetector(content=Img(src_base64=get_base64(upscaled_path), width=arg['width'] * float(prefs[\"enlarge_scale\"]), height=arg['height'] * float(prefs[\"enlarge_scale\"]), fit=ImageFit.CONTAIN, gapless_playback=True), data=upscaled_path, on_long_press_end=download_image, on_secondary_tap=download_image)], alignment=MainAxisAlignment.CENTER))\n",
        "          prt(Row([GestureDetector(content=Img(src=upscaled_path, width=arg['width'] * float(prefs[\"enlarge_scale\"]), height=arg['height'] * float(prefs[\"enlarge_scale\"]), fit=ImageFit.CONTAIN, gapless_playback=True), data=upscaled_path, on_long_press_end=download_image, on_secondary_tap=download_image)], alignment=MainAxisAlignment.CENTER))\n",
        "          #prt(Row([Img(src=upscaled_path, width=arg['width'] * float(prefs[\"enlarge_scale\"]), height=arg['height'] * float(prefs[\"enlarge_scale\"]), fit=ImageFit.CONTAIN, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "          #prt(Img(src=upscaled_path))\n",
        "          #upscaled = PILImage.open(os.path.join(batch_output, new_file))\n",
        "          #display(upscaled)\n",
        "        #else:\n",
        "          #time.sleep(0.4)\n",
        "          #prt(Row([Img(src=new_file, width=arg['width'], height=arg['height'], fit=ImageFit.FILL, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "        prt(Row([Text(fpath.rpartition(slash)[2])], alignment=MainAxisAlignment.CENTER))\n",
        "        idx += 1\n",
        "        if abort_run:\n",
        "          prt(Text(\"üõë   Aborting Current Diffusion Run...\"))\n",
        "          abort_run = False\n",
        "          return\n",
        "      p_idx += 1\n",
        "      if abort_run:\n",
        "        prt(Text(\"üõë   Aborting Current Diffusion Run...\"))\n",
        "        abort_run = False\n",
        "        return\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "  else:\n",
        "    clear_pipes(\"interpolation\")\n",
        "    if pipe_interpolation is None:\n",
        "      pipe_interpolation = get_interpolation_pipe()\n",
        "    txt2img_output = os.path.join(stable_dir, prefs['batch_folder_name'] if bool(prefs['batch_folder_name']) else 'dreams')\n",
        "    batch_output = prefs['image_output']\n",
        "    if not os.path.exists(txt2img_output):\n",
        "      os.makedirs(txt2img_output)\n",
        "    #dream_name = prefs['batch_folder_name'] if bool(prefs['batch_folder_name']) else None\n",
        "    #first = prompts[0]\n",
        "    arg = args.copy()\n",
        "    arg['width'] = int(arg['width'])\n",
        "    arg['height'] = int(arg['height'])\n",
        "    arg['seed'] = int(arg['seed'])\n",
        "    arg['guidance_scale'] = float(arg['guidance_scale'])\n",
        "    arg['steps'] = int(arg['steps'])\n",
        "    arg['eta'] = float(arg['eta'])\n",
        "    walk_prompts = []\n",
        "    walk_seeds = []\n",
        "    for p in prompts:\n",
        "      walk_prompts.append(p.prompt)\n",
        "      if int(p.arg['seed']) < 1 or arg['seed'] is None:\n",
        "        walk_seeds.append(random.randint(0,4294967295))\n",
        "      else:\n",
        "        walk_seeds.append(int(p.arg['seed']))\n",
        "    img_idx = 0\n",
        "    from watchdog.observers import Observer\n",
        "    from watchdog.events import LoggingEventHandler, FileSystemEventHandler\n",
        "    class Handler(FileSystemEventHandler):\n",
        "      def __init__(self):\n",
        "        super().__init__()\n",
        "      def on_created(self,event):\n",
        "        nonlocal img_idx\n",
        "        if event.is_directory:\n",
        "          return None\n",
        "        elif event.event_type == 'created':\n",
        "          page.auto_scrolling(True)\n",
        "          clear_last()\n",
        "          #p_count = f'[{img_idx + 1} of {(len(walk_prompts) -1) * int(prefs['num_interpolation_steps'])}]  '\n",
        "          #prt(Divider(height=6, thickness=2))\n",
        "          #prt(Row([Text(p_count), Text(walk_prompts[img_idx], expand=True, weight=FontWeight.BOLD), Text(f'seed: {walk_seeds[img_idx]}')]))\n",
        "          prt(Row([Img(src=event.src_path, width=arg['width'], height=arg['height'], fit=ImageFit.FILL, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "          prt(Row([Text(f'{event.src_path}')], alignment=MainAxisAlignment.CENTER))\n",
        "          page.update()\n",
        "          time.sleep(0.2)\n",
        "          page.auto_scrolling(False)\n",
        "          prt(pb)\n",
        "          img_idx += 1\n",
        "    image_handler = Handler()\n",
        "    observer = Observer()\n",
        "    observer.schedule(image_handler, txt2img_output, recursive = True)\n",
        "    observer.start()\n",
        "    prt(f\"Interpolating latent space between {len(walk_prompts)} prompts with {int(prefs['num_interpolation_steps'])} steps between each.\")\n",
        "    prt(Divider(height=6, thickness=2))\n",
        "    prt(pb)\n",
        "    page.auto_scrolling(False)\n",
        "    #prt(Row([Text(p_count), Text(pr[0] if type(pr) == list else pr, expand=True, weight=FontWeight.BOLD), Text(f'seed: {arg[\"seed\"]}')]))\n",
        "    images = pipe_interpolation.walk(prompts=walk_prompts, seeds=walk_seeds, num_interpolation_steps=int(prefs['num_interpolation_steps']), batch_size=int(prefs['batch_size']), output_dir=txt2img_output, width=arg['width'], height=arg['height'], guidance_scale=arg['guidance_scale'], num_inference_steps=int(arg['steps']), eta=arg['eta'], callback=callback_fn, callback_steps=1)\n",
        "    observer.stop()\n",
        "    clear_last()\n",
        "    fpath = images[0].rpartition(slash)[0]\n",
        "    bfolder = fpath.rpartition(slash)[2]\n",
        "    if prefs['apply_ESRGAN_upscale'] and status['installed_ESRGAN']:\n",
        "      prt('Applying Real-ESRGAN Upscaling to images...')\n",
        "      os.chdir(os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "      upload_folder = 'upload'\n",
        "      result_folder = 'results'     \n",
        "      if os.path.isdir(upload_folder):\n",
        "          shutil.rmtree(upload_folder)\n",
        "      if os.path.isdir(result_folder):\n",
        "          shutil.rmtree(result_folder)\n",
        "      os.mkdir(upload_folder)\n",
        "      os.mkdir(result_folder)\n",
        "      for i in images:\n",
        "        fname = i.rpartition(slash)[2]\n",
        "        dst_path = os.path.join(dist_dir, 'Real-ESRGAN', upload_folder, fname)\n",
        "        shutil.move(i, dst_path)\n",
        "      faceenhance = ' --face_enhance' if prefs[\"face_enhance\"] else ''\n",
        "      run_sp(f'python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --outscale {prefs[\"enlarge_scale\"]}{faceenhance}', cwd=os.path.join(dist_dir, 'Real-ESRGAN'), realtime=False)\n",
        "      filenames = os.listdir(os.path.join(dist_dir, 'Real-ESRGAN', 'results'))\n",
        "      for oname in filenames:\n",
        "        fparts = oname.rpartition('_out')\n",
        "        fname_clean = fparts[0] + fparts[2]\n",
        "        opath = os.path.join(fpath, fname_clean)\n",
        "        shutil.move(os.path.join(dist_dir, 'Real-ESRGAN', result_folder, oname), opath)\n",
        "      os.chdir(stable_dir)\n",
        "    os.makedirs(os.path.join(batch_output, bfolder), exist_ok=True)\n",
        "    imgs = os.listdir(fpath)\n",
        "    for i in imgs:\n",
        "      #prt(f'Created {i}')\n",
        "      #fname = i.rpartition(slash)[2]\n",
        "      if save_to_GDrive:\n",
        "        shutil.copy(os.path.join(fpath, i), os.path.join(batch_output, bfolder, i))\n",
        "      elif storage_type == \"PyDrive Google Drive\":\n",
        "        #batch_output\n",
        "        out_file = gdrive.CreateFile({'title': i})\n",
        "        out_file.SetContentFile(fpath)\n",
        "        out_file.Upload()\n",
        "      elif bool(prefs['image_output']):\n",
        "        shutil.copy(os.path.join(fpath, i), os.path.join(batch_output, bfolder, i))\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "\n",
        "\n",
        "def wget(url, output):\n",
        "    import subprocess\n",
        "    res = subprocess.run(['wget', '-q', url, '-O', output], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "nspterminology = None\n",
        "\n",
        "def nsp_parse(prompt):\n",
        "    import random, os, json\n",
        "    global nspterminology\n",
        "    new_prompt = ''\n",
        "    new_prompts = []\n",
        "    new_dict = {}\n",
        "    ptype = type(prompt)\n",
        "    #if not os.path.exists('./nsp_pantry.json'):\n",
        "    #    wget('https://raw.githubusercontent.com/WASasquatch/noodle-soup-prompts/main/nsp_pantry.json', f'.{slash}nsp_pantry.json')\n",
        "    if nspterminology is None:\n",
        "        response = requests.get(\"https://raw.githubusercontent.com/WASasquatch/noodle-soup-prompts/main/nsp_pantry.json\")\n",
        "        nspterminology = json.loads(response.content)\n",
        "    if ptype == dict:\n",
        "        for pstep, pvalue in prompt.items():\n",
        "            if type(pvalue) == list:\n",
        "                for prompt in pvalue:\n",
        "                    new_prompt = prompt\n",
        "                    for term in nspterminology:\n",
        "                        tkey = f'_{term}_'\n",
        "                        tcount = prompt.count(tkey)\n",
        "                        for i in range(tcount):\n",
        "                            new_prompt = new_prompt.replace(tkey, random.choice(nspterminology[term]), 1)\n",
        "                    new_prompts.append(new_prompt)\n",
        "                new_dict[pstep] = new_prompts\n",
        "                new_prompts = []\n",
        "        return new_dict\n",
        "    elif ptype == list:\n",
        "        for pstr in prompt:\n",
        "            new_prompt = pstr\n",
        "            for term in nspterminology:\n",
        "                tkey = f'_{term}_'\n",
        "                tcount = new_prompt.count(tkey)\n",
        "                for i in range(tcount):\n",
        "                    new_prompt = new_prompt.replace(tkey, random.choice(nspterminology[term]), 1)\n",
        "            new_prompts.append(new_prompt)\n",
        "            new_prompt = None\n",
        "        return new_prompts\n",
        "    elif ptype == str:\n",
        "        new_prompt = prompt\n",
        "        for term in nspterminology:\n",
        "            tkey = f'_{term}_'\n",
        "            tcount = new_prompt.count(tkey)\n",
        "            for i in range(tcount):\n",
        "                new_prompt = new_prompt.replace(tkey, random.choice(nspterminology[term]), 1)\n",
        "        return new_prompt\n",
        "    else:\n",
        "        return\n",
        "\n",
        "\n",
        "artists = ( \"Ivan Aivazovsky\", \"Beeple\", \"Zdzislaw Beksinski\", \"Albert Bierstadt\", \"Noah Bradley\", \"Jim Burns\", \"John Harris\", \"John Howe\", \"Thomas Kinkade\", \"Gediminas Pranckevicius\", \"Andreas Rocha\", \"Marc Simonetti\", \"Simon Stalenhag\", \"Yuumei\", \"Asher Brown Durand\", \"Tyler Edlin\", \"Jesper Ejsing\", \"Peter Mohrbacher\", \"RHADS\", \"Greg Rutkowski\", \"H.P. Lovecraft\", \"George Lucas\", \"Benoit B. Mandelbrot\", \"Edwin Austin Abbey\", \"Ansel Adams\", \"Arthur Adams\", \"Charles Addams\", \"Alena Aenami\", \"Pieter Aertsen\", \"Hilma af Klint\", \"Affandi\", \"Leonid Afremov\", \"Eileen Agar\", \"Ivan Aivazovsky\", \"Anni Albers\", \"Josef Albers\", \"Ivan Albright\", \"Yoshitaka Amano\", \"Cuno Amiet\", \"Sophie Anderson\", \"Wes Anderson\", \"Esao Andrews\", \"Charles Angrand\", \"Sofonisba Anguissola\", \"Hirohiko Araki\", \"Nobuyoshi Araki\", \"Shinji Aramaki\", \"Diane Arbus\", \"Giuseppe Arcimboldo\", \"Steve Argyle\", \"Jean Arp\", \"Artgerm\", \"John James Audubon\", \"Frank Auerbach\", \"Milton Avery\", \"Tex Avery\", \"Harriet Backer\", \"Francis Bacon\", \"Peter Bagge\", \"Tom Bagshaw\", \"Karol Bak\", \"Christopher Balaskas\", \"Hans Baldung\", \"Ronald Balfour\", \"Giacomo Balla\", \"Banksy\", \"Cicely Mary Barker\", \"Carl Barks\", \"Wayne Barlowe\", \"Jean-Michel Basquiat\", \"Jules Bastien-Lepage\", \"David Bates\", \"John Bauer\", \"Aubrey Beardsley\", \"Jasmine Becket-Griffith\", \"Max Beckmann\", \"Beeple\", \"Zdzislaw Beksinski\", \"Zdzis≈Çaw Beksi≈Ñski\", \"Julie Bell\", \"Hans Bellmer\", \"John Berkey\", \"√âmile Bernard\", \"Elsa Beskow\", \"Albert Bierstadt\", \"Enki Bilal\", \"Ivan Bilibin\", \"Simon Bisley\", \"Charles Blackman\", \"Thomas Blackshear\", \"Mary Blair\", \"Quentin Blake\", \"William Blake\", \"Antoine Blanchard\", \"John Blanche\", \"Pascal Blanch√©\", \"Karl Blossfeldt\", \"Don Bluth\", \"Umberto Boccioni\", \"Arnold B√∂cklin\", \"Chesley Bonestell\", \"Franklin Booth\", \"Guido Borelli da Caluso\", \"Marius Borgeaud\", \"Hieronymous Bosch\", \"Hieronymus Bosch\", \"Sam Bosma\", \"Johfra Bosschart\", \"Sandro Botticelli\", \"William-Adolphe Bouguereau\", \"Louise Bourgeois\", \"Eleanor Vere Boyle\", \"Noah Bradley\", \"Victor Brauner\", \"Austin Briggs\", \"Raymond Briggs\", \"Mark Briscoe\", \"Romero Britto\", \"Gerald Brom\", \"Mark Brooks\", \"Patrick Brown\", \"Pieter Bruegel the Elder\", \"Bernard Buffet\", \"Laurel Burch\", \"Charles E. Burchfield\", \"David Burdeny\", \"Richard Burlet\", \"David Burliuk\", \"Edward Burne-Jones\", \"Jim Burns\", \"William S. Burroughs\", \"Gaston Bussi√®re\", \"Kaethe Butcher\", \"Jack Butler Yeats\", \"Bob Byerley\", \"Alexandre Cabanel\", \"Ray Caesar\", \"Claude Cahun\", \"Zhichao Cai\", \"Randolph Caldecott\", \"Alexander Milne Calder\", \"Clyde Caldwell\", \"Eddie Campbell\", \"Pascale Campion\", \"Canaletto\", \"Caravaggio\", \"Annibale Carracci\", \"Carl Gustav Carus\", \"Santiago Caruso\", \"Mary Cassatt\", \"Paul C√©zanne\", \"Marc Chagall\", \"Marcel Chagall\", \"Yanjun Cheng\", \"Sandra Chevrier\", \"Judy Chicago\", \"James C. Christensen\", \"Frederic Church\", \"Mikalojus Konstantinas Ciurlionis\", \"Pieter Claesz\", \"Amanda Clark\", \"Harry Clarke\", \"Thomas Cole\", \"Mat Collishaw\", \"John Constable\", \"Cassius Marcellus Coolidge\", \"Richard Corben\", \"Lovis Corinth\", \"Joseph Cornell\", \"Camille Corot\", \"cosmic nebulae\", \"Gustave Courbet\", \"Lucas Cranach the Elder\", \"Walter Crane\", \"Craola\", \"Gregory Crewdson\", \"Henri-Edmond Cross\", \"Robert Crumb\", \"Tivadar Csontv√°ry Kosztka\", \"Krenz Cushart\", \"Leonardo da Vinci\", \"Richard Dadd\", \"Louise Dahl-Wolfe\", \"Salvador Dal√≠\", \"Farel Dalrymple\", \"Geof Darrow\", \"Honor√© Daumier\", \"Jack Davis\", \"Marc Davis\", \"Stuart Davis\", \"Craig Davison\", \"Walter Percy Day\", \"Pierre Puvis de Chavannes\", \"Giorgio de Chirico\", \"Pieter de Hooch\", \"Elaine de Kooning\", \"Willem de Kooning\", \"Evelyn De Morgan\", \"Henri de Toulouse-Lautrec\", \"Richard Deacon\", \"Roger Dean\", \"Michael Deforge\", \"Edgar Degas\", \"Lise Deharme\", \"Eugene Delacroix\", \"Beauford Delaney\", \"Sonia Delaunay\", \"Nicolas Delort\", \"Paul Delvaux\", \"Jean Delville\", \"Martin Deschambault\", \"Brian Despain\", \"Vincent Di Fate\", \"Steve Dillon\", \"Walt Disney\", \"Tony DiTerlizzi\", \"Steve Ditko\", \"Anna Dittmann\", \"Otto Dix\", \"√ìscar Dom√≠nguez\", \"Russell Dongjun Lu\", \"Stanley Donwood\", \"Gustave Dor√©\", \"Dave Dorman\", \"Arthur Dove\", \"Richard Doyle\", \"Tim Doyle\", \"Philippe Druillet\", \"Joseph Ducreux\", \"Edmund Dulac\", \"Asher Brown Durand\", \"Albrecht D√ºrer\", \"Thomas Eakins\", \"Eyvind Earle\", \"Jeff Easley\", \"Tyler Edlin\", \"Jason Edmiston\", \"Les Edwards\", \"Bob Eggleton\", \"Jesper Ejsing\", \"El Greco\", \"Olafur Eliasson\", \"Harold Elliott\", \"Dean Ellis\", \"Larry Elmore\", \"Peter Elson\", \"Ed Emshwiller\", \"Kilian Eng\", \"James Ensor\", \"Max Ernst\", \"Elliott Erwitt\", \"M.C. Escher\", \"Richard Eurich\", \"Glen Fabry\", \"Anton Fadeev\", \"Shepard Fairey\", \"John Philip Falter\", \"Lyonel Feininger\", \"Joe Fenton\", \"Agust√≠n Fern√°ndez\", \"Roberto Ferri\", \"Hugh Ferriss\", \"David Finch\", \"Virgil Finlay\", \"Howard Finster\", \"Anton Otto Fischer\", \"Paul Gustav Fischer\", \"Paul Gustave Fischer\", \"Art Fitzpatrick\", \"Dan Flavin\", \"Kaja Foglio\", \"Phil Foglio\", \"Chris Foss\", \"Hal Foster\", \"Jean-Honor√© Fragonard\", \"Victoria Franc√©s\", \"Lisa Frank\", \"Frank Frazetta\", \"Kelly Freas\", \"Lucian Freud\", \"Caspar David Friedrich\", \"Brian Froud\", \"Wendy Froud\", \"Ernst Fuchs\", \"Goro Fujita\", \"Henry Fuseli\", \"Thomas Gainsborough\", \"Emile Galle\", \"Stephen Gammell\", \"Hope Gangloff\", \"Antoni Gaudi\", \"Antoni Gaud√≠\", \"Jack Gaughan\", \"Paul Gauguin\", \"Giovanni Battista Gaulli\", \"Nikolai Ge\", \"Emma Geary\", \"Anne Geddes\", \"Jeremy Geddes\", \"Artemisia Gentileschi\", \"Justin Gerard\", \"Jean-Leon Gerome\", \"Jean-L√©on G√©r√¥me\", \"Atey Ghailan\", \"Alberto Giacometti\", \"Donato Giancola\", \"Dave Gibbons\", \"H. R. Giger\", \"James Gilleard\", \"Jean Giraud\", \"Milton Glaser\", \"Warwick Goble\", \"Andy Goldsworthy\", \"Hendrick Goltzius\", \"Natalia Goncharova\", \"Rob Gonsalves\", \"Josan Gonzalez\", \"Edward Gorey\", \"Arshile Gorky\", \"Francisco Goya\", \"J. J. Grandville\", \"Jane Graverol\", \"Mab Graves\", \"Laurie Greasley\", \"Kate Greenaway\", \"Alex Grey\", \"Peter Gric\", \"Carne Griffiths\", \"John Atkinson Grimshaw\", \"Henriette Grindat\", \"Matt Groening\", \"William Gropper\", \"George Grosz\", \"Matthias Gr√ºnewald\", \"Rebecca Guay\", \"James Gurney\", \"Philip Guston\", \"Sir James Guthrie\", \"Zaha Hadid\", \"Ernst Haeckel\", \"Sydney Prior Hall\", \"Asaf Hanuka\", \"Tomer Hanuka\", \"David A. Hardy\", \"Keith Haring\", \"John Harris\", \"Lawren Harris\", \"Marsden Hartley\", \"Ryohei Hase\", \"Jacob Hashimoto\", \"Martin Johnson Heade\", \"Erich Heckel\", \"Michael Heizer\", \"Steve Henderson\", \"Patrick Heron\", \"Ryan Hewett\", \"Jamie Hewlett\", \"Brothers Hildebrandt\", \"Greg Hildebrandt\", \"Tim Hildebrandt\", \"Miho Hirano\", \"Adolf Hitler\", \"Hannah Hoch\", \"David Hockney\", \"Filip Hodas\", \"Howard Hodgkin\", \"Ferdinand Hodler\", \"William Hogarth\", \"Katsushika Hokusai\", \"Carl Holsoe\", \"Winslow Homer\", \"Edward Hopper\", \"Aaron Horkey\", \"Kati Horna\", \"Ralph Horsley\", \"John Howe\", \"John Hoyland\", \"Arthur Hughes\", \"Edward Robert Hughes\", \"Friedensreich Regentag Dunkelbunt Hundertwasser\", \"Hundertwasser\", \"William Henry Hunt\", \"Louis Icart\", \"Ismail Inceoglu\", \"Bjarke Ingels\", \"George Inness\", \"Shotaro Ishinomori\", \"Junji Ito\", \"Johannes Itten\", \"Ub Iwerks\", \"Alexander Jansson\", \"Jaros≈Çaw Ja≈õnikowski\", \"James Jean\", \"Ruan Jia\", \"Martine Johanna\", \"Richard S. Johnson\", \"Jeffrey Catherine Jones\", \"Peter Andrew Jones\", \"Kim Jung Gi\", \"Joe Jusko\", \"Frida Kahlo\", \"M.W. Kaluta\", \"Wassily Kandinsky\", \"Terada Katsuya\", \"Audrey Kawasaki\", \"Hasui Kawase\", \"Zhang Kechun\", \"Felix Kelly\", \"John Frederick Kensett\", \"Rockwell Kent\", \"Hendrik Kerstens\", \"Brian Kesinger\", \"Jeremiah Ketner\", \"Adonna Khare\", \"Kitty Lange Kielland\", \"Thomas Kinkade\", \"Jack Kirby\", \"Ernst Ludwig Kirchner\", \"Tatsuro Kiuchi\", \"Mati Klarwein\", \"Jon Klassen\", \"Paul Klee\", \"Yves Klein\", \"Heinrich Kley\", \"Gustav Klimt\", \"Daniel Ridgway Knight\", \"Nick Knight\", \"Daniel Ridgway Knights\", \"Ayami Kojima\", \"Oskar Kokoschka\", \"K√§the Kollwitz\", \"Satoshi Kon\", \"Jeff Koons\", \"Konstantin Korovin\", \"Leon Kossoff\", \"Hugh Kretschmer\", \"Barbara Kruger\", \"Alfred Kubin\", \"Arkhyp Kuindzhi\", \"Kengo Kuma\", \"Yasuo Kuniyoshi\", \"Yayoi Kusama\", \"Ilya Kuvshinov\", \"Chris LaBrooy\", \"Raphael Lacoste\", \"Wilfredo Lam\", \"Mikhail Larionov\", \"Abigail Larson\", \"Jeffrey T. Larson\", \"Carl Larsson\", \"Dorothy Lathrop\", \"John Lavery\", \"Edward Lear\", \"Andr√© Leblanc\", \"Bastien Lecouffe-Deharme\", \"Alan Lee\", \"Jim Lee\", \"Heinrich Lefler\", \"Paul Lehr\", \"Edmund Leighton\", \"Frederick Lord Leighton\", \"Jeff Lemire\", \"Isaac Levitan\", \"J.C. Leyendecker\", \"Roy Lichtenstein\", \"Rob Liefeld\", \"Malcolm Liepke\", \"Jeremy Lipking\", \"Filippino Lippi\", \"Laurie Lipton\", \"Michal Lisowski\", \"Scott Listfield\", \"Cory Loftis\", \"Travis Louie\", \"George Luks\", \"Dora Maar\", \"August Macke\", \"Margaret Macdonald Mackintosh\", \"Clive Madgwick\", \"Lee Madgwick\", \"Rene Magritte\", \"Don Maitz\", \"Kazimir Malevich\", \"√âdouard Manet\", \"Jeremy Mann\", \"Sally Mann\", \"Franz Marc\", \"Chris Mars\", \"Otto Marseus van Schrieck\", \"John Martin\", \"Masaaki Masamoto\", \"Andr√© Masson\", \"Henri Matisse\", \"Leiji Matsumoto\", \"Taiy≈ç Matsumoto\", \"Roberto Matta\", \"Rodney Matthews\", \"David B. Mattingly\", \"Peter Max\", \"Marco Mazzoni\", \"Robert McCall\", \"Todd McFarlane\", \"Ryan McGinley\", \"Dave McKean\", \"Kelly McKernan\", \"Angus McKie\", \"Ralph McQuarrie\", \"Ian McQue\", \"Syd Mead\", \"J√≥zef Mehoffer\", \"Eddie Mendoza\", \"Adolph Menzel\", \"Maria Sibylla Merian\", \"Daniel Merriam\", \"Jean Metzinger\", \"Michelangelo\", \"Mike Mignola\", \"Frank Miller\", \"Ian Miller\", \"Russ Mills\", \"Victor Adame Minguez\", \"Joan Miro\", \"Kentaro Miura\", \"Paula Modersohn-Becker\", \"Amedeo Modigliani\", \"Moebius\", \"Peter Mohrbacher\", \"Piet Mondrian\", \"Claude Monet\", \"Jean-Baptiste Monge\", \"Kent Monkman\", \"Alyssa Monks\", \"Sailor Moon\", \"Chris Moore\", \"Gustave Moreau\", \"William Morris\", \"Igor Morski\", \"John Kenn Mortensen\", \"Victor Moscoso\", \"Grandma Moses\", \"Robert Motherwell\", \"Alphonse Mucha\", \"Craig Mullins\", \"Augustus Edwin Mulready\", \"Dan Mumford\", \"Edvard Munch\", \"Gabriele M√ºnter\", \"Gerhard Munthe\", \"Takashi Murakami\", \"Patrice Murciano\", \"Go Nagai\", \"Hiroshi Nagai\", \"Tibor Nagy\", \"Ted Nasmith\", \"Alice Neel\", \"Odd Nerdrum\", \"Mikhail Nesterov\", \"C. R. W. Nevinson\", \"Helmut Newton\", \"Victo Ngai\", \n",
        "           \"Dustin Nguyen\", \"Kay Nielsen\", \"Tsutomu Nihei\", \"Yasushi Nirasawa\", \"Sidney Nolan\", \"Emil Nolde\", \"Sven Nordqvist\", \"Earl Norem\", \"Marianne North\", \"Georgia O'Keeffe\", \"Terry Oakes\", \"Takeshi Obata\", \"Eiichiro Oda\", \"Koson Ohara\", \"Noriyoshi Ohrai\", \"Marek Okon\", \"M√©ret Oppenheim\", \"Katsuhiro Otomo\", \"Shohei Otomo\", \"Siya Oum\", \"Ida Rentoul Outhwaite\", \"James Paick\", \"David Palumbo\", \"Michael Parkes\", \"Keith Parkinson\", \"Maxfield Parrish\", \"Alfred Parsons\", \"Max Pechstein\", \"Agnes Lawrence Pelton\", \"Bruce Pennington\", \"John Perceval\", \"Gaetano Pesce\", \"Coles Phillips\", \"Francis Picabia\", \"Pablo Picasso\", \"Mauro Picenardi\", \"Anton Pieck\", \"Bonnard Pierre\", \"Yuri Ivanovich Pimenov\", \"Robert Antoine Pinchon\", \"Giovanni Battista Piranesi\", \"Camille Pissarro\", \"Patricia Polacco\", \"Jackson Pollock\", \"Lyubov Popova\", \"Candido Portinari\", \"Beatrix Potter\", \"Beatrix Potter\", \"Gediminas Pranckevicius\", \"Dod Procter\", \"Howard Pyle\", \"Arthur Rackham\", \"Alice Rahon\", \"Paul Ranson\", \"Raphael\", \"Robert Rauschenberg\", \"Man Ray\", \"Odilon Redon\", \"Pierre-Auguste Renoir\", \"Ilya Repin\", \"RHADS\", \"Gerhard Richter\", \"Diego Rivera\", \"Hubert Robert\", \"Andrew Robinson\", \"Charles Robinson\", \"W. Heath Robinson\", \"Andreas Rocha\", \"Norman Rockwell\", \"Nicholas Roerich\", \"Conrad Roset\", \"Bob Ross\", \"Jessica Rossier\", \"Ed Roth\", \"Mark Rothko\", \"Georges Rouault\", \"Henri Rousseau\", \"Luis Royo\", \"Jakub Rozalski\", \"Joao Ruas\", \"Peter Paul Rubens\", \"Mark Ryden\", \"Jan Pietersz Saenredam\", \"Pieter Jansz Saenredam\", \"Kay Sage\", \"Apollonia Saintclair\", \"John Singer Sargent\", \"Martiros Saryan\", \"Masaaki Sasamoto\", \"Thomas W Schaller\", \"Miriam Schapiro\", \"Yohann Schepacz\", \"Egon Schiele\", \"Karl Schmidt-Rottluff\", \"Charles Schulz\", \"Charles Schulz\", \"Carlos Schwabe\", \"Sean Scully\", \"Franz Sedlacek\", \"Maurice Sendak\", \"Zinaida Serebriakova\", \"Georges Seurat\", \"Ben Shahn\", \"Barclay Shaw\", \"E. H. Shepard\", \"Cindy Sherman\", \"Makoto Shinkai\", \"Yoji Shinkawa\", \"Chiharu Shiota\", \"Masamune Shirow\", \"Ivan Shishkin\", \"Bill Sienkiewicz\", \"Greg Simkins\", \"Marc Simonetti\", \"Kevin Sloan\", \"Adrian Smith\", \"Douglas Smith\", \"Jeffrey Smith\", \"Pamela Coleman Smith\", \"Zack Snyder\", \"Simeon Solomon\", \"Joaqu√≠n Sorolla\", \"Ettore Sottsass\", \"Cha√Øm Soutine\", \"Austin Osman Spare\", \"Sparth \", \"Art Spiegelman\", \"Simon Stalenhag\", \"Ralph Steadman\", \"William Steig\", \"Joseph Stella\", \"Irma Stern\", \"Anne Stokes\", \"James Stokoe\", \"William Stout\", \"George Stubbs\", \"Tatiana Suarez\", \"Ken Sugimori\", \"Hiroshi Sugimoto\", \"Brian Sum\", \"Matti Suuronen\", \"Raymond Swanland\", \"Naoko Takeuchi\", \"Rufino Tamayo\", \"Shaun Tan\", \"Yves Tanguay\", \"Henry Ossawa Tanner\", \"Dorothea Tanning\", \"Ben Templesmith\", \"theCHAMBA\", \"Tom Thomson\", \"Storm Thorgerson\", \"Bridget Bate Tichenor\", \"Louis Comfort Tiffany\", \"Tintoretto\", \"James Tissot\", \"Titian\", \"Akira Toriyama\", \"Ross Tran\", \"Clovis Trouille\", \"J.M.W. Turner\", \"James Turrell\", \"Daniela Uhlig\", \"Boris Vallejo\", \"Gustave Van de Woestijne\", \"Frits Van den Berghe\", \"Anthony van Dyck\", \"Jan van Eyck\", \"Vincent Van Gogh\", \"Willem van Haecht\", \"Rembrandt van Rijn\", \"Jacob van Ruisdael\", \"Salomon van Ruysdael\", \"Theo van Rysselberghe\", \"Remedios Varo\", \"Viktor Vasnetsov\", \"Kuno Veeber\", \"Diego Vel√°zquez\", \"Giovanni Battista Venanzi\", \"Johannes Vermeer\", \"Alexej von Jawlensky\", \"Marianne von Werefkin\", \"Hendrick Cornelisz Vroom\", \"Mikhail Vrubel\", \"Louis Wain\", \"Ron Walotsky\", \"Andy Warhol\", \"John William Waterhouse\", \"Jean-Antoine Watteau\", \"George Frederic Watts\", \"Max Weber\", \"Gerda Wegener\", \"Edward Weston\", \"Michael Whelan\", \"James Abbott McNeill Whistler\", \"Tim White\", \"Coby Whitmore\", \"John Wilhelm\", \"Robert Williams\", \"Al Williamson\", \"Carel Willink\", \"Mike Winkelmann\", \"Franz Xaver Winterhalter\", \"Klaus Wittmann\", \"Liam Wong\", \"Paul Wonner\", \"Ashley Wood\", \"Grant Wood\", \"Patrick Woodroffe\", \"Frank Lloyd Wright\", \"Bernie Wrightson\", \"Andrew Wyeth\", \"Qian Xuan\", \"Takato Yamamoto\", \"Liu Ye\", \"Jacek Yerka\", \"Akihiko Yoshida\", \"Hiroshi Yoshida\", \"Skottie Young\", \"Konstantin Yuon\", \"Yuumei\", \"Amir Zand\", \"Fenghua Zhong\", \"Nele Zirnite\", \"Anders Zorn\") \n",
        "styles = ( \"1970s era\", \"2001: A Space Odyssey\", \"60s kitsch and psychedelia\", \"Aaahh!!! Real Monsters\", \"abstract illusionism\", \"afrofuturism\", \"alabaster\", \"alhambresque\", \"ambrotype\", \"american romanticism\", \"amethyst\", \"amigurumi\", \"anaglyph effect\", \"anaglyph filter\", \"Ancient Egyptian\", \"ancient Greek architecture\", \"anime\", \"art nouveau\", \"astrophotography\", \"at dawn\", \"at dusk\", \"at high noon\", \"at night\", \"atompunk\", \"aureolin\", \"avant-garde\", \"Avatar The Last Airbender\", \"Babylonian\", \"Baker-Miller pink\", \"Baroque\", \"Bauhaus\", \"biopunk\", \"bismuth\", \"Blade Runner 2049\", \"blueprint\", \"bokeh\", \"bonsai\", \"bright\", \"bronze\", \"brutalism\", \"burgundy\", \"Byzantine\", \"calotype\", \"Cambrian\", \"camcorder effect\", \"carmine\", \"cassette futurism\", \"cassettepunk\", \"catholicpunk\", \"cerulean\", \"chalk art\", \"chartreuse\", \"chiaroscuro\", \"chillwave\", \"chromatic aberration\", \"chrome\", \"Cirque du Soleil\", \"claymation\", \"clockpunk\", \"cloudpunk\", \"cobalt\", \"colored pencil art\", \"Concept Art World\", \"copper patina\", \"copper verdigris\", \"Coraline\", \"cosmic horror\", \"cottagecore\", \"crayon art\", \"crimson\", \"CryEngine\", \"crystalline lattice\", \"cubic zirconia\", \"cubism\", \"cyanotype\", \"cyber noir\", \"cyberpunk\", \"cyclopean masonry\", \"daguerreotype\", \"Danny Phantom\", \"dark academia\", \"dark pastel\", \"dark rainbow\", \"DayGlo\", \"decopunk\", \"Dexter's Lab\", \"diamond\", \"dieselpunk\", \"Digimon\", \"digital art\", \"doge\", \"dollpunk\", \"Doom engine\", \"Dreamworks\", \"dutch golden age\", \"Egyptian\", \"eldritch\", \"emerald\", \"empyrean\", \"Eraserhead\", \"ethereal\", \"expressionism\", \"Fantastic Planet\", \"Fendi\", \"figurativism\", \"fire\", \"fisheye lens\", \"fluorescent\", \"forestpunk\", \"fractal manifold\", \"fractalism\", \"fresco\", \"fuchsia\", \"futuresynth\", \"Game of Thrones\", \"german romanticism\", \"glitch art\", \"glittering\", \"golden\", \"golden hour\", \"gothic\", \"gothic art\", \"graffiti\", \"graphite\", \"grim dark\", \"Harry Potter\", \"holography\", \"Howl‚Äôs Moving Castle\", \"hygge\", \"hyperrealism\", \"icy\", \"ikebana\", \"impressionism\", \"in Ancient Egypt\", \"in Egypt\", \"in Italy\", \"in Japan\", \"in the Central African Republic\", \"in the desert\", \"in the jungle\", \"in the swamp\", \"in the tundra\", \"incandescent\", \"indigo\", \"infrared\", \"Interstellar\", \"inverted colors\", \"iridescent\", \"iron\", \"islandpunk\", \"isotype\", \"Kai Fine Art\", \"khaki\", \"kokedama\", \"Korean folk art\", \"lapis lazuli\", \"Lawrence of Arabia\", \"leather\", \"leopard print\", \"lilac\", \"liminal space\", \"long exposure\", \"Lord of the Rings\", \"Louis Vuitton\", \"Lovecraftian\", \"low poly\", \"mac and cheese\", \"macro lens\", \"magenta\", \"magic realism\", \"manga\", \"mariachi\", \"marimekko\", \"maroon\", \"Medieval\", \"Mediterranean\", \"modernism\", \"Monster Rancher\", \"moonstone\", \"Moulin Rouge!\", \"multiple exposure\", \"Myst\", \"nacreous\", \"narrative realism\", \"naturalism\", \"neon\", \"Nosferatu\", \"obsidian\", \"oil and canvas\", \"opalescent\", \"optical illusion\", \"optical art\", \"organometallics\", \"ossuary\", \"outrun\", \"Paleolithic\", \"Pan's Labyrinth\", \"pastel\", \"patina\", \"pearlescent\", \"pewter\", \"Pixar\", \"Play-Doh\", \"pointillism\", \"Pokemon\", \"polaroid\", \"porcelain\", \"positivism\", \"postcyberpunk\", \"Pride & Prejudice\", \"prismatic\", \"pyroclastic flow\", \"Quake engine\", \"quartz\", \"rainbow\", \"reflective\", \"Renaissance\", \"retrowave\", \"Rococo\", \"rococopunk\", \"ruby\", \"rusty\", \"Salad Fingers\", \"sapphire\", \"scarlet\", \"shimmering\", \"silk\", \"sketched\", \"Slenderman\", \"smoke\", \"snakeskin\", \"Spaceghost Coast to Coast\", \"stained glass\", \"Star Wars\", \"steampunk\", \"steel\", \"steelpunk\", \"still life\", \"stonepunk\", \"Stranger Things\", \"street art\", \"stuckism\", \"Studio Ghibli\", \"Sumerian\", \"surrealism\", \"symbolism\", \"synthwave\", \"telephoto lens\", \"thalassophobia\", \"thangka\", \"the matrix\", \"tiger print\", \"tilt-shift\", \"tintype\", \"tonalism\", \"Toonami\", \"turquoise\", \"Ukiyo-e\", \"ultramarine\", \"ultraviolet\", \"umber\", \"underwater photography\", \"Unreal Engine\", \"vantablack\", \"vaporwave\", \"verdigris\", \"Versacci\", \"viridian\", \"wabi-sabi\", \"watercolor painting\", \"wooden\", \"x-ray photography\", \"minimalist\", \"dadaist\", \"neo-expressionist\", \"post-impressionist\", \"hyper real\", \"Art brut\", \"3D rendering\", \"uncanny valley\", \"fractal landscape\", \"fractal flames\", \"Mandelbulb\", \"inception dream\", \"waking life\", \"occult inscriptions\", \"barr relief\", \"marble sculpture\", \"wood carving\", \"church stained glass\", \"Japanese jade\", \"Zoetrope\", \"beautiful\", \"wide-angle\", \"Digital Painting\", \"glossy reflections\", \"cinematic\", \"spooky\", \"Digital paint concept art\", \"dramatic\", \"global illumination\", \"immaculate\", \"woods\", ) \n",
        "\n",
        "#Code a function in Python programming language named list_variations, which takes a list and returns a set of lists with possible permutations of the list. Example list_variations([1,2,3]) returns [[1,2,3],[1,2],[1,3],[2,3],[1],[2],[3]] */\n",
        "def list_variations(lst):\n",
        "    result = []\n",
        "    for i in range(len(lst)):\n",
        "        for j in range(i+1, len(lst)+1):\n",
        "            result.append(lst[i:j])\n",
        "    return result\n",
        "#print(str(list_variations([1,2,3])))\n",
        "def and_list(lst):\n",
        "  return \" and \".join([\", \".join(lst[:-1]),lst[-1]] if len(lst) > 2 else lst)\n",
        "\n",
        "generator_request_modes = [\"visually detailed\",\n",
        "  \"with long detailed colorful interesting artistic scenic visual descriptions\",\n",
        "  \"that is highly detailed, artistically interesting, describes a scene, colorful poetic language, with intricate visual descriptions\",\n",
        "  \"that are strange, descriptive, graphically visual, full of interesting subjects described in great detail, painted by an artist\",\n",
        "  \"that is technical, wordy, extra detailed, confusingly tangental, colorfully worded, dramatically narrative\",\n",
        "  \"that is creative, imaginative, funny, interesting, scenic, dark, witty, visual, unexpected, wild\",\n",
        "  \"that includes many subjects with descriptions, color details, artistic expression, point of view\",\n",
        "  \"complete sentence using many words to describe a landscape in an epic fantasy genre that includes a lot adjectives\",]\n",
        "\n",
        "def run_prompt_generator(page):\n",
        "  import random as rnd\n",
        "  global artists, styles\n",
        "  try:\n",
        "    import openai\n",
        "    openai.api_key = prefs['OpenAI_api_key']\n",
        "  except:\n",
        "    pass\n",
        "  prompts_gen = []\n",
        "  prompt_results = []\n",
        "  subject = \"\"\n",
        "  if bool(prefs['prompt_generator']['subject_detail']):\n",
        "      subject = \", and \" + prefs['prompt_generator']['subject_detail']\n",
        "\n",
        "  def prompt_gen():\n",
        "    prompt = f'''Write a list of {prefs['prompt_generator']['amount'] if prefs['prompt_generator']['phrase_as_subject'] else (prefs['prompt_generator']['amount'] + 4)} image generation prompts about \"{prefs['prompt_generator']['phrase']}\"{subject}, {generator_request_modes[int(prefs['prompt_generator']['request_mode'])]}, and unique without repetition:\n",
        "\n",
        "'''\n",
        "    #print(prompt)\n",
        "    if prefs['prompt_generator']['phrase_as_subject']:\n",
        "      prompt += \"\\n*\"\n",
        "    else:\n",
        "      prompt += f\"\"\"* A beautiful painting of a serene landscape with a river running through it, lush trees, golden sun illuminating\n",
        "* Fireflies illuminating autumnal woods, an Autumn in the Brightwood glade, with warm yellow lantern lights\n",
        "* The Fabric of spacetime continuum over a large cosmological vista, pieces of dark matter, space dust and nebula doted with small dots that seem to form fractal patterns and glowing bright lanterns in distances, also with an stardust effect towards the plane of the galaxy\n",
        "* Midnight landscape painting of a city under a starry sky, owl in the shaman forest knowing the ways of magic, warm glow over the buildings\n",
        "* {prefs['prompt_generator']['phrase']}\"\"\"\n",
        "    response = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=2400, temperature=prefs['prompt_generator']['AI_temperature'], presence_penalty=1)\n",
        "    #print(response)\n",
        "    result = response[\"choices\"][0][\"text\"].strip()\n",
        "    #if result[-1] == '.': result = result[:-1]\n",
        "    #print(str(result))\n",
        "    for p in result.split('\\n'):\n",
        "      pr = p.strip()\n",
        "      if not bool(pr): continue\n",
        "      if pr[-1] == '.': pr = pr[:-1]\n",
        "      if pr[0] == '*': pr = pr[2:]\n",
        "      elif '.' in pr: # Sometimes got 1. 2.\n",
        "        pr = pr.partition('.')[2].strip()\n",
        "      if '\"' in pr: pr = pr.replace('\"', '')\n",
        "      prompt_results.append(pr)\n",
        "  #print(f\"Request mode influence: {request_modes[prefs['prompt_generator']['request_mode']]}\\n\")\n",
        "  page.prompt_generator_list.controls.append(Row([ProgressRing(), Text(\"Requesting Prompts from the AI...\", weight=FontWeight.BOLD)]))\n",
        "  page.prompt_generator_list.update()\n",
        "  prompt_gen()\n",
        "  del page.prompt_generator_list.controls[-1]\n",
        "  page.prompt_generator_list.update()\n",
        "  if len(prompt_results) < prefs['prompt_generator']['amount']:\n",
        "    additional = prefs['prompt_generator']['amount'] - len(prompt_results)\n",
        "    print(f\"Didn't make enough prompts.. Needed {additional} more.\")\n",
        "  n=1\n",
        "  for p in prompt_results:\n",
        "    random_artist=[]\n",
        "    for a in range(prefs['prompt_generator']['random_artists']):\n",
        "      random_artist.append(rnd.choice(artists))\n",
        "    #print(list_variations(random_artist))\n",
        "    artist = \" and \".join([\", \".join(random_artist[:-1]),random_artist[-1]] if len(random_artist) > 2 else random_artist)\n",
        "    random_style = []\n",
        "    for s in range(prefs['prompt_generator']['random_styles']):\n",
        "      random_style.append(rnd.choice(styles))\n",
        "    style = \", \".join(random_style)\n",
        "    if not prefs['prompt_generator']['phrase_as_subject'] and n == 1:\n",
        "      p = prefs['prompt_generator']['phrase'] + \" \" + p\n",
        "    text_prompt = p\n",
        "    if prefs['prompt_generator']['random_artists'] > 0: text_prompt += f\", by {artist}\"\n",
        "    if prefs['prompt_generator']['random_styles'] > 0: text_prompt += f\", style of {style}\"\n",
        "    if prefs['prompt_generator']['random_styles'] != 0 and prefs['prompt_generator']['permutate_artists']:\n",
        "      prompts_gen.append(text_prompt)\n",
        "    if prefs['prompt_generator']['permutate_artists']:\n",
        "      for a in list_variations(random_artist):\n",
        "        prompt_variation = p + f\", by {and_list(a)}\"\n",
        "        prompts_gen.append(prompt_variation)\n",
        "      if prefs['prompt_generator']['random_styles'] > 0:\n",
        "        prompts_gen.append(p + f\", style of {style}\")\n",
        "    else: prompts_gen.append(text_prompt)\n",
        "    n += 1\n",
        "  for item in prompts_gen:\n",
        "    page.add_to_prompt_generator(item)\n",
        "    #print(f'   \"{item}\",')\n",
        "\n",
        "remixer_request_modes = [\n",
        "      \"visually detailed wording, flowing sentences, extra long descriptions\",\n",
        "      \"that is similar but with more details, themes, imagination, interest, subjects, artistic style, poetry, tone, settings, adjectives, visualizations\",\n",
        "      \"that is completely rewritten, inspired by, paints a complete picture of an artistic seen\",\n",
        "      \"with detailed colorful interesting artistic scenic visual descriptions, described to a blind person\",\n",
        "      \"that is highly detailed, artistically interesting, describes a scene, colorful poetic language, with intricate visual descriptions\",\n",
        "      \"that replaces every noun, adjective, verb, pronoun, with related words\",\n",
        "      \"that is strange, descriptive, graphically visual, full of interesting subjects described in great detail, painted by an artist\",\n",
        "      \"that is highly technical, extremely wordy, extra detailed, confusingly tangental, colorfully worded, dramatically narrative\",\n",
        "      \"that is creative, imaginative, funny, interesting, scenic, dark, witty, visual, unexpected, wild\",\n",
        "      \"that includes more subjects with descriptions, textured color details, expressive\",]\n",
        "      #\"complete sentence using many words to describe a landscape in an epic fantasy genre that includes a lot adjectives\",\n",
        "\n",
        "def run_prompt_remixer(page):\n",
        "  import random as rnd\n",
        "  global artists, styles\n",
        "  try:\n",
        "    import openai\n",
        "    openai.api_key = prefs['OpenAI_api_key']\n",
        "  except:\n",
        "    pass\n",
        "  prompts_remix = []\n",
        "  prompt_results = []\n",
        "  \n",
        "  if '_' in prefs['prompt_remixer']['seed_prompt']:\n",
        "    seed_prompt = nsp_parse(prefs['prompt_remixer']['seed_prompt'])\n",
        "  else:\n",
        "    seed_prompt = prefs['prompt_remixer']['seed_prompt']\n",
        "  if '_' in prefs['prompt_remixer']['optional_about_influencer']:\n",
        "    optional_about_influencer = nsp_parse(prefs['prompt_remixer']['optional_about_influencer'])\n",
        "  else:\n",
        "    optional_about_influencer = prefs['prompt_remixer']['optional_about_influencer']\n",
        "  about =  f\" about {optional_about_influencer}\" if bool(optional_about_influencer) else \"\"\n",
        "  prompt = f'Write a list of {prefs[\"prompt_remixer\"][\"amount\"]} remixed variations from the following image generation prompt{about}, \"{prefs[\"prompt_remixer\"][\"seed_prompt\"]}\", {remixer_request_modes[int(prefs[\"prompt_remixer\"][\"request_mode\"])]}, and unique without repetition:\\n\\n*'\n",
        "  prompt_results = []\n",
        "  \n",
        "  def prompt_remix():\n",
        "    response = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=2400, temperature=prefs[\"prompt_remixer\"]['AI_temperature'], presence_penalty=1)\n",
        "    #print(response)\n",
        "    result = response[\"choices\"][0][\"text\"].strip()\n",
        "    #if result[-1] == '.': result = result[:-1]\n",
        "    #print(str(result))\n",
        "    for p in result.split('\\n'):\n",
        "      pr = p.strip()\n",
        "      if not bool(pr): continue\n",
        "      if pr[-1] == '.': pr = pr[:-1]\n",
        "      if pr[0] == '*': pr = pr[2:]\n",
        "      elif '.' in pr: # Sometimes got 1. 2.\n",
        "        pr = pr.partition('.')[2].strip()\n",
        "      prompt_results.append(pr)\n",
        "  page.prompt_remixer_list.controls.append(Text(f\"Remixing {seed_prompt}\" + (f\", about {optional_about_influencer}\" if bool(optional_about_influencer) else \"\") + f\"\\nRequest mode influence: {remixer_request_modes[int(prefs['prompt_remixer']['request_mode'])]}\\n\"))\n",
        "  page.prompt_remixer_list.update()\n",
        "  #page.add_to_prompt_remixer(f\"Remixing {seed_prompt}\" + (f\", about {optional_about_influencer}\" if bool(optional_about_influencer) else \"\") + f\"\\nRequest mode influence: {remixer_request_modes[int(prefs['prompt_remixer']['request_mode'])]}\\n\")\n",
        "  #print(f\"Remixing {seed_prompt}\" + (f\", about {optional_about_influencer}\" if bool(optional_about_influencer) else \"\"))\n",
        "  #print(f\"Request mode influence: {remixer_request_modes[int(prefs['prompt_remixer']['request_mode'])]}\\n\")\n",
        "  page.prompt_remixer_list.controls.append(Row([ProgressRing(), Text(\"Requesting Prompt Remixes...\", weight=FontWeight.BOLD)]))\n",
        "  page.prompt_remixer_list.update()\n",
        "  prompt_remix()\n",
        "  del page.prompt_remixer_list.controls[-1]\n",
        "  page.prompt_remixer_list.update()\n",
        "\n",
        "  for p in prompt_results:\n",
        "    random_artist=[]\n",
        "    for a in range(prefs['prompt_remixer']['random_artists']):\n",
        "      random_artist.append(rnd.choice(artists))\n",
        "    #print(list_variations(random_artist))\n",
        "    artist = \" and \".join([\", \".join(random_artist[:-1]),random_artist[-1]] if len(random_artist) > 2 else random_artist)\n",
        "    random_style = []\n",
        "    for s in range(prefs['prompt_remixer']['random_styles']):\n",
        "      random_style.append(rnd.choice(styles))\n",
        "    style = \", \".join(random_style)\n",
        "    text_prompt = p\n",
        "    if prefs['prompt_remixer']['random_artists'] > 0: text_prompt += f\", by {artist}\"\n",
        "    if prefs['prompt_remixer']['random_styles'] > 0: text_prompt += f\", style of {style}\"\n",
        "    if prefs['prompt_remixer']['random_styles'] == 0 and prefs['prompt_remixer']['permutate_artists']:\n",
        "      prompts_remix.append(text_prompt)\n",
        "    if prefs['prompt_remixer']['permutate_artists']:\n",
        "      for a in list_variations(random_artist):\n",
        "        prompt_variation = p + f\", by {and_list(a)}\"\n",
        "        prompts_remix.append(prompt_variation)\n",
        "      if prefs['prompt_remixer']['random_styles'] > 0:\n",
        "        prompts_remix.append(p + f\", style of {style}\")\n",
        "    else: prompts_remix.append(text_prompt)\n",
        "  for item in prompts_remix:\n",
        "    page.add_to_prompt_remixer(item)\n",
        "\n",
        "brainstorm_request_modes = {\n",
        "    \"Brainstorm\":\"Brainstorm visual ideas for an image prompt about \",\n",
        "    \"Write\":\"Write an interesting visual scene about \",\n",
        "    \"Rewrite\":\"Rewrite new variations of \",\n",
        "    \"Edit\":\"Edit this text to improve details and structure: \",\n",
        "    \"Story\":\"Write an interesting story with visual details and poetic subjects about \",\n",
        "    \"Description\":\"Describe in graphic detail \",\n",
        "    \"Picture\":\"Paint a picture with words about \",\n",
        "    \"Raw Request\":\"\",\n",
        "}\n",
        "\n",
        "def run_prompt_brainstormer(page):\n",
        "    import random as rnd\n",
        "    global artists, styles, brainstorm_request_modes\n",
        "    textsynth_engine = \"gptj_6B\" #param [\"gptj_6B\", \"boris_6B\", \"fairseq_gpt_13B\", \"gptneox_20B\", \"m2m100_1_2B\"]\n",
        "    #markdown HuggingFace Bloom AI Settings\n",
        "    max_tokens_length = 128 #param {type:'slider', min:1, max:64, step:1}\n",
        "    seed = int(2222 * prefs['prompt_brainstormer']['AI_temperature']) #param {type:'integer'}\n",
        "    API_URL = \"https://api-inference.huggingface.co/models/bigscience/bloom\"\n",
        "\n",
        "    good_key = True\n",
        "    if prefs['prompt_brainstormer']['AI_engine'] == \"TextSynth GPT-J\":\n",
        "      try: \n",
        "        if not bool(prefs['TextSynth_api_key']): good_key = False\n",
        "      except NameError: good_key = False\n",
        "      if not good_key:\n",
        "        print(f\"\\33[91mMissing TextSynth_api_key...\\33[0m Define your key up above.\")\n",
        "      else:\n",
        "        try:\n",
        "          from textsynthpy import TextSynth, Complete\n",
        "        except ImportError:\n",
        "          run_sp(\"pip install textsynthpy\")\n",
        "          clear_output()\n",
        "        finally:\n",
        "          from textsynthpy import TextSynth, Complete\n",
        "        textsynth = TextSynth(prefs['TextSynth_api_key'], engine=textsynth_engine) # Insert your API key in the previous cell\n",
        "    if prefs['prompt_brainstormer']['AI_engine'] == \"OpenAI GPT-3\":\n",
        "      try:\n",
        "        if not bool(prefs['OpenAI_api_key']): good_key = False\n",
        "      except NameError: good_key = False\n",
        "      if not good_key:\n",
        "        print(f\"\\33[91mMissing OpenAI_api_key...\\33[0m Define your key up above.\")\n",
        "      else:\n",
        "        try:\n",
        "          import openai\n",
        "        except ImportError:\n",
        "          run_sp(\"pip install openai -qq\")\n",
        "          #clear_output()\n",
        "        finally:\n",
        "          import openai\n",
        "        openai.api_key = prefs['OpenAI_api_key']\n",
        "    if prefs['prompt_brainstormer']['AI_engine'] == \"HuggingFace Bloom 176B\" or prefs['prompt_brainstormer']['AI_engine'] == \"HuggingFace Flan-T5 XXL\":\n",
        "      try:\n",
        "        if not bool(prefs['HuggingFace_api_key']): good_key = False\n",
        "      except NameError: good_key = False\n",
        "      if not good_key:\n",
        "        print(f\"\\33[91mMissing HuggingFace_api_key...\\33[0m Define your key up above.\")\n",
        "    #ask_OpenAI_instead = False #@param {type:'boolean'}\n",
        "\n",
        "    prompt_request_modes = [\n",
        "        \"visually detailed wording, flowing sentences, extra long descriptions\",\n",
        "        \"that is similar but with more details, themes, imagination, interest, subjects, artistic style, poetry, tone, settings, adjectives, visualizations\",\n",
        "        \"that is completely rewritten, inspired by, paints a complete picture of an artistic seen\",\n",
        "        \"with detailed colorful interesting artistic scenic visual descriptions, described to a blind person\",\n",
        "        \"that is highly detailed, artistically interesting, describes a scene, colorful poetic language, with intricate visual descriptions\",\n",
        "        \"that replaces every noun, adjective, verb, pronoun, with related words\",\n",
        "        \"that is strange, descriptive, graphically visual, full of interesting subjects described in great detail, painted by an artist\",\n",
        "        \"that is highly technical, extremely wordy, extra detailed, confusingly tangental, colorfully worded, dramatically narrative\",\n",
        "        \"that is creative, imaginative, funny, interesting, scenic, dark, witty, visual, unexpected, wild\",\n",
        "        \"that includes more subjects with descriptions, textured color details, expressive\",]\n",
        "        #\"complete sentence using many words to describe a landscape in an epic fantasy genre that includes a lot adjectives\",\n",
        "    \n",
        "    request = f'{brainstorm_request_modes[prefs[\"prompt_brainstormer\"][\"request_mode\"]]}\"{prefs[\"prompt_brainstormer\"][\"about_prompt\"]}\":' if prefs['prompt_brainstormer']['request_mode'] != \"Raw Request\" else prefs['prompt_brainstormer']['about_prompt']\n",
        "\n",
        "    def query(payload):\n",
        "        #print(payload)\n",
        "        response = requests.request(\"POST\", API_URL, json=payload, headers={\"Authorization\": f\"Bearer {prefs['HuggingFace_api_key']}\"})\n",
        "        #print(response.text)\n",
        "        return json.loads(response.content.decode(\"utf-8\"))\n",
        "\n",
        "    def bloom_request(input_sentence):\n",
        "        parameters = {\n",
        "            \"max_new_tokens\": max_tokens_length,\n",
        "            \"do_sample\": False,\n",
        "            \"seed\": seed,\n",
        "            \"early_stopping\": False,\n",
        "            \"length_penalty\": 0.0,\n",
        "            \"eos_token_id\": None,}\n",
        "        payload = {\"inputs\": input_sentence, \"parameters\": parameters,\"options\" : {\"use_cache\": False} }\n",
        "        data = query(payload)\n",
        "        if \"error\" in data:\n",
        "            return f\"\\33[31mERROR: {data['error']}\\33[0m\"\n",
        "\n",
        "        generation = data[0][\"generated_text\"].split(input_sentence, 1)[1]\n",
        "        #return data[0][\"generated_text\"]\n",
        "        return generation\n",
        "    \n",
        "    def flan_query(payload):\n",
        "        #print(payload)\n",
        "        response = requests.request(\"POST\", \"https://api-inference.huggingface.co/models/google/flan-t5-xxl\", json=payload, headers={\"Authorization\": f\"Bearer {prefs['HuggingFace_api_key']}\"})\n",
        "        #print(response.text)\n",
        "        return json.loads(response.content.decode(\"utf-8\"))\n",
        "\n",
        "    def flan_request(input_sentence):\n",
        "        parameters = {\n",
        "            \"max_new_tokens\": max_tokens_length,\n",
        "            \"do_sample\": False,\n",
        "            \"seed\": seed,\n",
        "            \"early_stopping\": False,\n",
        "            \"length_penalty\": 0.0,\n",
        "            \"eos_token_id\": None,}\n",
        "        payload = {\"inputs\": input_sentence, \"parameters\": parameters,\"options\" : {\"use_cache\": False} }\n",
        "        data = flan_query(payload)\n",
        "        if \"error\" in data:\n",
        "            return f\"\\33[31mERROR: {data['error']}\\33[0m\"\n",
        "\n",
        "        generation = data[0][\"generated_text\"].split(input_sentence, 1)[1]\n",
        "        #return data[0][\"generated_text\"]\n",
        "        return generation\n",
        "\n",
        "    def prompt_brainstormer():\n",
        "      #(prompt=prompt, temperature=AI_temperature, presence_penalty=1, stop= \"\\n\")\n",
        "      page.prompt_brainstormer_list.controls.append(Row([ProgressRing(), Text(\"Storming the AI's Brain...\", weight=FontWeight.BOLD)]))\n",
        "      page.prompt_brainstormer_list.update()\n",
        "\n",
        "      if prefs['prompt_brainstormer']['AI_engine'] == \"TextSynth GPT-J\":\n",
        "        response = textsynth.text_complete(prompt=request, max_tokens=200, temperature=prefs['prompt_brainstormer']['AI_temperature'], presence_penalty=1)\n",
        "        #print(str(response))\n",
        "        result = response.text.strip()\n",
        "      elif prefs['prompt_brainstormer']['AI_engine'] == \"OpenAI GPT-3\":\n",
        "        response = openai.Completion.create(engine=\"text-davinci-003\", prompt=request, max_tokens=2400, temperature=prefs['prompt_brainstormer']['AI_temperature'], presence_penalty=1)\n",
        "        result = response[\"choices\"][0][\"text\"].strip()\n",
        "      elif prefs['prompt_brainstormer']['AI_engine'] == \"HuggingFace Bloom 176B\":\n",
        "        result = bloom_request(request)\n",
        "      elif prefs['prompt_brainstormer']['AI_engine'] == \"HuggingFace Flan-T5\":\n",
        "        result = flan_request(request) \n",
        "      del page.prompt_brainstormer_list.controls[-1]\n",
        "      page.prompt_brainstormer_list.update()\n",
        "      page.add_to_prompt_brainstormer(str(result) + '\\n')\n",
        "    #print(f\"Remixing {seed_prompt}\" + (f\", about {optional_about_influencer}\" if bool(optional_about_influencer) else \"\"))\n",
        "    if good_key:\n",
        "      #print(request)\n",
        "      prompt_brainstormer()\n",
        "\n",
        "def run_prompt_writer(page):\n",
        "    '''try:\n",
        "        import nsp_pantry\n",
        "        from nsp_pantry import nsp_parse\n",
        "    except ModuleNotFoundError:\n",
        "        run_sp(\"wget -qq --show-progress --no-cache --backups=1 https://raw.githubusercontent.com/WASasquatch/noodle-soup-prompts/main/nsp_pantry.py\")\n",
        "        #print(subprocess.run(['wget', '-q', '--show-progress', '--no-cache', '--backups=1', 'https://raw.githubusercontent.com/WASasquatch/noodle-soup-prompts/main/nsp_pantry.py'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    finally:\n",
        "        import nsp_pantry\n",
        "        from nsp_pantry import nsp_parse'''\n",
        "    import random as rnd\n",
        "    def generate_prompt():\n",
        "      text_prompts = []\n",
        "      global art_Subjects, by_Artists, art_Styles\n",
        "      nsSubjects = nsp_parse(prefs['prompt_writer']['art_Subjects'])\n",
        "      nsArtists = nsp_parse(prefs['prompt_writer']['by_Artists'])\n",
        "      nsStyles = nsp_parse(prefs['prompt_writer']['art_Styles'])\n",
        "      prompt = nsSubjects\n",
        "      random_artist=[]\n",
        "      if nsArtists: random_artist.append(nsArtists)\n",
        "      for a in range(prefs['prompt_writer']['random_artists']):\n",
        "        random_artist.append(rnd.choice(artists))\n",
        "      artist = and_list(random_artist)\n",
        "      #artist = random.choice(artists) + \" and \" + random.choice(artists)\n",
        "      random_style = []\n",
        "      if prefs['prompt_writer']['art_Styles']: random_style.append(nsStyles)\n",
        "      for s in range(prefs['prompt_writer']['random_styles']):\n",
        "        random_style.append(rnd.choice(styles))\n",
        "      style = \", \".join(random_style)\n",
        "      subject_prompt = prompt\n",
        "      if len(artist) > 0: prompt += f\", by {artist}\"\n",
        "      if len(style) > 0: prompt += f\", style of {style}\"\n",
        "      if not prefs['prompt_writer']['permutate_artists']:\n",
        "        return prompt\n",
        "      if prefs['prompt_writer']['random_styles'] > 0 and prefs['prompt_writer']['permutate_artists']:\n",
        "        text_prompts.append(prompt)\n",
        "      if prefs['prompt_writer']['permutate_artists']:\n",
        "        for a in list_variations(random_artist):\n",
        "          prompt_variation = subject_prompt + f\", by {and_list(a)}\"\n",
        "          text_prompts.append(prompt_variation)\n",
        "        if prefs['prompt_writer']['random_styles'] > 0:\n",
        "          text_prompts.append(subject_prompt + f\", style of {style}\")\n",
        "        return text_prompts\n",
        "      #if mod_Custom and mod_Custom.strip(): prompt += mod_Custom)\n",
        "      #return prompt\n",
        "    prompts_writer = []\n",
        "    for p in range(prefs['prompt_writer']['amount']):\n",
        "      prompts_writer.append(generate_prompt())\n",
        "    for item in prompts_writer:\n",
        "      if type(item) is str:\n",
        "        page.add_to_prompt_writer(item)\n",
        "      if type(item) is list:\n",
        "        for i in item:\n",
        "          page.add_to_prompt_writer(i)\n",
        "\n",
        "def run_upscaling(page):\n",
        "    #print(str(ESRGAN_prefs))\n",
        "    if not status['installed_ESRGAN']:\n",
        "      alert_msg(page, \"You must Install Real-ESRGAN first\")\n",
        "      return\n",
        "    import os, shutil\n",
        "    import re\n",
        "    from collections import Counter\n",
        "    from PIL import Image as PILImage\n",
        "    enlarge_scale = ESRGAN_prefs['enlarge_scale']\n",
        "    face_enhance = ESRGAN_prefs['face_enhance']\n",
        "    image_path = ESRGAN_prefs['image_path']\n",
        "    save_to_GDrive = ESRGAN_prefs['save_to_GDrive']\n",
        "    upload_file = ESRGAN_prefs['upload_file']\n",
        "    download_locally = ESRGAN_prefs['download_locally']\n",
        "    display_image = ESRGAN_prefs['display_image']\n",
        "    dst_image_path = ESRGAN_prefs['dst_image_path']\n",
        "    filename_suffix = ESRGAN_prefs['filename_suffix']\n",
        "    split_image_grid = ESRGAN_prefs['split_image_grid']\n",
        "    rows = ESRGAN_prefs['rows']\n",
        "    cols = ESRGAN_prefs['cols']\n",
        "    def split(im, rows, cols, img_path, should_cleanup=False):\n",
        "        im_width, im_height = im.size\n",
        "        row_width = int(im_width / rows)\n",
        "        row_height = int(im_height / cols)\n",
        "        n = 0\n",
        "        for i in range(0, cols):\n",
        "            for j in range(0, rows):\n",
        "                box = (j * row_width, i * row_height, j * row_width +\n",
        "                      row_width, i * row_height + row_height)\n",
        "                outp = im.crop(box)\n",
        "                name, ext = os.path.splitext(img_path)\n",
        "                outp_path = name + \"-\" + str(n) + ext\n",
        "                #print(\"Exporting image tile: \" + outp_path)\n",
        "                outp.save(outp_path)\n",
        "                n += 1\n",
        "        if should_cleanup:\n",
        "            #print(\"Cleaning up: \" + img_path)\n",
        "            os.remove(img_path)\n",
        "    \n",
        "    os.chdir(os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "    upload_folder = 'upload'\n",
        "    result_folder = 'results'\n",
        "    if os.path.isdir(upload_folder):\n",
        "        shutil.rmtree(upload_folder)\n",
        "    if os.path.isdir(result_folder):\n",
        "        shutil.rmtree(result_folder)\n",
        "    os.mkdir(upload_folder)\n",
        "    os.mkdir(result_folder)\n",
        "\n",
        "    uploaded = None\n",
        "    if not upload_file:\n",
        "      if not image_path:\n",
        "         alert_msg(page, 'Provide path to image, local or url')\n",
        "         return\n",
        "      if '.' in image_path:\n",
        "        if os.path.exists(image_path):\n",
        "          uploaded = {image_path: image_path.rpartition(slash)[2]}\n",
        "        else:\n",
        "          alert_msg(page, 'File does not exist')\n",
        "          return\n",
        "      else:\n",
        "        if os.path.isdir(image_path):\n",
        "          uploaded = {}\n",
        "          for f in os.listdir(image_path):\n",
        "            uploaded[ os.path.join(image_path, f)] = f\n",
        "        else:\n",
        "          alert_msg(page, 'Image Path directory does not exist')\n",
        "          return\n",
        "    else:\n",
        "      uploaded = files.upload()\n",
        "    page.clear_ESRGAN_output(uploaded)\n",
        "    page.add_to_ESRGAN_output(Text(f\"Upscaling {len(uploaded)} images..\"))\n",
        "    for filename in uploaded.keys():\n",
        "      if not os.path.isfile(filename):\n",
        "        #print(\"Skipping \" + filename)\n",
        "        continue\n",
        "      fname = filename.rpartition(slash)[2] if slash in filename else filename\n",
        "      dst_path = os.path.join(upload_folder, fname)\n",
        "      #print(f'Copy {filename} to {dst_path}')\n",
        "      shutil.copy(filename, dst_path)\n",
        "      if split_image_grid:\n",
        "        img = PILImage.open(dst_path)\n",
        "        split(img, rows, cols, dst_path, True)\n",
        "    os.chdir(os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "    faceenhance = ' --face_enhance' if face_enhance else ''\n",
        "    run_sp(f'python inference_realesrgan.py -n RealESRGAN_x4plus -i {upload_folder} --outscale {enlarge_scale}{faceenhance}', cwd=os.path.join(dist_dir, 'Real-ESRGAN'), realtime=False)\n",
        "    os.chdir(root_dir)\n",
        "    if is_Colab:\n",
        "      from google.colab import files\n",
        "    if not bool(dst_image_path.strip()):\n",
        "      if os.path.isdir(image_path):\n",
        "          dst_image_path = image_path\n",
        "      else:\n",
        "          dst_image_path = prefs['image_output'] #image_path.rpartition(slash)[0]\n",
        "    filenames = os.listdir(os.path.join(dist_dir, 'Real-ESRGAN', 'results'))\n",
        "    for fname in filenames:\n",
        "      fparts = fname.rpartition('_out')\n",
        "      fname_clean = fparts[0] + filename_suffix + fparts[2]\n",
        "      #print(f'Copying {fname_clean}')\n",
        "      if save_to_GDrive:\n",
        "        if not os.path.isdir(dst_image_path):\n",
        "          os.makedirs(dst_image_path)\n",
        "        shutil.copy(os.path.join(dist_dir, 'Real-ESRGAN', 'results', fname), os.path.join(dst_image_path, fname_clean))\n",
        "      else: # TODO PyDrive\n",
        "        shutil.copy(os.path.join(dist_dir, 'Real-ESRGAN', 'results', fname), os.path.join(dst_image_path, fname_clean))\n",
        "      if download_locally:\n",
        "        files.download(os.path.join(dist_dir, 'Real-ESRGAN', 'results', fname))\n",
        "      if display_image:\n",
        "        page.add_to_ESRGAN_output(Image(src=os.path.join(dist_dir, 'Real-ESRGAN', 'results', fname)))\n",
        "      page.add_to_ESRGAN_output(Row([Text(os.path.join(dst_image_path, fname_clean))], alignment=MainAxisAlignment.CENTER))\n",
        "\n",
        "def run_retrieve(page):\n",
        "    upload_file = retrieve_prefs['upload_file']\n",
        "    image_path = retrieve_prefs['image_path']\n",
        "    display_full_metadata = retrieve_prefs['display_full_metadata']\n",
        "    display_image = retrieve_prefs['display_image']\n",
        "    add_to_prompts = retrieve_prefs['add_to_prompts']\n",
        "\n",
        "    import os, json\n",
        "    import PIL\n",
        "    from PIL import Image as PILImage\n",
        "    if is_Colab:\n",
        "      from google.colab import files\n",
        "    def meta_dream(meta):\n",
        "      if meta is not None and len(meta) > 1:\n",
        "          #d = Dream(meta[\"prompt\"])\n",
        "          print(str(meta))\n",
        "          arg = {}\n",
        "          p = ''\n",
        "          dream = '    Dream('\n",
        "          if meta.get('title'):\n",
        "            dream += f'\"{meta[\"title\"]}\"'\n",
        "            p = meta[\"title\"]\n",
        "          if meta.get('prompt'):\n",
        "            dream += f'\"{meta[\"prompt\"]}\"'\n",
        "            p = meta[\"prompt\"]\n",
        "          if meta.get('config'):\n",
        "            meta = meta['config']\n",
        "          if meta.get('prompt'):\n",
        "            #dream += f'\"{meta[\"prompt\"]}\"'\n",
        "            p = meta[\"prompt\"]\n",
        "          if meta.get('prompt2'):\n",
        "            dream += f', prompt2=\"{meta[\"prompt2\"]}\"'\n",
        "            arg[\"prompt2\"] = meta[\"prompt2\"]\n",
        "          if meta.get('tweens'):\n",
        "            dream += f', tweens={meta[\"tweens\"]}'\n",
        "            arg[\"tweens\"] = meta[\"tweens\"]\n",
        "          if meta.get('width'):\n",
        "            dream += f', width={meta[\"width\"]}'\n",
        "            arg[\"width\"] = meta[\"width\"]\n",
        "          if meta.get('height'):\n",
        "            dream += f', height={meta[\"height\"]}'\n",
        "            arg[\"height\"] = meta[\"height\"]\n",
        "          if meta.get('guidance_scale'):\n",
        "            dream += f', guidance_scale={meta[\"guidance_scale\"]}'\n",
        "            arg[\"guidance_scale\"] = meta[\"guidance_scale\"]\n",
        "          elif meta.get('CGS'):\n",
        "            dream += f', guidance_scale={meta[\"CGS\"]}'\n",
        "            arg[\"guidance_scale\"] = meta[\"CGS\"]\n",
        "          if meta.get('steps'):\n",
        "            dream += f', steps={meta[\"steps\"]}'\n",
        "            arg[\"steps\"] = meta[\"steps\"]\n",
        "          if meta.get('eta'):\n",
        "            dream += f', eta={meta[\"eta\"]}'\n",
        "            arg[\"eta\"] = meta[\"eta\"]\n",
        "          if meta.get('seed'):\n",
        "            dream += f', seed={meta[\"seed\"]}'\n",
        "            arg[\"seed\"] = meta[\"seed\"]\n",
        "          if meta.get('init_image'):\n",
        "            dream += f', init_image=\"{meta[\"init_image\"]}\"'\n",
        "            arg[\"init_image\"] = meta[\"init_image\"]\n",
        "          if meta.get('mask_image'):\n",
        "            dream += f', mask_image=\"{meta[\"mask_image\"]}\"'\n",
        "            arg[\"mask_image\"] = meta[\"mask_image\"]\n",
        "          if meta.get('init_image_strength'):\n",
        "            dream += f', init_image_strength={meta[\"init_image_strength\"]}'\n",
        "            arg[\"init_image_strength\"] = meta[\"init_image_strength\"]\n",
        "          dream += '),'\n",
        "          page.add_to_retrieve_output(Text(dream, selectable=True))\n",
        "          if display_full_metadata:\n",
        "            page.add_to_retrieve_output(Text(str(metadata)))\n",
        "          if add_to_prompts:\n",
        "            page.add_to_prompts(p, arg)\n",
        "      else:\n",
        "          alert_msg(page, 'Problem reading your config json image meta data.')\n",
        "          return\n",
        "    uploaded = {}\n",
        "    if not upload_file:\n",
        "      if not bool(image_path):\n",
        "        alert_msg(page, 'Provide path to image, local or url')\n",
        "        return\n",
        "      if '.' in image_path:\n",
        "        if os.path.exists(image_path):\n",
        "          uploaded = {image_path: image_path.rpartition(slash)[2]}\n",
        "        else:\n",
        "          alert_msg(page, 'File does not exist')\n",
        "          return\n",
        "      else:\n",
        "        if os.path.isdir(image_path):\n",
        "          uploaded = {}\n",
        "          for f in os.listdir(image_path):\n",
        "            uploaded[ os.path.join(image_path, f)] = f\n",
        "        else:\n",
        "          alert_msg(page, 'The image_path directory does not exist')\n",
        "          return\n",
        "    else:\n",
        "      if not is_Colab:\n",
        "        uploaded = files.upload()\n",
        "        alert_msg(page, \"Can't upload an image easily from non-Colab systems\")\n",
        "        return\n",
        "    if len(uploaded) > 1:\n",
        "      page.add_to_retrieve_output(Text(f\"Revealing Dream of {len(uploaded)} images..\\n\"))\n",
        "    for filename in uploaded.keys():\n",
        "      if not os.path.isfile(filename):\n",
        "        #print(\"Skipping subfolder \" + filename)\n",
        "        continue\n",
        "      print(filename)\n",
        "      if filename.rpartition('.')[2] == 'json':\n",
        "        meta = json.load(filename)\n",
        "        meta_dream(meta)\n",
        "      elif filename.rpartition('.')[2] == 'png':\n",
        "        img = PILImage.open(filename)\n",
        "        metadata = img.info\n",
        "        if display_image:\n",
        "          page.add_to_retrieve_output(Image(src=filename))\n",
        "          #display(img)\n",
        "        if metadata is None or len(metadata) < 1:\n",
        "          alert_msg(page, 'Sorry, image has no exif data.')\n",
        "          return\n",
        "          #print(metadata)\n",
        "        else:\n",
        "          if metadata.get('config_json'):\n",
        "            json_txt = metadata['config_json']\n",
        "            #print(json_txt)\n",
        "            meta = json.loads(json_txt)\n",
        "            meta_dream(meta)\n",
        "          elif metadata.get('config'):\n",
        "            config = metadata['config']\n",
        "            meta = {}\n",
        "            key = \"\"\n",
        "            val = \"\"\n",
        "            if metadata.get('title'):\n",
        "              meta['prompt'] = metadata['title']\n",
        "            for col in config.split(':'):\n",
        "              #print(col.strip())\n",
        "              if ',' not in col:\n",
        "                key = col\n",
        "              else:\n",
        "                parts = col.rpartition(',')\n",
        "                val = parts[0].strip()\n",
        "                if bool(key) and bool(val):\n",
        "                  meta[key] = val\n",
        "                  val = ''\n",
        "                key = parts[2].strip()\n",
        "            #print(meta)\n",
        "            meta_dream(meta)\n",
        "            #print(dream)\n",
        "          else:\n",
        "            alert_msg(page, \"No Enhanced Stable Diffusion config metadata found inside image.\")\n",
        "\n",
        "def run_initfolder(page):\n",
        "    prompt_string = initfolder_prefs['prompt_string']\n",
        "    init_folder = initfolder_prefs['init_folder']\n",
        "    include_strength = initfolder_prefs['include_strength']\n",
        "    image_strength = initfolder_prefs['image_strength']\n",
        "    #init_image='/content/ pic.png', init_image_strength=0.4\n",
        "    if bool(prompt_string):\n",
        "      p_str = f'\"{prompt_string.strip()}\"'\n",
        "      skip_str = f', init_image_strength={image_strength}' if bool(include_strength) else ''\n",
        "      if os.path.isdir(init_folder):\n",
        "        arg = {}\n",
        "        #print(\"prompts = [\")\n",
        "        for f in os.listdir(init_folder):\n",
        "          init_path = os.path.join(init_folder, f)\n",
        "          if os.path.isdir(init_path): continue\n",
        "          if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            page.add_to_initfolder_output(Text(f'    Dream({p_str}, init_image=\"{init_path}\"{skip_str}),'))\n",
        "            arg['init_image'] = init_path\n",
        "            if bool(include_strength):\n",
        "              arg['init_image_strength'] = image_strength\n",
        "            page.add_to_prompts(prompt_string, arg)\n",
        "        if not bool(status['installed_img2img']):\n",
        "          alert_msg(page, 'Make sure you Install the Image2Image module before running Stable Diffusion on prompts...')\n",
        "       # print(\"]\")\n",
        "      else:\n",
        "        alert_msg(page, 'The init_folder directory does not exist.')\n",
        "    else: alert_msg(page, 'Your prompt_string is empty. What do you want to apply to images?')\n",
        "\n",
        "def multiple_of_64(x):\n",
        "    return int(round(x/64)*64)\n",
        "def multiple_of_8(x):\n",
        "    return int(round(x/8)*8)\n",
        "def multiple_of(x, num):\n",
        "    return int(round(x/num)*num)\n",
        "def scale_dimensions(width, height, max=1024, multiple=16):\n",
        "  max = int(max)\n",
        "  r_width = width\n",
        "  r_height = height\n",
        "  if width < max and height < max:\n",
        "    if width >= height:\n",
        "      ratio = max / width\n",
        "      r_width = max\n",
        "      r_height = int(height * ratio)\n",
        "    else:\n",
        "      ratio = max / height\n",
        "      r_height = max\n",
        "      r_width = int(width * ratio)\n",
        "    width = r_width\n",
        "    height = r_height\n",
        "  if width >= height:\n",
        "    if width > max:\n",
        "      r_width = max\n",
        "      r_height = int(height * (max/width))\n",
        "    else:\n",
        "      r_width = width\n",
        "      r_height = height\n",
        "  else:\n",
        "    if height > max:\n",
        "      r_height = max\n",
        "      r_width = int(width * (max/height))\n",
        "    else:\n",
        "      r_width = width\n",
        "      r_height = height\n",
        "  return multiple_of(r_width, multiple), multiple_of(r_height, multiple)\n",
        "\n",
        "def run_repainter(page):\n",
        "    global repaint_prefs, prefs, status, pipe_repaint\n",
        "    if not status['installed_diffusers']:\n",
        "      alert_msg(page, \"You need to Install HuggingFace Diffusers before using...\")\n",
        "      return\n",
        "    if not bool(repaint_prefs['original_image']) or not bool(repaint_prefs['mask_image']):\n",
        "      alert_msg(page, \"You must provide the Original Image and the Mask Image to process...\")\n",
        "      return\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line, size=17)\n",
        "      page.repaint_output.controls.append(line)\n",
        "      page.repaint_output.update()\n",
        "    def clear_last():\n",
        "      del page.repaint_output.controls[-1]\n",
        "      page.repaint_output.update()\n",
        "    progress = ProgressBar(bar_height=8)\n",
        "    def callback_fnc(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n",
        "      callback_fnc.has_been_called = True\n",
        "      nonlocal progress\n",
        "      total_steps = len(latents)\n",
        "      percent = (step +1)/ total_steps\n",
        "      progress.value = percent\n",
        "      progress.tooltip = f\"{step +1} / {total_steps} timestep: {timestep}\"\n",
        "      progress.update()\n",
        "      #print(f'{type(latents)} {len(latents)}- {str(latents)}')\n",
        "    prt(Row([ProgressRing(), Text(\"Installing RePaint Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "    import requests, random\n",
        "    from io import BytesIO\n",
        "    from PIL import Image as PILImage\n",
        "    from PIL import ImageOps\n",
        "    if repaint_prefs['original_image'].startswith('http'):\n",
        "      #response = requests.get(repaint_prefs['original_image'])\n",
        "      #original_img = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "      original_img = PILImage.open(requests.get(repaint_prefs['original_image'], stream=True).raw)\n",
        "    else:\n",
        "      if os.path.isfile(repaint_prefs['original_image']):\n",
        "        original_img = PILImage.open(repaint_prefs['original_image'])\n",
        "      else:\n",
        "        alert_msg(page, f\"ERROR: Couldn't find your original_image {repaint_prefs['original_image']}\")\n",
        "        return\n",
        "    width, height = original_img.size\n",
        "    width, height = scale_dimensions(width, height, repaint_prefs['max_size'])\n",
        "    original_img = original_img.resize((width, height), resample=PILImage.LANCZOS)\n",
        "    original_img = ImageOps.exif_transpose(original_img).convert(\"RGB\")\n",
        "    mask_img = None\n",
        "    if repaint_prefs['mask_image'].startswith('http'):\n",
        "      #response = requests.get(repaint_prefs['mask_image'])\n",
        "      #mask_img = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "      mask_img = PILImage.open(requests.get(repaint_prefs['mask_image'], stream=True).raw)\n",
        "    else:\n",
        "      if os.path.isfile(repaint_prefs['mask_image']):\n",
        "        mask_img = PILImage.open(repaint_prefs['mask_image'])\n",
        "      else:\n",
        "        alert_msg(page, f\"ERROR: Couldn't find your mask_image {repaint_prefs['mask_image']}\")\n",
        "        return\n",
        "    #mask_img = mask_img.convert(\"L\")\n",
        "    #mask_img = mask_img.convert(\"1\")\n",
        "    if repaint_prefs['invert_mask']:\n",
        "       mask_img = ImageOps.invert(mask_img.convert('RGB'))\n",
        "    mask_img = mask_img.resize((width, height), resample=PILImage.NEAREST)\n",
        "    mask_img = ImageOps.exif_transpose(mask_img).convert(\"RGB\")\n",
        "    #print(f'Resize to {width}x{height}')\n",
        "    clear_txt2img_pipe()\n",
        "    clear_img2img_pipe()\n",
        "    clear_unet_pipe()\n",
        "    clear_clip_guided_pipe()\n",
        "    if not status['installed_repaint']:\n",
        "      get_repaint(page)\n",
        "      status['installed_repaint'] = True\n",
        "    if pipe_repaint is None:\n",
        "      pipe_repaint = get_repaint_pipe()\n",
        "    clear_last()\n",
        "    prt(\"Generating Repaint of your Image...\")\n",
        "    prt(progress)\n",
        "    random_seed = int(repaint_prefs['seed']) if int(repaint_prefs['seed']) > 0 else random.randint(0,4294967295)\n",
        "    generator = torch.Generator(device=torch_device).manual_seed(random_seed)\n",
        "#Sizes of tensors must match except in dimension 1. Expected size 58 but got size 59 for tensor number 1 in the list.\n",
        "    try:\n",
        "      #from IPython.utils.capture import capture_output\n",
        "      #with capture_output() as captured:\n",
        "      image = pipe_repaint(original_image=original_img, mask_image=mask_img, num_inference_steps=repaint_prefs['num_inference_steps'], eta=repaint_prefs['eta'], jump_length=repaint_prefs['jump_length'], jump_n_sample=repaint_prefs['jump_length'], generator=generator, callback=callback_fnc, callback_steps=1).images[0]\n",
        "      #print(str(captured.stdout))\n",
        "    except Exception as e:\n",
        "      clear_last()\n",
        "      alert_msg(page, f\"ERROR: Couldn't Repaint your image for some reason.  Possibly out of memory or something wrong with my code...\", content=Text(str(e)))\n",
        "      return\n",
        "    fname = repaint_prefs['original_image'].rpartition('.')[0]\n",
        "    fname = fname.rpartition(slash)[2]\n",
        "    if prefs['file_suffix_seed']: fname += f\"-{random_seed}\"\n",
        "    image_path = available_file(stable_dir, fname, 1)\n",
        "    image.save(image_path)\n",
        "    out_path = image_path\n",
        "    clear_last()\n",
        "    clear_last()\n",
        "    prt(Row([Img(src=image_path, width=width, height=height, fit=ImageFit.FILL, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "    #TODO: ESRGAN, Metadata & PyDrive\n",
        "    if storage_type == \"Colab Google Drive\":\n",
        "      new_file = available_file(prefs['image_output'], fname, 1)\n",
        "      out_path = new_file\n",
        "      shutil.copy(image_path, new_file)\n",
        "    elif bool(prefs['image_output']):\n",
        "      new_file = available_file(prefs['image_output'], fname, 1)\n",
        "      out_path = new_file\n",
        "      shutil.copy(image_path, new_file)\n",
        "    prt(Row([Text(out_path)], alignment=MainAxisAlignment.CENTER))\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "def run_image_variation(page):\n",
        "    global image_variation_prefs, pipe_image_variation\n",
        "    if not status['installed_diffusers']:\n",
        "      alert_msg(page, \"You must Install the HuggingFace Diffusers Library first... \")\n",
        "      return\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line)\n",
        "      page.image_variation_output.controls.append(line)\n",
        "      page.image_variation_output.update()\n",
        "    def clear_last():\n",
        "      del page.image_variation_output.controls[-1]\n",
        "      page.image_variation_output.update()\n",
        "    progress = ProgressBar(bar_height=8)\n",
        "    def callback_fnc(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n",
        "      callback_fnc.has_been_called = True\n",
        "      nonlocal progress\n",
        "      total_steps = image_variation_prefs['num_inference_steps']#len(latents)\n",
        "      percent = (step +1)/ total_steps\n",
        "      progress.value = percent\n",
        "      progress.tooltip = f\"{step +1} / {total_steps} timestep: {timestep}\"\n",
        "      progress.update()\n",
        "    page.image_variation_output.controls.clear()\n",
        "    from io import BytesIO\n",
        "    from PIL import Image as PILImage\n",
        "    from PIL import ImageOps\n",
        "    if image_variation_prefs['init_image'].startswith('http'):\n",
        "      init_img = PILImage.open(requests.get(image_variation_prefs['init_image'], stream=True).raw)\n",
        "    else:\n",
        "      if os.path.isfile(image_variation_prefs['init_image']):\n",
        "        init_img = PILImage.open(image_variation_prefs['init_image'])\n",
        "      else:\n",
        "        alert_msg(page, f\"ERROR: Couldn't find your init_image {image_variation_prefs['init_image']}\")\n",
        "        return\n",
        "    width, height = init_img.size\n",
        "    width, height = scale_dimensions(width, height, image_variation_prefs['max_size'])\n",
        "    tform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(\n",
        "            (width, height),\n",
        "            interpolation=transforms.InterpolationMode.BICUBIC,\n",
        "            antialias=False,\n",
        "            ),\n",
        "        transforms.Normalize(\n",
        "          [0.48145466, 0.4578275, 0.40821073],\n",
        "          [0.26862954, 0.26130258, 0.27577711]),\n",
        "    ])\n",
        "    init_img = tform(init_img).to(torch_device)\n",
        "    #init_img = init_img.resize((width, height), resample=PILImage.LANCZOS)\n",
        "    #init_img = ImageOps.exif_transpose(init_img).convert(\"RGB\")\n",
        "    clear_pipes('image_variation')\n",
        "    if pipe_image_variation == None:\n",
        "        from diffusers import StableDiffusionImageVariationPipeline\n",
        "        prt(Row([ProgressRing(), Text(\" Downloading Image Variation Pipeline\", weight=FontWeight.BOLD)]))\n",
        "        model_id = \"fusing/sd-image-variations-diffusers\"\n",
        "        pipe_image_variation = StableDiffusionImageVariationPipeline.from_pretrained(model_id, scheduler=model_scheduler(model_id), safety_checker=None, cache_dir=prefs['cache_dir'] if bool(prefs['cache_dir']) else None)\n",
        "        pipe_image_variation.to(torch_device)\n",
        "        pipe_image_variation = optimize_pipe(pipe_image_variation)\n",
        "        #pipe_image_variation.set_progress_bar_config(disable=True)\n",
        "        clear_last()\n",
        "    s = \"s\" if image_variation_prefs['num_images'] > 1 else \"\"\n",
        "    prt(f\"Generating Variation{s} of your Image...\")\n",
        "    prt(progress)\n",
        "    random_seed = int(image_variation_prefs['seed']) if int(image_variation_prefs['seed']) > 0 else rnd.randint(0,4294967295)\n",
        "    generator = torch.Generator(device=torch_device).manual_seed(random_seed)\n",
        "\n",
        "    try:\n",
        "        images = pipe_image_variation(image=init_img, height=height, width=width, num_inference_steps=image_variation_prefs['num_inference_steps'], guidance_scale=image_variation_prefs['guidance_scale'], eta=image_variation_prefs['eta'], num_images_per_prompt=image_variation_prefs['num_images'], generator=generator, callback=callback_fnc, callback_steps=1).images\n",
        "    except Exception as e:\n",
        "        clear_last()\n",
        "        clear_last()\n",
        "        alert_msg(page, \"Error running pipeline\", content=Text(str(e)))\n",
        "        return\n",
        "    clear_last()\n",
        "    clear_last()\n",
        "    fname = image_variation_prefs['init_image'].rpartition('.')[0]\n",
        "    fname = fname.rpartition(slash)[2]\n",
        "    if prefs['file_suffix_seed']: fname += f\"-{random_seed}\"\n",
        "    for image in images:\n",
        "        image_path = available_file(stable_dir, fname, 1)\n",
        "        image.save(image_path)\n",
        "        out_path = image_path\n",
        "        prt(Row([Img(src=image_path, width=width, height=height, fit=ImageFit.FILL, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "        #TODO: ESRGAN, Metadata & PyDrive\n",
        "        if storage_type == \"Colab Google Drive\":\n",
        "            new_file = available_file(prefs['image_output'], fname, 1)\n",
        "            out_path = new_file\n",
        "            shutil.copy(image_path, new_file)\n",
        "        elif bool(prefs['image_output']):\n",
        "            new_file = available_file(prefs['image_output'], fname, 1)\n",
        "            out_path = new_file\n",
        "            shutil.copy(image_path, new_file)\n",
        "        prt(Row([Text(out_path)], alignment=MainAxisAlignment.CENTER))\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "def run_CLIPstyler(page):\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line)\n",
        "      page.image2text_output.controls.append(line)\n",
        "      page.image2text_output.update()\n",
        "    def clear_last():\n",
        "      del page.image2text_output.controls[-1]\n",
        "      page.image2text_output.update()\n",
        "    clipstyler_dir = os.path.join(root_dir, \"CLIPstyler\")\n",
        "    if not os.path.exists(clipstyler_dir):\n",
        "          os.mkdir(clipstyler_dir)\n",
        "    if CLIPstyler_prefs['original_image'].startswith('http'):\n",
        "        import requests\n",
        "        from io import BytesIO\n",
        "        response = requests.get(CLIPstyler_prefs['original_image'])\n",
        "        fpath = os.path.join(clipstyler_dir, CLIPstyler_prefs['original_image'].rpartition(slash)[2])\n",
        "        original_img = PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        #width, height = original_img.size\n",
        "        #width, height = scale_dimensions(width, height)\n",
        "        original_img = original_img.resize((CLIPstyler_prefs['width'], CLIPstyler_prefs['height']), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "        original_img.save(fpath)\n",
        "        CLIPstyler_prefs['image_dir'] = fpath\n",
        "    elif os.path.isfile(CLIPstyler_prefs['original_image']):\n",
        "        fpath = os.path.join(clipstyler_dir, CLIPstyler_prefs['original_image'].rpartition(slash)[2])\n",
        "        original_img = PILImage.open(CLIPstyler_prefs['original_image'])\n",
        "        #width, height = original_img.size\n",
        "        #width, height = scale_dimensions(width, height)\n",
        "        original_img = original_img.resize((CLIPstyler_prefs['width'], CLIPstyler_prefs['height']), resample=PILImage.LANCZOS).convert(\"RGB\")\n",
        "        original_img.save(fpath)\n",
        "        CLIPstyler_prefs['image_dir'] = fpath\n",
        "    else:\n",
        "        alert_msg(page, \"Couldn't find a valid File, Path or URL...\")\n",
        "        return\n",
        "    progress = ProgressBar(bar_height=8)\n",
        "    prt(Row([ProgressRing(), Text(\" Downloading CLIP-Styler Packages...\", weight=FontWeight.BOLD)]))\n",
        "    run_process(\"pip install ftfy regex tqdm\", realtime=False, page=page)\n",
        "    run_sp(\"pip install git+https://github.com/openai/CLIP.git\", realtime=False)\n",
        "    #os.chdir(clipstyler_dir)\n",
        "    os.chdir(root_dir)\n",
        "    run_sp(\"pip install git+https://github.com/cyclomon/CLIPstyler.git\", realtime=True)\n",
        "    #!git clone https://github.com/cyclomon/CLIPstyler/\n",
        "    run_sp(f\"git clone https://github.com/cyclomon/CLIPstyler/ {clipstyler_dir}\", realtime=True)\n",
        "    os.chdir(root_dir)\n",
        "    #run_process(f\"git clone https://github.com/paper11667/CLIPstyler/ {clipstyler_dir}\", realtime=False, page=page)\n",
        "    sys.path.append(clipstyler_dir)\n",
        "\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import torch.nn\n",
        "    import torch.optim as optim\n",
        "    from torchvision import transforms, models\n",
        "    import StyleNet\n",
        "    import utils\n",
        "    import clip\n",
        "    import torch.nn.functional as F\n",
        "    from template import imagenet_templates\n",
        "    from torchvision import utils as vutils\n",
        "    import argparse\n",
        "    from torchvision.transforms.functional import adjust_contrast\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    VGG = models.vgg19(pretrained=True).features\n",
        "    VGG.to(device)\n",
        "    save_dir = stable_dir\n",
        "    if bool(CLIPstyler_prefs['batch_folder_name']):\n",
        "        save_dir = os.path.join(stable_dir, CLIPstyler_prefs['batch_folder_name'])\n",
        "    new_file = format_filename(CLIPstyler_prefs[\"prompt_text\"])\n",
        "    images = []\n",
        "    for parameter in VGG.parameters():\n",
        "        parameter.requires_grad_(False)\n",
        "        \n",
        "    def img_denormalize(image):\n",
        "        mean=torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "        std=torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        "        mean = mean.view(1,-1,1,1)\n",
        "        std = std.view(1,-1,1,1)\n",
        "        image = image*std +mean\n",
        "        return image\n",
        "\n",
        "    def img_normalize(image):\n",
        "        mean=torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "        std=torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        "        mean = mean.view(1,-1,1,1)\n",
        "        std = std.view(1,-1,1,1)\n",
        "        image = (image-mean)/std\n",
        "        return image\n",
        "\n",
        "    def clip_normalize(image,device):\n",
        "        image = F.interpolate(image,size=224,mode='bicubic')\n",
        "        mean=torch.tensor([0.48145466, 0.4578275, 0.40821073]).to(device)\n",
        "        std=torch.tensor([0.26862954, 0.26130258, 0.27577711]).to(device)\n",
        "        mean = mean.view(1,-1,1,1)\n",
        "        std = std.view(1,-1,1,1)\n",
        "        image = (image-mean)/std\n",
        "        return image\n",
        "        \n",
        "    def get_image_prior_losses(inputs_jit):\n",
        "        diff1 = inputs_jit[:, :, :, :-1] - inputs_jit[:, :, :, 1:]\n",
        "        diff2 = inputs_jit[:, :, :-1, :] - inputs_jit[:, :, 1:, :]\n",
        "        diff3 = inputs_jit[:, :, 1:, :-1] - inputs_jit[:, :, :-1, 1:]\n",
        "        diff4 = inputs_jit[:, :, :-1, :-1] - inputs_jit[:, :, 1:, 1:]\n",
        "        loss_var_l2 = torch.norm(diff1) + torch.norm(diff2) + torch.norm(diff3) + torch.norm(diff4)\n",
        "        return loss_var_l2\n",
        "\n",
        "    from argparse import Namespace\n",
        "    source = CLIPstyler_prefs['source']\n",
        "\n",
        "    training_args = {\n",
        "        \"lambda_tv\": 2e-3,\n",
        "        \"lambda_patch\": 9000,\n",
        "        \"lambda_dir\": 500,\n",
        "        \"lambda_c\": 150,\n",
        "        \"crop_size\": CLIPstyler_prefs['crop_size'],\n",
        "        \"num_crops\":CLIPstyler_prefs['num_crops'],\n",
        "        \"img_height\":CLIPstyler_prefs['height'],\n",
        "        \"img_width\":CLIPstyler_prefs['width'],\n",
        "        \"max_step\":CLIPstyler_prefs['training_iterations'],\n",
        "        \"lr\":5e-4,\n",
        "        \"thresh\":0.7,\n",
        "        \"content_path\":CLIPstyler_prefs['image_dir'],\n",
        "        \"text\":CLIPstyler_prefs['prompt_text']\n",
        "    }\n",
        "\n",
        "    style_args = Namespace(**training_args)\n",
        "\n",
        "    def compose_text_with_templates(text: str, templates=imagenet_templates) -> list:\n",
        "        return [template.format(text) for template in templates]\n",
        "\n",
        "    content_path = style_args.content_path\n",
        "    content_image = utils.load_image2(content_path, img_height=style_args.img_height,img_width =style_args.img_width)\n",
        "    content_image = content_image.to(device)\n",
        "    content_features = utils.get_features(img_normalize(content_image), VGG)\n",
        "    target = content_image.clone().requires_grad_(True).to(device)\n",
        "    style_net = StyleNet.UNet()\n",
        "    style_net.to(device)\n",
        "\n",
        "    style_weights = {'conv1_1': 0.1,\n",
        "                    'conv2_1': 0.2,\n",
        "                    'conv3_1': 0.4,\n",
        "                    'conv4_1': 0.8,\n",
        "                    'conv5_1': 1.6}\n",
        "    clear_last()\n",
        "    prt(\"Generating Stylized Image from your source... Check console output for progress.\")\n",
        "    prt(progress)\n",
        "\n",
        "    content_weight = style_args.lambda_c\n",
        "    show_every = 20\n",
        "    optimizer = optim.Adam(style_net.parameters(), lr=style_args.lr)\n",
        "    s_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "    steps = style_args.max_step\n",
        "    content_loss_epoch = []\n",
        "    style_loss_epoch = []\n",
        "    total_loss_epoch = []\n",
        "    output_image = content_image\n",
        "    m_cont = torch.mean(content_image,dim=(2,3),keepdim=False).squeeze(0)\n",
        "    m_cont = [m_cont[0].item(),m_cont[1].item(),m_cont[2].item()]\n",
        "    cropper = transforms.Compose([transforms.RandomCrop(style_args.crop_size)])\n",
        "    augment = transforms.Compose([\n",
        "        transforms.RandomPerspective(fill=0, p=1,distortion_scale=0.5),\n",
        "        transforms.Resize(224)\n",
        "    ])\n",
        "\n",
        "    clip_model, preprocess = clip.load('ViT-B/32', device, jit=False)\n",
        "    prompt = style_args.text\n",
        "\n",
        "    with torch.no_grad():\n",
        "        template_text = compose_text_with_templates(prompt, imagenet_templates)\n",
        "        tokens = clip.tokenize(template_text).to(device)\n",
        "        text_features = clip_model.encode_text(tokens).dcrop_sizech()\n",
        "        text_features = text_features.mean(axis=0, keepdim=True)\n",
        "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "        template_source = compose_text_with_templates(source, imagenet_templates)\n",
        "        tokens_source = clip.tokenize(template_source).to(device)\n",
        "        text_source = clip_model.encode_text(tokens_source).dcrop_sizech()\n",
        "        text_source = text_source.mean(axis=0, keepdim=True)\n",
        "        text_source /= text_source.norm(dim=-1, keepdim=True)\n",
        "        source_features = clip_model.encode_image(clip_normalize(content_image,device))\n",
        "        source_features /= (source_features.clone().norm(dim=-1, keepdim=True))\n",
        "\n",
        "        \n",
        "    num_crops = style_args.num_crops\n",
        "    for epoch in range(0, steps+1):\n",
        "        s_scheduler.step()\n",
        "        target = style_net(content_image,use_sigmoid=True).to(device)\n",
        "        target.requires_grad_(True)\n",
        "        target_features = utils.get_features(img_normalize(target), VGG)\n",
        "        content_loss = 0\n",
        "        content_loss += torch.mean((target_features['conv4_2'] - content_features['conv4_2']) ** 2)\n",
        "        content_loss += torch.mean((target_features['conv5_2'] - content_features['conv5_2']) ** 2)\n",
        "        loss_patch=0 \n",
        "        img_proc =[]\n",
        "        for n in range(num_crops):\n",
        "            target_crop = cropper(target)\n",
        "            target_crop = augment(target_crop)\n",
        "            img_proc.append(target_crop)\n",
        "        img_proc = torch.cat(img_proc,dim=0)\n",
        "        img_aug = img_proc\n",
        "        image_features = clip_model.encode_image(clip_normalize(img_aug,device))\n",
        "        image_features /= (image_features.clone().norm(dim=-1, keepdim=True))\n",
        "        img_direction = (image_features-source_features)\n",
        "        img_direction /= img_direction.clone().norm(dim=-1, keepdim=True)\n",
        "        text_direction = (text_features-text_source).repeat(image_features.size(0),1)\n",
        "        text_direction /= text_direction.norm(dim=-1, keepdim=True)\n",
        "        loss_temp = (1- torch.cosine_similarity(img_direction, text_direction, dim=1))\n",
        "        loss_temp[loss_temp<style_args.thresh] =0\n",
        "        loss_patch+=loss_temp.mean()\n",
        "        glob_features = clip_model.encode_image(clip_normalize(target,device))\n",
        "        glob_features /= (glob_features.clone().norm(dim=-1, keepdim=True))\n",
        "        glob_direction = (glob_features-source_features)\n",
        "        glob_direction /= glob_direction.clone().norm(dim=-1, keepdim=True)\n",
        "        loss_glob = (1- torch.cosine_similarity(glob_direction, text_direction, dim=1)).mean()\n",
        "        reg_tv = style_args.lambda_tv*get_image_prior_losses(target)\n",
        "        total_loss = style_args.lambda_patch*loss_patch + content_weight * content_loss+ reg_tv+ style_args.lambda_dir*loss_glob\n",
        "        total_loss_epoch.append(total_loss)\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % show_every == 0:\n",
        "            prt(\"After %d iters:\" % epoch)\n",
        "            prt('  Total loss: ', total_loss.item())\n",
        "            prt('  Content loss: ', content_loss.item())\n",
        "            prt('  patch loss: ', loss_patch.item())\n",
        "            prt('  dir loss: ', loss_glob.item())\n",
        "            prt('  TV loss: ', reg_tv.item())\n",
        "        \n",
        "        if epoch % show_every == 0:\n",
        "            output_image = target.clone()\n",
        "            output_image = torch.clamp(output_image,0,1)\n",
        "            output_image = adjust_contrast(output_image,1.5)\n",
        "            img = utils.im_convert2(output_image)\n",
        "            save_file = available_file(save_dir, new_file, 1)\n",
        "            img.save(save_file)\n",
        "            prt(Row([Img(src=save_file, width=CLIPstyler_prefs['width'], height=CLIPstyler_prefs['height'], fit=ImageFit.FILL, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "            prt(Row([Text(save_file)], alignment=MainAxisAlignment.CENTER))\n",
        "            images.append(save_file)\n",
        "            #plt.imshow(utils.im_convert2(output_image))\n",
        "            #plt.show()\n",
        "        progress.value = (epoch) / steps\n",
        "        progress.tooltip = f'[{(epoch)} / {steps}]'\n",
        "        progress.update()\n",
        "    #clear_last()\n",
        "    # TODO: ESRGAN and copy to GDrive and Metadata\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "def run_image2text(page):\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line)\n",
        "      page.image2text_output.controls.append(line)\n",
        "      page.image2text_output.update()\n",
        "    def clear_last():\n",
        "      del page.image2text_output.controls[-1]\n",
        "      page.image2text_output.update()\n",
        "    progress = ProgressBar(bar_height=8)\n",
        "    #if not status['installed_diffusers']:\n",
        "    #  alert_msg(page, \"You must Install the HuggingFace Diffusers Library first... \")\n",
        "    #  return\n",
        "    prt(Row([ProgressRing(), Text(\" Downloading Image2Text CLIP-Interrogator Blips...\", weight=FontWeight.BOLD)]))\n",
        "    #try:\n",
        "    #    import clip\n",
        "    #except ModuleNotFoundError:\n",
        "    run_process(\"pip install ftfy regex tqdm timm fairscale requests\", realtime=False)\n",
        "    #run_sp(\"pip install --upgrade transformers==4.21.2\", realtime=False)\n",
        "    run_process(\"pip install transformers==4.21.3 --upgrade --force-reinstall\", realtime=False)\n",
        "    run_process(\"pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\", realtime=False)\n",
        "    run_process(\"pip install -e git+https://github.com/pharmapsychotic/BLIP.git@lib#egg=blip\", realtime=False)\n",
        "    run_process(\"pip clone https://github.com/pharmapsychotic/clip-interrogator.git\", realtime=False)\n",
        "        #['pip', 'install', 'ftfy', 'gradio', 'regex', 'tqdm', 'transformers==4.21.2', 'timm', 'fairscale', 'requests'],\n",
        "    #    pass\n",
        "    # Have to force downgrade of transformers because error with cache_dir, but should upgrade after run\n",
        "    run_process(\"pip install clip-interrogator\", realtime=False)\n",
        "    \n",
        "    '''def setup():\n",
        "        install_cmds = [\n",
        "            ['pip', 'install', 'ftfy', 'gradio', 'regex', 'tqdm', 'transformers==4.21.2', 'timm', 'fairscale', 'requests'],\n",
        "            ['pip', 'install', 'git+https://github.com/openai/CLIP.git@main#egg=clip'],\n",
        "            ['pip', 'install', 'git+https://github.com/pharmapsychotic/BLIP.git@lib#egg=blip'],\n",
        "            ['git', 'clone', 'https://github.com/pharmapsychotic/clip-interrogator.git'],\n",
        "            ['pip', 'install', 'clip-interrogator'],\n",
        "        ]\n",
        "        for cmd in install_cmds:\n",
        "            print(subprocess.run(cmd, stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    setup()'''\n",
        "    #run_sp(\"pip install git+https://github.com/openai/CLIP.git\", realtime=False)\n",
        "    import argparse, sys, time\n",
        "    sys.path.append('src/blip')\n",
        "    sys.path.append('src/clip')\n",
        "    sys.path.append('clip-interrogator')\n",
        "    import clip\n",
        "    import torch\n",
        "    from clip_interrogator import Interrogator, Config\n",
        "    clear_last()\n",
        "    prt(\"Interrogating Images to Describe Prompt... Check console output for progress.\")\n",
        "    prt(progress)\n",
        "    ci = Interrogator(Config())\n",
        "    '''try:\n",
        "    except Exception as e:\n",
        "        clear_last()\n",
        "        alert_msg(page, \"ERROR: Problem running Interrogator, check settings and try again...\", content=Text(str(e)))\n",
        "        pass'''\n",
        "    def inference(image, mode):\n",
        "        nonlocal ci\n",
        "        image = image.convert('RGB')\n",
        "        if mode == 'best':\n",
        "            return ci.interrogate(image)\n",
        "        elif mode == 'classic':\n",
        "            return ci.interrogate_classic(image)\n",
        "        else:\n",
        "            return ci.interrogate_fast(image)\n",
        "    folder_path = image2text_prefs['folder_path']\n",
        "    mode = image2text_prefs['mode'] #'best' #param [\"best\",\"classic\", \"fast\"]\n",
        "    files = [f for f in os.listdir(folder_path) if f.endswith('.jpg') or  f.endswith('.png')] if os.path.exists(folder_path) else []\n",
        "    clear_last()\n",
        "    prompts = []\n",
        "    for file in files:\n",
        "        image = PILImage.open(os.path.join(folder_path, file)).convert('RGB')\n",
        "        prompt = inference(image, mode)\n",
        "        prompts.append(prompt)\n",
        "        page.add_to_image2text(prompt)\n",
        "        #thumb = image.copy()\n",
        "        #thumb.thumbnail([256, 256])\n",
        "        #display(thumb)\n",
        "        #print(prompt)\n",
        "    if image2text_prefs['save_csv']:\n",
        "        if len(prompts):\n",
        "            import csv\n",
        "            csv_path = os.path.join(folder_path, 'img2txt_prompts.csv')\n",
        "            with open(csv_path, 'w', encoding='utf-8', newline='') as f:\n",
        "                w = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
        "                w.writerow(['image', 'prompt'])\n",
        "                for file, prompt in zip(files, prompts):\n",
        "                    w.writerow([file, prompt])\n",
        "\n",
        "            prt(f\"\\n\\n\\nGenerated {len(prompts)} and saved to {csv_path}, enjoy!\")\n",
        "        else:\n",
        "            prt(f\"Sorry, we couldn't find any images in {folder_path}\")\n",
        "    run_process(\"pip uninstall -y git+https://github.com/pharmapsychotic/BLIP.git@lib#egg=blip\", realtime=False)\n",
        "    run_process(\"pip uninstall -y clip-interrogator\", realtime=False)\n",
        "    run_process(\"pip uninstall -y transformers\", realtime=False)\n",
        "    run_process(\"pip install --upgrade transformers\", realtime=False)\n",
        "    clear_last()\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "def run_dance_diffusion(page):\n",
        "    if not status['installed_diffusers']:\n",
        "      alert_msg(page, \"You must Install the HuggingFace Diffusers Library first... \")\n",
        "      return\n",
        "    global dance_pipe, dance_prefs\n",
        "    if dance_prefs['dance_model'] == 'Community':\n",
        "      alert_msg(page, \"Custom Community Checkpoints are not functional yet, working on it so check back later... \")\n",
        "      return\n",
        "    from diffusers import DanceDiffusionPipeline\n",
        "    import scipy.io.wavfile, random\n",
        "    try:\n",
        "      import gdown\n",
        "    except ImportError:\n",
        "      run_sp(\"pip install gdown\")\n",
        "    finally:\n",
        "      import gdown\n",
        "    #import sys\n",
        "    #sys.path.append('drive/gdrive/MyDrive/NotebookDatasets/CMVRLG')\n",
        "    #print(dir(os))\n",
        "    #print(dir(os.path))\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line)\n",
        "      page.dance_output.controls.append(line)\n",
        "      page.dance_output.update()\n",
        "    def clear_last():\n",
        "      del page.dance_output.controls[-1]\n",
        "      page.dance_output.update()\n",
        "    def play_audio(e):\n",
        "      e.control.data.play()\n",
        "    prt(Row([ProgressRing(), Text(\" Downloading Dance Diffusion Models\", weight=FontWeight.BOLD)]))\n",
        "    dance_model_file = f\"harmonai/{dance_prefs['dance_model']}\"\n",
        "    if dance_prefs['dance_model'] == 'Community':\n",
        "      models_path = os.path.join(root_dir, 'models')\n",
        "      os.makedirs(models_path, exist_ok=True)\n",
        "      for c in community_models:\n",
        "        if c['name'] == dance_prefs['community_model']:\n",
        "          community = c\n",
        "      if bool(community['download']):\n",
        "        dance_model_file = os.path.join(models_path, community['ckpt'])\n",
        "        gdown.download(community['download'], dance_model_file, quiet=True)\n",
        "        #run_sp(f'gdown {community['download']} {dance_model_file}')\n",
        "        #run_sp(f\"wget {community['download']} -O {models_path}\")\n",
        "    dance_pipe = DanceDiffusionPipeline.from_pretrained(dance_model_file, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "    dance_pipe = dance_pipe.to(torch_device)\n",
        "    dance_pipe.set_progress_bar_config(disable=True)\n",
        "    random_seed = int(dance_prefs['seed']) if int(dance_prefs['seed']) > 0 else random.randint(0,4294967295)\n",
        "    dance_generator = torch.Generator(device=torch_device).manual_seed(random_seed)\n",
        "    clear_last()\n",
        "    pb.width=page.width - 50\n",
        "    prt(pb)\n",
        "    if prefs['higher_vram_mode']:\n",
        "      output = dance_pipe(generator=dance_generator, batch_size=int(dance_prefs['batch_size']), num_inference_steps=int(dance_prefs['inference_steps']), audio_length_in_s=float(dance_prefs['audio_length_in_s']))\n",
        "    else:\n",
        "      output = dance_pipe(generator=dance_generator, batch_size=int(dance_prefs['batch_size']), num_inference_steps=int(dance_prefs['inference_steps']), audio_length_in_s=float(dance_prefs['audio_length_in_s']), torch_dtype=torch.float16)\n",
        "    #, callback=callback_fn, callback_steps=1)\n",
        "    audio = output.audios\n",
        "    audio_slice = audio[0, -3:, -3:]\n",
        "    clear_last()\n",
        "    #prt(f'audio: {type(audio[0])}, audio_slice: {type(audio_slice)}, len:{len(audio)}')\n",
        "    #audio_slice.tofile(\"/content/dance-test.wav\")\n",
        "    audio_name = f\"dance-{dance_prefs['dance_model']}\" + (f\"-{random_seed}\" if prefs['file_suffix_seed'] else '')\n",
        "    audio_local = os.path.join(root_dir, \"audio_out\")\n",
        "    audio_out = audio_local\n",
        "    os.makedirs(audio_local, exist_ok=True)\n",
        "    if storage_type == \"Colab Google Drive\":\n",
        "      audio_out = prefs['image_output'].rpartition(slash)[0] + slash + 'audio_out'\n",
        "      os.makedirs(audio_out, exist_ok=True)\n",
        "    i = 0\n",
        "    for a in audio:\n",
        "      fname = available_file(audio_local, audio_name, i, ext=\"wav\")\n",
        "      scipy.io.wavfile.write(fname, dance_pipe.unet.sample_rate, a.transpose())\n",
        "      os.path.abspath(fname)\n",
        "      a_out = Audio(src=fname, autoplay=False)\n",
        "      page.overlay.append(a_out)\n",
        "      page.update()\n",
        "      display_name = fname\n",
        "      #a.tofile(f\"/content/dance-{i}.wav\")\n",
        "      if storage_type == \"Colab Google Drive\":\n",
        "        audio_save = available_file(audio_out, audio_name, i, ext='wav')\n",
        "        shutil.copy(fname, audio_save)\n",
        "        display_name = audio_save\n",
        "      prt(Row([IconButton(icon=icons.PLAY_CIRCLE_FILLED, icon_size=48, on_click=play_audio, data=a_out), Text(display_name)]))\n",
        "      i += 1\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "\n",
        "# https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb\n",
        "def run_dreambooth(page):\n",
        "    global dreambooth_prefs, prefs\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line)\n",
        "      page.dreambooth_output.controls.append(line)\n",
        "      page.dreambooth_output.update()\n",
        "    def clear_last():\n",
        "      del page.dreambooth_output.controls[-1]\n",
        "      page.dreambooth_output.update()\n",
        "    if not status['installed_diffusers']:\n",
        "      alert_msg(page, \"You must Install the HuggingFace Diffusers Library first... \")\n",
        "      return\n",
        "    save_path = os.path.join(root_dir, \"my_concept\")\n",
        "    error = False\n",
        "    if not os.path.exists(save_path):\n",
        "      error = True\n",
        "    elif len(os.listdir(save_path)) == 0:\n",
        "      error = True\n",
        "    if len(page.file_list.controls) == 0:\n",
        "      error = True\n",
        "    if error:\n",
        "      alert_msg(page, \"Couldn't find a list of images to train concept. Add image files to the list...\")\n",
        "      return\n",
        "    prt(Row([ProgressRing(), Text(\" Downloading DreamBooth Conceptualizers\", weight=FontWeight.BOLD)]))\n",
        "    run_process(\"pip install -qq bitsandbytes\")\n",
        "    import argparse\n",
        "    import itertools\n",
        "    import math\n",
        "    from contextlib import nullcontext\n",
        "    import random\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import torch.nn.functional as F\n",
        "    import torch.utils.checkpoint\n",
        "    from torch.utils.data import Dataset\n",
        "    from accelerate import Accelerator\n",
        "    from accelerate.logging import get_logger\n",
        "    from accelerate.utils import set_seed\n",
        "    from diffusers import AutoencoderKL, DDPMScheduler, PNDMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
        "    from diffusers.hub_utils import init_git_repo, push_to_hub\n",
        "    from diffusers.optimization import get_scheduler\n",
        "    from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "    \n",
        "    from torchvision import transforms\n",
        "    from tqdm.auto import tqdm\n",
        "    from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "    import bitsandbytes as bnb\n",
        "    import gc\n",
        "    import glob\n",
        "    from io import BytesIO\n",
        "    from PIL import Image as PILImage\n",
        "\n",
        "    def download_image(url):\n",
        "      try:\n",
        "        response = requests.get(url)\n",
        "      except:\n",
        "        return None\n",
        "      return PILImage.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    #images = list(filter(None,[download_image(url) for url in dreambooth_prefs['urls']]))\n",
        "    #save_path = \"./my_concept\"\n",
        "    #if not os.path.exists(save_path):\n",
        "    #  os.mkdir(save_path)\n",
        "    #[image.save(f\"{save_path}/{i}.jpeg\") for i, image in enumerate(images)]\n",
        "    #image_grid(images, 1, len(images))\n",
        "\n",
        "    prior_preservation_class_folder = dreambooth_prefs['prior_preservation_class_folder']\n",
        "    class_data_root=prior_preservation_class_folder\n",
        "    class_prompt=dreambooth_prefs['prior_preservation_class_prompt']\n",
        "    class_data_root=prior_preservation_class_folder\n",
        "    dreambooth_prefs['instance_prompt'] = dreambooth_prefs['instance_prompt'].strip()\n",
        "    clear_txt2img_pipe()\n",
        "    clear_img2img_pipe()\n",
        "    clear_unet_pipe()\n",
        "    clear_clip_guided_pipe()\n",
        "    num_new_images = None\n",
        "    if(dreambooth_prefs['prior_preservation']):\n",
        "        class_images_dir = Path(class_data_root)\n",
        "        if not class_images_dir.exists():\n",
        "            class_images_dir.mkdir(parents=True)\n",
        "        cur_class_images = len(list(class_images_dir.iterdir()))\n",
        "\n",
        "        if cur_class_images < dreambooth_prefs['num_class_images']:\n",
        "            if prefs['higher_vram_mode']:\n",
        "              pipeline = StableDiffusionPipeline.from_pretrained(model_path).to(\"cuda\")\n",
        "            else:\n",
        "              pipeline = StableDiffusionPipeline.from_pretrained(model_path, revision=\"fp16\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "            if prefs['enable_attention_slicing']:\n",
        "              pipeline.enable_attention_slicing()\n",
        "            pipeline.set_progress_bar_config(disable=True)\n",
        "\n",
        "            num_new_images = dreambooth_prefs['num_class_images'] - cur_class_images\n",
        "            print(f\"Number of class images to sample: {num_new_images}.\")\n",
        "\n",
        "            sample_dataset = PromptDataset(class_prompt, num_new_images)\n",
        "            sample_dataloader = torch.utils.data.DataLoader(sample_dataset, batch_size=dreambooth_prefs['sample_batch_size'])\n",
        "\n",
        "            for example in tqdm(sample_dataloader, desc=\"Generating class images\"):\n",
        "                images = pipeline(example[\"prompt\"]).images\n",
        "\n",
        "                for i, image in enumerate(images):\n",
        "                    image.save(class_images_dir / f\"{example['index'][i] + cur_class_images}.jpg\")\n",
        "            pipeline = None\n",
        "            gc.collect()\n",
        "            del pipeline\n",
        "            with torch.no_grad():\n",
        "              torch.cuda.empty_cache()\n",
        "    text_encoder = CLIPTextModel.from_pretrained(model_path, subfolder=\"text_encoder\")\n",
        "    vae = AutoencoderKL.from_pretrained(model_path, subfolder=\"vae\")\n",
        "    unet = UNet2DConditionModel.from_pretrained(model_path, subfolder=\"unet\")\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(model_path,subfolder=\"tokenizer\")\n",
        "    \n",
        "    from argparse import Namespace\n",
        "    dreambooth_args = Namespace(\n",
        "        pretrained_model_name_or_path=model_path,\n",
        "        resolution=dreambooth_prefs['max_size'],\n",
        "        center_crop=True,\n",
        "        instance_data_dir=save_path,\n",
        "        instance_prompt=dreambooth_prefs['instance_prompt'],\n",
        "        learning_rate=dreambooth_prefs['learning_rate'],#5e-06,\n",
        "        max_train_steps=dreambooth_prefs['max_train_steps'],#450,\n",
        "        train_batch_size=1,\n",
        "        gradient_accumulation_steps=2,\n",
        "        max_grad_norm=1.0,\n",
        "        mixed_precision=\"no\", # set to \"fp16\" for mixed-precision training.\n",
        "        gradient_checkpointing=True, # set this to True to lower the memory usage.\n",
        "        use_8bit_adam=not prefs['higher_vram_mode'], # use 8bit optimizer from bitsandbytes\n",
        "        seed=dreambooth_prefs['seed'],#3434554,\n",
        "        with_prior_preservation=dreambooth_prefs['prior_preservation'], \n",
        "        prior_loss_weight=dreambooth_prefs['prior_loss_weight'],\n",
        "        sample_batch_size=dreambooth_prefs['sample_batch_size'],\n",
        "        class_data_dir=dreambooth_prefs['prior_preservation_class_folder'], \n",
        "        class_prompt=class_prompt, \n",
        "        num_class_images=dreambooth_prefs['num_class_images'], \n",
        "        output_dir=\"dreambooth-concept\",\n",
        "    )\n",
        "\n",
        "    from accelerate.utils import set_seed\n",
        "    def training_function(text_encoder, vae, unet):\n",
        "        logger = get_logger(__name__)\n",
        "\n",
        "        accelerator = Accelerator(\n",
        "            gradient_accumulation_steps=dreambooth_args.gradient_accumulation_steps,\n",
        "            mixed_precision=dreambooth_args.mixed_precision,\n",
        "        )\n",
        "\n",
        "        set_seed(dreambooth_args.seed)\n",
        "\n",
        "        if dreambooth_args.gradient_checkpointing:\n",
        "            unet.enable_gradient_checkpointing()\n",
        "\n",
        "        # Use 8-bit Adam for lower memory usage or to fine-tune the model in 16GB GPUs\n",
        "        if dreambooth_args.use_8bit_adam:\n",
        "            optimizer_class = bnb.optim.AdamW8bit\n",
        "        else:\n",
        "            optimizer_class = torch.optim.AdamW\n",
        "\n",
        "        optimizer = optimizer_class(unet.parameters(),lr=dreambooth_args.learning_rate)\n",
        "\n",
        "        noise_scheduler = DDPMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "        \n",
        "        train_dataset = DreamBoothDataset(\n",
        "            instance_data_root=dreambooth_args.instance_data_dir,\n",
        "            instance_prompt=dreambooth_args.instance_prompt,\n",
        "            class_data_root=dreambooth_args.class_data_dir if dreambooth_args.with_prior_preservation else None,\n",
        "            class_prompt=dreambooth_args.class_prompt,\n",
        "            tokenizer=tokenizer,\n",
        "            size=dreambooth_args.resolution,\n",
        "            center_crop=dreambooth_args.center_crop,\n",
        "        )\n",
        "\n",
        "        def collate_fn(examples):\n",
        "            input_ids = [example[\"instance_prompt_ids\"] for example in examples]\n",
        "            pixel_values = [example[\"instance_images\"] for example in examples]\n",
        "\n",
        "            # concat class and instance examples for prior preservation\n",
        "            if dreambooth_args.with_prior_preservation:\n",
        "                input_ids += [example[\"class_prompt_ids\"] for example in examples]\n",
        "                pixel_values += [example[\"class_images\"] for example in examples]\n",
        "\n",
        "            pixel_values = torch.stack(pixel_values)\n",
        "            pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
        "\n",
        "            input_ids = tokenizer.pad({\"input_ids\": input_ids}, padding=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "            batch = {\n",
        "                \"input_ids\": input_ids,\n",
        "                \"pixel_values\": pixel_values,\n",
        "            }\n",
        "            return batch\n",
        "        \n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=dreambooth_args.train_batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "        unet, optimizer, train_dataloader = accelerator.prepare(unet, optimizer, train_dataloader)\n",
        "\n",
        "        # Move text_encode and vae to gpu\n",
        "        text_encoder.to(accelerator.device)\n",
        "        vae.to(accelerator.device)\n",
        "\n",
        "        # We need to recalculate our total training steps as the size of the training dataloader may have changed.\n",
        "        num_update_steps_per_epoch = math.ceil(len(train_dataloader) / dreambooth_args.gradient_accumulation_steps)\n",
        "        num_train_epochs = math.ceil(dreambooth_args.max_train_steps / num_update_steps_per_epoch)\n",
        "        clear_last()\n",
        "        total_batch_size = dreambooth_args.train_batch_size * accelerator.num_processes * dreambooth_args.gradient_accumulation_steps\n",
        "\n",
        "        prt(\"***** Running training *****\")\n",
        "        prt(f\"  Number of examples = {len(train_dataset)}\")\n",
        "        if num_new_images != None: prt(f\"  Number of class images to sample: {num_new_images}.\")\n",
        "        prt(f\"  Instantaneous batch size per device = {dreambooth_args.train_batch_size}\")\n",
        "        prt(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
        "        prt(f\"  Gradient Accumulation steps = {dreambooth_args.gradient_accumulation_steps}\")\n",
        "        prt(f\"  Total optimization steps = {dreambooth_args.max_train_steps}\")\n",
        "        progress = ProgressBar(bar_height=8)\n",
        "        prt(progress)\n",
        "        progress_bar = tqdm(range(dreambooth_args.max_train_steps), disable=not accelerator.is_local_main_process)\n",
        "        progress_bar.set_description(\"Steps\")\n",
        "        global_step = 0\n",
        "\n",
        "        for epoch in range(num_train_epochs):\n",
        "            unet.train()\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                with accelerator.accumulate(unet):\n",
        "                    # Convert images to latent space\n",
        "                    with torch.no_grad():\n",
        "                        latents = vae.encode(batch[\"pixel_values\"]).latent_dist.sample()\n",
        "                        latents = latents * 0.18215\n",
        "\n",
        "                    # Sample noise that we'll add to the latents\n",
        "                    noise = torch.randn(latents.shape).to(latents.device)\n",
        "                    bsz = latents.shape[0]\n",
        "                    # Sample a random timestep for each image\n",
        "                    timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device).long()\n",
        "\n",
        "                    # Add noise to the latents according to the noise magnitude at each timestep\n",
        "                    # (this is the forward diffusion process)\n",
        "                    noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
        "\n",
        "                    # Get the text embedding for conditioning\n",
        "                    with torch.no_grad():\n",
        "                        encoder_hidden_states = text_encoder(batch[\"input_ids\"])[0]\n",
        "\n",
        "                    # Predict the noise residual\n",
        "                    noise_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
        "\n",
        "                    if dreambooth_args.with_prior_preservation:\n",
        "                        # Chunk the noise and noise_pred into two parts and compute the loss on each part separately.\n",
        "                        noise_pred, noise_pred_prior = torch.chunk(noise_pred, 2, dim=0)\n",
        "                        noise, noise_prior = torch.chunk(noise, 2, dim=0)\n",
        "\n",
        "                        # Compute instance loss\n",
        "                        loss = F.mse_loss(noise_pred, noise, reduction=\"none\").mean([1, 2, 3]).mean()\n",
        "\n",
        "                        # Compute prior loss\n",
        "                        prior_loss = F.mse_loss(noise_pred_prior, noise_prior, reduction=\"none\").mean([1, 2, 3]).mean()\n",
        "\n",
        "                        # Add the prior loss to the instance loss.\n",
        "                        loss = loss + dreambooth_args.prior_loss_weight * prior_loss\n",
        "                    else:\n",
        "                        loss = F.mse_loss(noise_pred, noise, reduction=\"none\").mean([1, 2, 3]).mean()\n",
        "\n",
        "                    accelerator.backward(loss)\n",
        "                    if accelerator.sync_gradients:\n",
        "                        accelerator.clip_grad_norm_(unet.parameters(), dreambooth_args.max_grad_norm)\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                # Checks if the accelerator has performed an optimization step behind the scenes\n",
        "                if accelerator.sync_gradients:\n",
        "                    progress_bar.update(1)\n",
        "                    global_step += 1\n",
        "\n",
        "                logs = {\"loss\": loss.detach().item()}\n",
        "                progress_bar.set_postfix(**logs)\n",
        "                progress.value = (global_step + 1) / dreambooth_args.max_train_steps\n",
        "                progress.tooltip = f'[{(global_step + 1)} / {dreambooth_args.max_train_steps}]'\n",
        "                progress.update()\n",
        "\n",
        "                if global_step >= dreambooth_args.max_train_steps:\n",
        "                    break\n",
        "\n",
        "            accelerator.wait_for_everyone()\n",
        "        \n",
        "        # Create the pipeline using the trained modules and save it.\n",
        "        if accelerator.is_main_process:\n",
        "            pipeline = StableDiffusionPipeline(\n",
        "                text_encoder=text_encoder,\n",
        "                vae=vae,\n",
        "                unet=accelerator.unwrap_model(unet),\n",
        "                tokenizer=tokenizer,\n",
        "                scheduler=PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True),\n",
        "                safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"),\n",
        "                feature_extractor=CLIPFeatureExtractor.from_pretrained(\"openai/clip-vit-base-patch32\"),\n",
        "            )\n",
        "            pipeline.save_pretrained(dreambooth_args.output_dir)\n",
        "    \n",
        "    import accelerate\n",
        "    try:\n",
        "      accelerate.notebook_launcher(training_function, args=(text_encoder, vae, unet))\n",
        "    except Exception as e:\n",
        "      clear_last()\n",
        "      alert_msg(page, \"ERROR: CUDA Ran Out of Memory. Try reducing parameters and try again...\", content=Text(str(e)))\n",
        "      with torch.no_grad():\n",
        "        torch.cuda.empty_cache()\n",
        "      return\n",
        "    clear_last()\n",
        "    with torch.no_grad():\n",
        "        torch.cuda.empty_cache()\n",
        "    name_of_your_concept = dreambooth_prefs['name_of_your_concept']\n",
        "    if(dreambooth_prefs['save_concept']):\n",
        "      from slugify import slugify\n",
        "      from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "      from huggingface_hub import create_repo\n",
        "      from IPython.display import display_markdown\n",
        "      api = HfApi()\n",
        "      your_username = api.whoami()[\"name\"]\n",
        "      dreambooth_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        dreambooth_args.output_dir,\n",
        "        torch_dtype=torch.float16,\n",
        "      ).to(\"cuda\")\n",
        "      os.makedirs(\"fp16_model\",exist_ok=True)\n",
        "      dreambooth_pipe.save_pretrained(\"fp16_model\")\n",
        "\n",
        "      if(dreambooth_prefs['where_to_save_concept'] == \"Public Library\"):\n",
        "        repo_id = f\"sd-dreambooth-library/{slugify(name_of_your_concept)}\"\n",
        "        #Join the Concepts Library organization if you aren't part of it already\n",
        "        run_sp(f\"curl -X POST -H 'Authorization: Bearer '{hf_token} -H 'Content-Type: application/json' https://huggingface.co/organizations/sd-dreambooth-library/share/SSeOwppVCscfTEzFGQaqpfcjukVeNrKNHX\", realtime=False)\n",
        "        #!curl -X POST -H 'Authorization: Bearer '$hf_token -H 'Content-Type: application/json' https://huggingface.co/organizations/sd-dreambooth-library/share/SSeOwppVCscfTEzFGQaqpfcjukVeNrKNHX\n",
        "      else:\n",
        "        repo_id = f\"{your_username}/{slugify(name_of_your_concept)}\"\n",
        "      output_dir = dreambooth_args.output_dir\n",
        "      if(not prefs['HuggingFace_api_key']):\n",
        "        with open(HfFolder.path_token, 'r') as fin: hf_token = fin.read();\n",
        "      else:\n",
        "        hf_token = prefs['HuggingFace_api_key'] \n",
        "      \n",
        "      images_upload = os.listdir(save_path)\n",
        "      image_string = \"\"\n",
        "      #repo_id = f\"sd-dreambooth-library/{slugify(name_of_your_concept)}\"\n",
        "      for i, image in enumerate(images_upload):\n",
        "          image_string = f'''{image_string}![image {i}](https://huggingface.co/{repo_id}/resolve/main/concept_images/{image})\n",
        "    '''\n",
        "      description = dreambooth_prefs['readme_description']\n",
        "      if bool(description.strip()):\n",
        "        description = dreambooth_prefs['readme_description'] + '\\n\\n'\n",
        "      readme_text = f'''---\n",
        "    license: mit\n",
        "    ---\n",
        "    ### {name_of_your_concept} on Stable Diffusion via Dreambooth using [Stable Diffusion Deluxe](https://colab.research.google.com/github/Skquark/AI-Friends/blob/main/Stable_Diffusion_Deluxe.ipynb)\n",
        "    #### model by {api.whoami()[\"name\"]}\n",
        "    This your the Stable Diffusion model fine-tuned the {name_of_your_concept} concept taught to Stable Diffusion with Dreambooth.\n",
        "    It can be used by modifying the `instance_prompt`: **{dreambooth_prefs['instance_prompt']}**\n",
        "\n",
        "    {description}You can also train your own concepts and upload them to the library by using [this notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb).\n",
        "    And you can run your new concept via `diffusers`: [Colab Notebook for Inference](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_inference.ipynb), [Spaces with the Public Concepts loaded](https://huggingface.co/spaces/sd-dreambooth-library/stable-diffusion-dreambooth-concepts)\n",
        "\n",
        "    Here are the images used for training this concept:\n",
        "    {image_string}\n",
        "    '''\n",
        "      #Save the readme to a file\n",
        "      readme_file = open(\"README.md\", \"w\")\n",
        "      readme_file.write(readme_text)\n",
        "      readme_file.close()\n",
        "      #Save the token identifier to a file\n",
        "      text_file = open(\"token_identifier.txt\", \"w\")\n",
        "      text_file.write(dreambooth_prefs['instance_prompt'])\n",
        "      text_file.close()\n",
        "      operations = [\n",
        "        CommitOperationAdd(path_in_repo=\"token_identifier.txt\", path_or_fileobj=\"token_identifier.txt\"),\n",
        "        CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\"),\n",
        "      ]\n",
        "      create_repo(repo_id,private=True, token=hf_token)\n",
        "      \n",
        "      api.create_commit(repo_id=repo_id, operations=operations, commit_message=f\"Upload the concept {name_of_your_concept} embeds and token\",token=hf_token)\n",
        "      api.upload_folder(folder_path=\"fp16_model\", path_in_repo=\"\", repo_id=repo_id,token=hf_token)\n",
        "      api.upload_folder(folder_path=save_path, path_in_repo=\"concept_images\", repo_id=repo_id, token=hf_token)\n",
        "      prefs['custom_model'] = repo_id\n",
        "      prt(Markdown(f\"## Your concept was saved successfully to _{repo_id}_.<br>[Click here to access it](https://huggingface.co/{repo_id} and go to _Installers->Model Checkpoint->Custom Model Path_ to use. Include Token in prompts.\"))\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "try:\n",
        "    from torchvision import transforms\n",
        "except Exception:\n",
        "    run_sp(\"pip install torchvision\", realtime=False)\n",
        "    from torchvision import transforms\n",
        "    pass\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DreamBoothDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        instance_data_root,\n",
        "        instance_prompt,\n",
        "        tokenizer,\n",
        "        class_data_root=None,\n",
        "        class_prompt=None,\n",
        "        size=dreambooth_prefs['max_size'],\n",
        "        center_crop=False,\n",
        "    ):\n",
        "        self.size = size\n",
        "        self.center_crop = center_crop\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.instance_data_root = Path(instance_data_root)\n",
        "        if not self.instance_data_root.exists():\n",
        "            raise ValueError(\"Instance images root doesn't exists.\")\n",
        "\n",
        "        self.instance_images_path = list(Path(instance_data_root).iterdir())\n",
        "        self.num_instance_images = len(self.instance_images_path)\n",
        "        self.instance_prompt = instance_prompt\n",
        "        self._length = self.num_instance_images\n",
        "\n",
        "        if class_data_root is not None:\n",
        "            self.class_data_root = Path(class_data_root)\n",
        "            self.class_data_root.mkdir(parents=True, exist_ok=True)\n",
        "            self.class_images_path = list(Path(class_data_root).iterdir())\n",
        "            self.num_class_images = len(self.class_images_path)\n",
        "            self._length = max(self.num_class_images, self.num_instance_images)\n",
        "            self.class_prompt = class_prompt\n",
        "        else:\n",
        "            self.class_data_root = None\n",
        "\n",
        "        self.image_transforms = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "                transforms.CenterCrop(size) if center_crop else transforms.RandomCrop(size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.5], [0.5]),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        from PIL import Image as PILImage\n",
        "        example = {}\n",
        "        instance_image = PILImage.open(self.instance_images_path[index % self.num_instance_images])\n",
        "        if not instance_image.mode == \"RGB\":\n",
        "            instance_image = instance_image.convert(\"RGB\")\n",
        "        example[\"instance_images\"] = self.image_transforms(instance_image)\n",
        "        example[\"instance_prompt_ids\"] = self.tokenizer(\n",
        "            self.instance_prompt,\n",
        "            padding=\"do_not_pad\",\n",
        "            truncation=True,\n",
        "            max_length=self.tokenizer.model_max_length,\n",
        "        ).input_ids\n",
        "\n",
        "        if self.class_data_root:\n",
        "            class_image = PILImage.open(self.class_images_path[index % self.num_class_images])\n",
        "            if not class_image.mode == \"RGB\":\n",
        "                class_image = class_image.convert(\"RGB\")\n",
        "            example[\"class_images\"] = self.image_transforms(class_image)\n",
        "            example[\"class_prompt_ids\"] = self.tokenizer(\n",
        "                self.class_prompt,\n",
        "                padding=\"do_not_pad\",\n",
        "                truncation=True,\n",
        "                max_length=self.tokenizer.model_max_length,\n",
        "            ).input_ids\n",
        "        \n",
        "        return example\n",
        "\n",
        "class PromptDataset(Dataset):\n",
        "    def __init__(self, prompt, num_samples):\n",
        "        self.prompt = prompt\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        example = {}\n",
        "        example[\"prompt\"] = self.prompt\n",
        "        example[\"index\"] = index\n",
        "        return example\n",
        "\n",
        "\n",
        "def run_textualinversion(page):\n",
        "    global textualinversion_prefs, prefs\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line)\n",
        "      page.textualinversion_output.controls.append(line)\n",
        "      page.textualinversion_output.update()\n",
        "    def clear_last():\n",
        "      del page.textualinversion_output.controls[-1]\n",
        "      page.textualinversion_output.update()\n",
        "    if not status['installed_diffusers']:\n",
        "      alert_msg(page, \"You must Install the HuggingFace Diffusers Library first... \")\n",
        "      return\n",
        "    save_path = os.path.join(root_dir, \"my_concept\")\n",
        "    error = False\n",
        "    if not os.path.exists(save_path):\n",
        "      error = True\n",
        "    elif len(os.listdir(save_path)) == 0:\n",
        "      error = True\n",
        "    if len(page.file_list.controls) == 0:\n",
        "      error = True\n",
        "    if error:\n",
        "      alert_msg(page, \"Couldn't find a list of images to train concept. Add image files to the list...\")\n",
        "      return\n",
        "    prt(Row([ProgressRing(), Text(\" Downloading Textual-Inversion Training Models\", weight=FontWeight.BOLD)]))\n",
        "    #run_process(\"pip install -qq bitsandbytes\")\n",
        "    import argparse\n",
        "    import itertools\n",
        "    import math\n",
        "    import random\n",
        "\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import torch.nn.functional as F\n",
        "    import torch.utils.checkpoint\n",
        "    from torch.utils.data import Dataset\n",
        "    from accelerate import Accelerator\n",
        "    from accelerate.logging import get_logger\n",
        "    from accelerate.utils import set_seed\n",
        "    from diffusers import AutoencoderKL, DDPMScheduler, PNDMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
        "    from diffusers.hub_utils import init_git_repo, push_to_hub\n",
        "    from diffusers.optimization import get_scheduler\n",
        "    from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "    from torchvision import transforms\n",
        "    from tqdm.auto import tqdm\n",
        "    from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "\n",
        "    imagenet_templates_small = [\n",
        "        \"a photo of a {}\",\n",
        "        \"a rendering of a {}\",\n",
        "        \"a cropped photo of the {}\",\n",
        "        \"the photo of a {}\",\n",
        "        \"a photo of a clean {}\",\n",
        "        \"a photo of a dirty {}\",\n",
        "        \"a dark photo of the {}\",\n",
        "        \"a photo of my {}\",\n",
        "        \"a photo of the cool {}\",\n",
        "        \"a close-up photo of a {}\",\n",
        "        \"a bright photo of the {}\",\n",
        "        \"a cropped photo of a {}\",\n",
        "        \"a photo of the {}\",\n",
        "        \"a good photo of the {}\",\n",
        "        \"a photo of one {}\",\n",
        "        \"a close-up photo of the {}\",\n",
        "        \"a rendition of the {}\",\n",
        "        \"a photo of the clean {}\",\n",
        "        \"a rendition of a {}\",\n",
        "        \"a photo of a nice {}\",\n",
        "        \"a good photo of a {}\",\n",
        "        \"a photo of the nice {}\",\n",
        "        \"a photo of the small {}\",\n",
        "        \"a photo of the weird {}\",\n",
        "        \"a photo of the large {}\",\n",
        "        \"a photo of a cool {}\",\n",
        "        \"a photo of a small {}\",\n",
        "    ]\n",
        "\n",
        "    imagenet_style_templates_small = [\n",
        "        \"a painting in the style of {}\",\n",
        "        \"a rendering in the style of {}\",\n",
        "        \"a cropped painting in the style of {}\",\n",
        "        \"the painting in the style of {}\",\n",
        "        \"a clean painting in the style of {}\",\n",
        "        \"a dirty painting in the style of {}\",\n",
        "        \"a dark painting in the style of {}\",\n",
        "        \"a picture in the style of {}\",\n",
        "        \"a cool painting in the style of {}\",\n",
        "        \"a close-up painting in the style of {}\",\n",
        "        \"a bright painting in the style of {}\",\n",
        "        \"a cropped painting in the style of {}\",\n",
        "        \"a good painting in the style of {}\",\n",
        "        \"a close-up painting in the style of {}\",\n",
        "        \"a rendition in the style of {}\",\n",
        "        \"a nice painting in the style of {}\",\n",
        "        \"a small painting in the style of {}\",\n",
        "        \"a weird painting in the style of {}\",\n",
        "        \"a large painting in the style of {}\",\n",
        "    ]\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(\n",
        "        model_path,\n",
        "        subfolder=\"tokenizer\",\n",
        "    )\n",
        "    placeholder_token = textualinversion_prefs['placeholder_token'].strip()\n",
        "    if not placeholder_token.startswith('<'): placeholder_token = '<' + placeholder_token\n",
        "    if not placeholder_token.endswith('>'): placeholder_token = placeholder_token + '>'\n",
        "    # Add the placeholder token in tokenizer\n",
        "    num_added_tokens = tokenizer.add_tokens(placeholder_token)\n",
        "    if num_added_tokens == 0:\n",
        "        raise ValueError(\n",
        "            f\"The tokenizer already contains the token {placeholder_token}. Please pass a different\"\n",
        "            \" `placeholder_token` that is not already in the tokenizer.\"\n",
        "        )\n",
        "\n",
        "    token_ids = tokenizer.encode(textualinversion_prefs['initializer_token'], add_special_tokens=False)\n",
        "    # Check if initializer_token is a single token or a sequence of tokens\n",
        "    if len(token_ids) > 1:\n",
        "        raise ValueError(\"The initializer token must be a single token.\")\n",
        "\n",
        "    initializer_token_id = token_ids[0]\n",
        "    placeholder_token_id = tokenizer.convert_tokens_to_ids(placeholder_token)\n",
        "\n",
        "    # Load the Stable Diffusion model\n",
        "    # Load models and create wrapper for stable diffusion\n",
        "    text_encoder = CLIPTextModel.from_pretrained(\n",
        "        model_path, subfolder=\"text_encoder\"\n",
        "    )\n",
        "    vae = AutoencoderKL.from_pretrained(\n",
        "        model_path, subfolder=\"vae\"\n",
        "    )\n",
        "    unet = UNet2DConditionModel.from_pretrained(\n",
        "        model_path, subfolder=\"unet\"\n",
        "    )\n",
        "\n",
        "    text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "    token_embeds = text_encoder.get_input_embeddings().weight.data\n",
        "    token_embeds[placeholder_token_id] = token_embeds[initializer_token_id]\n",
        "\n",
        "    def freeze_params(params):\n",
        "        for param in params:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Freeze vae and unet\n",
        "    freeze_params(vae.parameters())\n",
        "    freeze_params(unet.parameters())\n",
        "    # Freeze all parameters except for the token embeddings in text encoder\n",
        "    params_to_freeze = itertools.chain(\n",
        "        text_encoder.text_model.encoder.parameters(),\n",
        "        text_encoder.text_model.final_layer_norm.parameters(),\n",
        "        text_encoder.text_model.embeddings.position_embedding.parameters(),\n",
        "    )\n",
        "    freeze_params(params_to_freeze)\n",
        "    train_dataset = TextualInversionDataset(\n",
        "        data_root=save_path,\n",
        "        tokenizer=tokenizer,\n",
        "        size=512,\n",
        "        placeholder_token=placeholder_token,\n",
        "        repeats=100,\n",
        "        learnable_property=textualinversion_prefs['what_to_teach'], #Option selected above between object and style\n",
        "        center_crop=False,\n",
        "        set=\"train\",\n",
        "    )\n",
        "    def create_dataloader(train_batch_size=1):\n",
        "        return torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "    noise_scheduler = DDPMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000, tensor_format=\"pt\")\n",
        "    def training_function(text_encoder, vae, unet):\n",
        "        logger = get_logger(__name__)\n",
        "\n",
        "        train_batch_size = textualinversion_prefs[\"train_batch_size\"]\n",
        "        gradient_accumulation_steps = textualinversion_prefs[\"gradient_accumulation_steps\"]\n",
        "        learning_rate = textualinversion_prefs[\"learning_rate\"]\n",
        "        max_train_steps = textualinversion_prefs[\"max_train_steps\"]\n",
        "        output_dir = textualinversion_prefs[\"output_dir\"]\n",
        "        accelerator = Accelerator(gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "        train_dataloader = create_dataloader(train_batch_size)\n",
        "        if textualinversion_prefs[\"scale_lr\"]:\n",
        "            learning_rate = (learning_rate * gradient_accumulation_steps * train_batch_size * accelerator.num_processes)\n",
        "        # Initialize the optimizer\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            text_encoder.get_input_embeddings().parameters(),  # only optimize the embeddings\n",
        "            lr=learning_rate,\n",
        "        )\n",
        "        text_encoder, optimizer, train_dataloader = accelerator.prepare(text_encoder, optimizer, train_dataloader)\n",
        "        vae.to(accelerator.device)\n",
        "        unet.to(accelerator.device)\n",
        "        vae.eval()\n",
        "        unet.eval()\n",
        "        # We need to recalculate our total training steps as the size of the training dataloader may have changed.\n",
        "        num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
        "        num_train_epochs = math.ceil(max_train_steps / num_update_steps_per_epoch)\n",
        "        clear_last()\n",
        "        # Train!\n",
        "        total_batch_size = train_batch_size * accelerator.num_processes * gradient_accumulation_steps\n",
        "\n",
        "        prt(\"***** Running training *****\")\n",
        "        prt(f\"  Num examples = {len(train_dataset)}\")\n",
        "        prt(f\"  Instantaneous batch size per device = {train_batch_size}\")\n",
        "        prt(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
        "        prt(f\"  Gradient Accumulation steps = {gradient_accumulation_steps}\")\n",
        "        prt(f\"  Total optimization steps = {max_train_steps}\")\n",
        "        progress = ProgressBar(bar_height=8)\n",
        "        prt(progress)\n",
        "        progress_bar = tqdm(range(max_train_steps), disable=not accelerator.is_local_main_process)\n",
        "        progress_bar.set_description(\"Steps\")\n",
        "        global_step = 0\n",
        "\n",
        "        for epoch in range(num_train_epochs):\n",
        "            text_encoder.train()\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                with accelerator.accumulate(text_encoder):\n",
        "                    # Convert images to latent space\n",
        "                    latents = vae.encode(batch[\"pixel_values\"]).latent_dist.sample().detach()\n",
        "                    latents = latents * 0.18215\n",
        "\n",
        "                    # Sample noise that we'll add to the latents\n",
        "                    noise = torch.randn(latents.shape).to(latents.device)\n",
        "                    bsz = latents.shape[0]\n",
        "                    # Sample a random timestep for each image\n",
        "                    timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bsz,), device=latents.device).long()\n",
        "\n",
        "                    # Add noise to the latents according to the noise magnitude at each timestep\n",
        "                    # (this is the forward diffusion process)\n",
        "                    noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
        "\n",
        "                    # Get the text embedding for conditioning\n",
        "                    encoder_hidden_states = text_encoder(batch[\"input_ids\"])[0]\n",
        "\n",
        "                    # Predict the noise residual\n",
        "                    noise_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
        "\n",
        "                    loss = F.mse_loss(noise_pred, noise, reduction=\"none\").mean([1, 2, 3]).mean()\n",
        "                    accelerator.backward(loss)\n",
        "\n",
        "                    # Zero out the gradients for all token embeddings except the newly added\n",
        "                    # embeddings for the concept, as we only want to optimize the concept embeddings\n",
        "                    if accelerator.num_processes > 1:\n",
        "                        grads = text_encoder.module.get_input_embeddings().weight.grad\n",
        "                    else:\n",
        "                        grads = text_encoder.get_input_embeddings().weight.grad\n",
        "                    # Get the index for tokens that we want to zero the grads for\n",
        "                    index_grads_to_zero = torch.arange(len(tokenizer)) != placeholder_token_id\n",
        "                    grads.data[index_grads_to_zero, :] = grads.data[index_grads_to_zero, :].fill_(0)\n",
        "\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                # Checks if the accelerator has performed an optimization step behind the scenes\n",
        "                if accelerator.sync_gradients:\n",
        "                    progress_bar.update(1)\n",
        "                    global_step += 1\n",
        "                    progress.value = (global_step + 1) / max_train_steps\n",
        "                    progress.tooltip = f'[{(global_step + 1)} / {max_train_steps}]'\n",
        "                    progress.update()\n",
        "\n",
        "                logs = {\"loss\": loss.detach().item()}\n",
        "                progress_bar.set_postfix(**logs)\n",
        "\n",
        "                if global_step >= max_train_steps:\n",
        "                    break\n",
        "\n",
        "            accelerator.wait_for_everyone()\n",
        "\n",
        "\n",
        "        # Create the pipeline using using the trained modules and save it.\n",
        "        if accelerator.is_main_process:\n",
        "            pipeline = StableDiffusionPipeline(\n",
        "                text_encoder=accelerator.unwrap_model(text_encoder),\n",
        "                vae=vae,\n",
        "                unet=unet,\n",
        "                tokenizer=tokenizer,\n",
        "                scheduler=PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True),\n",
        "                safety_checker=None if prefs['disable_nsfw_filter'] else StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"),\n",
        "                feature_extractor=CLIPFeatureExtractor.from_pretrained(\"openai/clip-vit-base-patch32\"),\n",
        "            )\n",
        "            pipeline.save_pretrained(output_dir)\n",
        "            # Also save the newly trained embeddings\n",
        "            learned_embeds = accelerator.unwrap_model(text_encoder).get_input_embeddings().weight[placeholder_token_id]\n",
        "            learned_embeds_dict = {placeholder_token: learned_embeds.detach().cpu()}\n",
        "            torch.save(learned_embeds_dict, os.path.join(output_dir, \"learned_embeds.bin\"))\n",
        "    \n",
        "    import accelerate\n",
        "    try:\n",
        "        accelerate.notebook_launcher(training_function, args=(text_encoder, vae, unet))\n",
        "    except Exception as e:\n",
        "      clear_last()\n",
        "      alert_msg(page, \"ERROR: CUDA Ran Out of Memory. Try reducing parameters and try again...\", content=Text(str(e)))\n",
        "      with torch.no_grad():\n",
        "        torch.cuda.empty_cache()\n",
        "      return\n",
        "    clear_last()\n",
        "    #title Save your newly created concept to the [library of concepts](https://huggingface.co/sd-concepts-library)?\n",
        "    save_concept_to_public_library = textualinversion_prefs['save_concept']\n",
        "    name_of_your_concept = textualinversion_prefs['name_of_your_concept']\n",
        "    # `hf_token_write`: leave blank if you logged in with a token with `write access` in the [Initial Setup](#scrollTo=KbzZ9xe6dWwf). If not, [go to your tokens settings and create a write access token](https://huggingface.co/settings/tokens)\n",
        "    hf_token_write = prefs['HuggingFace_api_key']\n",
        "\n",
        "    if(save_concept_to_public_library):\n",
        "        from slugify import slugify\n",
        "        from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "        from huggingface_hub import create_repo\n",
        "        api = HfApi()\n",
        "        your_username = api.whoami()[\"name\"]\n",
        "        repo_id = f\"sd-concepts-library/{slugify(name_of_your_concept)}\"\n",
        "        output_dir = textualinversion_prefs[\"output_dir\"]\n",
        "        if(not hf_token_write):\n",
        "            with open(HfFolder.path_token, 'r') as fin: hf_token = fin.read();\n",
        "        else:\n",
        "            hf_token = hf_token_write\n",
        "        if(textualinversion_prefs['where_to_save_concept'] == \"Public Library\"):\n",
        "            #Join the Concepts Library organization if you aren't part of it already\n",
        "            run_sp(f\"curl -X POST -H 'Authorization: Bearer '{hf_token} -H 'Content-Type: application/json' https://huggingface.co/organizations/sd-concepts-library/share/VcLXJtzwwxnHYCkNMLpSJCdnNFZHQwWywv\", realtime=False)\n",
        "            # curl -X POST -H 'Authorization: Bearer '$hf_token -H 'Content-Type: application/json' https://huggingface.co/organizations/sd-concepts-library/share/VcLXJtzwwxnHYCkNMLpSJCdnNFZHQwWywv\n",
        "        else:\n",
        "            repo_id = f\"{your_username}/{slugify(name_of_your_concept)}\"\n",
        "        images_upload = os.listdir(\"my_concept\")\n",
        "        image_string = \"\"\n",
        "        repo_id = f\"sd-concepts-library/{slugify(name_of_your_concept)}\"\n",
        "        for i, image in enumerate(images_upload):\n",
        "            image_string = f'''{image_string}![{placeholder_token} {i}](https://huggingface.co/{repo_id}/resolve/main/concept_images/{image})\n",
        "        '''\n",
        "        if(textualinversion_prefs['what_to_teach'] == \"style\"):\n",
        "            what_to_teach_article = f\"a `{textualinversion_prefs['what_to_teach']}`\"\n",
        "        else:\n",
        "            what_to_teach_article = f\"an `{textualinversion_prefs['what_to_teach']}`\"\n",
        "        description = textualinversion_prefs['readme_description']\n",
        "        if bool(description.strip()):\n",
        "            description = textualinversion_prefs['readme_description'] + '\\n\\n'\n",
        "        readme_text = f'''---\n",
        "        license: mit\n",
        "        ---\n",
        "        ### {name_of_your_concept} by {your_username} using [Stable Diffusion Deluxe](https://colab.research.google.com/github/Skquark/AI-Friends/blob/main/Stable_Diffusion_Deluxe.ipynb)\n",
        "        This is the `{placeholder_token}` concept taught to Stable Diffusion via Textual Inversion. You can load this concept into the [Stable Diffusion Deluxe](https://colab.research.google.com/github/Skquark/AI-Friends/blob/main/Stable_Diffusion_Deluxe.ipynb) notebook. You can also train your own concepts and load them into the concept libraries there too, or using [this notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_textual_inversion_training.ipynb).\n",
        "    \n",
        "        {description}Here is the new concept you will be able to use as {what_to_teach_article}:\n",
        "        {image_string}\n",
        "        '''\n",
        "        #Save the readme to a file\n",
        "        readme_file = open(\"README.md\", \"w\")\n",
        "        readme_file.write(readme_text)\n",
        "        readme_file.close()\n",
        "        #Save the token identifier to a file\n",
        "        text_file = open(\"token_identifier.txt\", \"w\")\n",
        "        text_file.write(placeholder_token)\n",
        "        text_file.close()\n",
        "        #Save the type of teached thing to a file\n",
        "        type_file = open(\"type_of_concept.txt\",\"w\")\n",
        "        type_file.write(textualinversion_prefs['what_to_teach'])\n",
        "        type_file.close()\n",
        "        operations = [\n",
        "            CommitOperationAdd(path_in_repo=\"learned_embeds.bin\", path_or_fileobj=f\"{output_dir}/learned_embeds.bin\"),\n",
        "            CommitOperationAdd(path_in_repo=\"token_identifier.txt\", path_or_fileobj=\"token_identifier.txt\"),\n",
        "            CommitOperationAdd(path_in_repo=\"type_of_concept.txt\", path_or_fileobj=\"type_of_concept.txt\"),\n",
        "            CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\"),\n",
        "        ]\n",
        "        create_repo(repo_id,private=True, token=hf_token)\n",
        "        api = HfApi()\n",
        "        api.create_commit(\n",
        "            repo_id=repo_id,\n",
        "            operations=operations,\n",
        "            commit_message=f\"Upload the concept {name_of_your_concept} embeds and token\",\n",
        "            token=hf_token\n",
        "        )\n",
        "        api.upload_folder(\n",
        "            folder_path=save_path,\n",
        "            path_in_repo=\"concept_images\",\n",
        "            repo_id=repo_id,\n",
        "            token=hf_token\n",
        "        )\n",
        "        prefs['custom_model'] = repo_id\n",
        "        prt(Markdown(f\"## Your concept was saved successfully to _{repo_id}_.<br>[Click here to access it](https://huggingface.co/{repo_id} and go to _Installers->Model Checkpoint->Custom Model Path_ to use. Include Token to your Prompt text.\"))\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "class TextualInversionDataset(Dataset):\n",
        "    import random as rnd\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_root,\n",
        "        tokenizer,\n",
        "        learnable_property=\"object\",  # [object, style]\n",
        "        size=textualinversion_prefs['max_size'],\n",
        "        repeats=100,\n",
        "        interpolation=\"bicubic\",\n",
        "        flip_p=0.5,\n",
        "        set=\"train\",\n",
        "        placeholder_token=\"*\",\n",
        "        center_crop=False,\n",
        "    ):\n",
        "        self.data_root = data_root\n",
        "        self.tokenizer = tokenizer\n",
        "        self.learnable_property = learnable_property\n",
        "        self.size = size\n",
        "        self.placeholder_token = placeholder_token\n",
        "        self.center_crop = center_crop\n",
        "        self.flip_p = flip_p\n",
        "        self.image_paths = [os.path.join(self.data_root, file_path) for file_path in os.listdir(self.data_root)]\n",
        "        self.num_images = len(self.image_paths)\n",
        "        self._length = self.num_images\n",
        "        if set == \"train\":\n",
        "            self._length = self.num_images * repeats\n",
        "        self.interpolation = {\n",
        "            \"linear\": PIL.Image.LINEAR,\n",
        "            \"bilinear\": PIL.Image.BILINEAR,\n",
        "            \"bicubic\": PIL.Image.BICUBIC,\n",
        "            \"lanczos\": PIL.Image.LANCZOS,\n",
        "        }[interpolation]\n",
        "        self.templates = imagenet_style_templates_small if learnable_property == \"style\" else imagenet_templates_small\n",
        "        self.flip_transform = transforms.RandomHorizontalFlip(p=self.flip_p)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._length\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        import random as rnd\n",
        "        example = {}\n",
        "        image = PILImage.open(self.image_paths[i % self.num_images])\n",
        "        if not image.mode == \"RGB\":\n",
        "            image = image.convert(\"RGB\")\n",
        "        placeholder_string = self.placeholder_token\n",
        "        text = rnd.choice(self.templates).format(placeholder_string)\n",
        "        example[\"input_ids\"] = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.tokenizer.model_max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        ).input_ids[0]\n",
        "        # default to score-sde preprocessing\n",
        "        img = np.array(image).astype(np.uint8)\n",
        "        if self.center_crop:\n",
        "            crop = min(img.shape[0], img.shape[1])\n",
        "            h, w, = (\n",
        "                img.shape[0],\n",
        "                img.shape[1],\n",
        "            )\n",
        "            img = img[(h - crop) // 2 : (h + crop) // 2, (w - crop) // 2 : (w + crop) // 2]\n",
        "        image = PILImage.fromarray(img)\n",
        "        image = image.resize((self.size, self.size), resample=self.interpolation)\n",
        "        image = self.flip_transform(image)\n",
        "        image = np.array(image).astype(np.uint8)\n",
        "        image = (image / 127.5 - 1.0).astype(np.float32)\n",
        "        example[\"pixel_values\"] = torch.from_numpy(image).permute(2, 0, 1)\n",
        "        return example\n",
        "\n",
        "def run_materialdiffusion(page):\n",
        "    global materialdiffusion_prefs, prefs\n",
        "    if not bool(materialdiffusion_prefs['material_prompt']):\n",
        "      alert_msg(page, \"You must provide a text prompt to process your material...\")\n",
        "      return\n",
        "    if not bool(prefs['Replicate_api_key']):\n",
        "      alert_msg(page, \"You must provide your Replicate API Token in Settings to process your material...\")\n",
        "      return\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line, size=17)\n",
        "      page.materialdiffusion_output.controls.append(line)\n",
        "      page.materialdiffusion_output.update()\n",
        "    def clear_last():\n",
        "      del page.materialdiffusion_output.controls[-1]\n",
        "      page.materialdiffusion_output.update()\n",
        "    progress = ProgressBar(bar_height=8)\n",
        "    def callback_fnc(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n",
        "      callback_fnc.has_been_called = True\n",
        "      nonlocal progress\n",
        "      total_steps = len(latents)\n",
        "      percent = (step +1)/ total_steps\n",
        "      progress.value = percent\n",
        "      progress.tooltip = f\"{step +1} / {total_steps} timestep: {timestep}\"\n",
        "      progress.update()\n",
        "      #print(f'{type(latents)} {len(latents)}- {str(latents)}')\n",
        "    try:\n",
        "      run_sp(\"pip install git+https://github.com/TomMoore515/material_stable_diffusion.git@main#egg=predict\", realtime=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        #alert_msg(page, f\"Error installing Material Diffusion from TomMoore515...\", content=Text(str(e)))\n",
        "        pass\n",
        "    prt(Row([ProgressRing(), Text(\"Installing Replicate Material Diffusion Pipeline...\", weight=FontWeight.BOLD)]))\n",
        "    try:\n",
        "        import replicate\n",
        "    except ImportError as e:\n",
        "        run_process(\"pip install replicate -qq\", realtime=True)\n",
        "        import replicate\n",
        "        pass\n",
        "    os.environ[\"REPLICATE_API_TOKEN\"] = prefs['Replicate_api_key']\n",
        "    #export REPLICATE_API_TOKEN=\n",
        "    try:\n",
        "        model = replicate.models.get(\"tommoore515/material_stable_diffusion\")\n",
        "        version = model.versions.get(\"3b5c0242f8925a4ab6c79b4c51e9b4ce6374e9b07b5e8461d89e692fd0faa449\")\n",
        "    except Exception as e:\n",
        "        alert_msg(page, f\"Seems like your Replicate API Token is Invalid. Check it again...\", content=Text(str(e)))\n",
        "        return\n",
        "    import requests\n",
        "    from io import BytesIO\n",
        "    from PIL import ImageOps\n",
        "    init_img = None\n",
        "    if bool(materialdiffusion_prefs['init_image']):\n",
        "        if materialdiffusion_prefs['init_image'].startswith('http'):\n",
        "            init_img = PILImage.open(requests.get(materialdiffusion_prefs['init_image'], stream=True).raw)\n",
        "        else:\n",
        "            if os.path.isfile(materialdiffusion_prefs['init_image']):\n",
        "                init_img = PILImage.open(materialdiffusion_prefs['init_image'])\n",
        "            else:\n",
        "                alert_msg(page, f\"ERROR: Couldn't find your init_image {materialdiffusion_prefs['init_image']}\")\n",
        "                return\n",
        "        #width, height = init_img.size\n",
        "        #width, height = scale_dimensions(materialdiffusion_prefs['width'], materialdiffusion_prefs['height'])\n",
        "        init_img = init_img.resize((materialdiffusion_prefs['width'], materialdiffusion_prefs['height']), resample=PILImage.LANCZOS)\n",
        "        init_img = ImageOps.exif_transpose(init_img).convert(\"RGB\")\n",
        "    mask_img = None\n",
        "    if bool(materialdiffusion_prefs['mask_image']):\n",
        "        if materialdiffusion_prefs['mask_image'].startswith('http'):\n",
        "            mask_img = PILImage.open(requests.get(materialdiffusion_prefs['mask_image'], stream=True).raw)\n",
        "        else:\n",
        "            if os.path.isfile(materialdiffusion_prefs['mask_image']):\n",
        "                mask_img = PILImage.open(materialdiffusion_prefs['mask_image'])\n",
        "            else:\n",
        "                alert_msg(page, f\"ERROR: Couldn't find your mask_image {materialdiffusion_prefs['mask_image']}\")\n",
        "                return\n",
        "            if materialdiffusion_prefs['invert_mask']:\n",
        "                mask_img = ImageOps.invert(mask_img.convert('RGB'))\n",
        "                mask_img = mask_img.resize((materialdiffusion_prefs['width'], materialdiffusion_prefs['height']), resample=PILImage.NEAREST)\n",
        "                mask_img = ImageOps.exif_transpose(mask_img).convert(\"RGB\")\n",
        "    #print(f'Resize to {width}x{height}')\n",
        "    clear_pipes()\n",
        "    clear_last()\n",
        "    prt(\"Generating your Material Diffusion Image...\")\n",
        "    prt(progress)\n",
        "    random_seed = int(materialdiffusion_prefs['seed']) if int(materialdiffusion_prefs['seed']) > 0 else rnd.randint(0,4294967295)\n",
        "    try:\n",
        "        images = version.predict(prompt=materialdiffusion_prefs['material_prompt'], width=materialdiffusion_prefs['width'], height=materialdiffusion_prefs['height'], init_image=init_img, mask=mask_img, prompt_strength=materialdiffusion_prefs['prompt_strength'], num_outputs=materialdiffusion_prefs['num_outputs'], num_inference_steps=materialdiffusion_prefs['steps'], guidance_scale=materialdiffusion_prefs['guidance_scale'], seed=random_seed)\n",
        "    except Exception as e:\n",
        "        clear_last()\n",
        "        clear_last()\n",
        "        alert_msg(page, f\"ERROR: Couldn't create your image for some reason.  Possibly out of memory or something wrong with my code...\", content=Text(str(e)))\n",
        "        return\n",
        "    clear_last()\n",
        "    clear_last()\n",
        "    txt2img_output = stable_dir\n",
        "    batch_output = prefs['image_output']\n",
        "    print(str(images))\n",
        "    if images is None:\n",
        "        prt(f\"ERROR: Problem generating images, check your settings and run above blocks again, or report the error to Skquark if it really seems broken.\")\n",
        "        return\n",
        "    idx = 0\n",
        "    for image in images:\n",
        "        random_seed += idx\n",
        "        fname = format_filename(materialdiffusion_prefs['material_prompt'])\n",
        "        seed_suffix = f\"-{random_seed}\" if bool(prefs['file_suffix_seed']) else ''\n",
        "        fname = f'{materialdiffusion_prefs[\"file_prefix\"]}{fname}{seed_suffix}'\n",
        "        txt2img_output = stable_dir\n",
        "        if bool(materialdiffusion_prefs['batch_folder_name']):\n",
        "            txt2img_output = os.path.join(stable_dir, materialdiffusion_prefs['batch_folder_name'])\n",
        "        if not os.path.exists(txt2img_output):\n",
        "            os.makedirs(txt2img_output)\n",
        "        image_path = available_file(txt2img_output, fname, 1)\n",
        "        #image.save(image_path)\n",
        "        response = requests.get(image, stream=True)\n",
        "        with open(image_path, \"wb\") as f:\n",
        "          f.write(response.content)\n",
        "        new_file = image_path.rpartition(slash)[2]\n",
        "        if not materialdiffusion_prefs['display_upscaled_image'] or not materialdiffusion_prefs['apply_ESRGAN_upscale']:\n",
        "            prt(Row([Img(src=image_path, width=materialdiffusion_prefs['width'], height=materialdiffusion_prefs['height'], fit=ImageFit.FILL, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "\n",
        "        if save_to_GDrive:\n",
        "            batch_output = os.path.join(prefs['image_output'], materialdiffusion_prefs['batch_folder_name'])\n",
        "            if not os.path.exists(batch_output):\n",
        "                os.makedirs(batch_output)\n",
        "        elif storage_type == \"PyDrive Google Drive\":\n",
        "            newFolder = gdrive.CreateFile({'title': materialdiffusion_prefs['batch_folder_name'], \"parents\": [{\"kind\": \"drive#fileLink\", \"id\": prefs['image_output']}],\"mimeType\": \"application/vnd.google-apps.folder\"})\n",
        "            newFolder.Upload()\n",
        "            batch_output = newFolder\n",
        "        out_path = batch_output if save_to_GDrive else txt2img_output\n",
        "        \n",
        "        if materialdiffusion_prefs['apply_ESRGAN_upscale'] and status['installed_ESRGAN']:\n",
        "            os.chdir(os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "            upload_folder = 'upload'\n",
        "            result_folder = 'results'     \n",
        "            if os.path.isdir(upload_folder):\n",
        "                shutil.rmtree(upload_folder)\n",
        "            if os.path.isdir(result_folder):\n",
        "                shutil.rmtree(result_folder)\n",
        "            os.mkdir(upload_folder)\n",
        "            os.mkdir(result_folder)\n",
        "            short_name = f'{fname[:80]}-{idx}.png'\n",
        "            dst_path = os.path.join(dist_dir, 'Real-ESRGAN', upload_folder, short_name)\n",
        "            #print(f'Moving {fpath} to {dst_path}')\n",
        "            #shutil.move(fpath, dst_path)\n",
        "            shutil.copy(image_path, dst_path)\n",
        "            #faceenhance = ' --face_enhance' if materialdiffusion_prefs[\"face_enhance\"] else ''\n",
        "            faceenhance = ''\n",
        "            #python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --outscale {enlarge_scale}{faceenhance}\n",
        "            run_sp(f'python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --outscale {materialdiffusion_prefs[\"enlarge_scale\"]}{faceenhance}', cwd=os.path.join(dist_dir, 'Real-ESRGAN'), realtime=False)\n",
        "            out_file = short_name.rpartition('.')[0] + '_out.png'\n",
        "            #print(f'move {root_dir}Real-ESRGAN/{result_folder}/{out_file} to {fpath}')\n",
        "            #shutil.move(f'{root_dir}Real-ESRGAN/{result_folder}/{out_file}', fpath)\n",
        "            upscaled_path = os.path.join(out_path, new_file)\n",
        "            shutil.move(os.path.join(dist_dir, 'Real-ESRGAN', result_folder, out_file), upscaled_path)\n",
        "            # !python inference_realesrgan.py --model_path experiments/pretrained_models/RealESRGAN_x4plus.pth --input upload --netscale 4 --outscale 3.5 --half --face_enhance\n",
        "            os.chdir(stable_dir)\n",
        "            if materialdiffusion_prefs['display_upscaled_image']:\n",
        "                time.sleep(0.6)\n",
        "                prt(Row([Img(src=upscaled_path, width=materialdiffusion_prefs['width'] * float(materialdiffusion_prefs[\"enlarge_scale\"]), height=materialdiffusion_prefs['height'] * float(materialdiffusion_prefs[\"enlarge_scale\"]), fit=ImageFit.CONTAIN, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "        else:\n",
        "            shutil.copy(image_path, os.path.join(out_path, new_file))\n",
        "        # TODO: Add Metadata\n",
        "        prt(Row([Text(new_file)], alignment=MainAxisAlignment.CENTER))\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "\n",
        "def run_dall_e(page, from_list=False):\n",
        "    global dall_e_prefs, prefs, prompts\n",
        "    if (not bool(dall_e_prefs['prompt']) and not from_list) or (from_list and (len(prompts) == 0)):\n",
        "      alert_msg(page, \"You must provide a text prompt to process your image generation...\")\n",
        "      return\n",
        "    if not bool(prefs['OpenAI_api_key']):\n",
        "      alert_msg(page, \"You must provide your OpenAI API Key in Settings to process your Dall-e 2 Creation...\")\n",
        "      return\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line, size=17)\n",
        "      page.dall_e_output.controls.append(line)\n",
        "      page.dall_e_output.update()\n",
        "    def clear_last():\n",
        "      del page.dall_e_output.controls[-1]\n",
        "      page.dall_e_output.update()\n",
        "    progress = ProgressBar(bar_height=8)\n",
        "    prt(Row([ProgressRing(), Text(\"Installing OpenAi Dall-E 2 API...\", weight=FontWeight.BOLD)]))\n",
        "    run_process(\"pip install -q openai\", realtime=False)\n",
        "    import openai\n",
        "    try:\n",
        "        openai.api_key = prefs['OpenAI_api_key']\n",
        "    except Exception as e:\n",
        "        alert_msg(page, f\"Seems like your OpenAI API Key is Invalid. Check it again...\", content=Text(str(e)))\n",
        "        return\n",
        "    import requests\n",
        "    from io import BytesIO\n",
        "    from PIL import ImageOps\n",
        "    \n",
        "    save_dir = os.path.join(root_dir, 'dalle_inputs')\n",
        "    init_img = None\n",
        "    dall_e_list = []\n",
        "    if from_list:\n",
        "        if len(prompts) > 0:\n",
        "            for p in prompts:\n",
        "                dall_e_list.append({'prompt': p.prompt, 'init_image': p.arg['init_image'], 'mask_image': p.arg['mask_image']})\n",
        "        else:\n",
        "            alert_msg(page, f\"Your Prompts List is empty. Add to your batch list to use feature.\")\n",
        "            return\n",
        "    else:\n",
        "        dall_e_list.append({'prompt': dall_e_prefs['prompt'], 'init_image': dall_e_prefs['init_image'], 'mask_image': dall_e_prefs['mask_image']})\n",
        "    \n",
        "    for p in dall_e_list:\n",
        "        init_image = p['init_image']\n",
        "        mask_image = p['mask_image']\n",
        "        if bool(init_image):\n",
        "            fname = init_image.rpartition(slash)[2]\n",
        "            init_file = os.path.join(save_dir, fname)\n",
        "            if init_image.startswith('http'):\n",
        "                init_img = PILImage.open(requests.get(init_image, stream=True).raw)\n",
        "            else:\n",
        "                if os.path.isfile(init_image):\n",
        "                    init_img = PILImage.open(init_image)\n",
        "                else:\n",
        "                    alert_msg(page, f\"ERROR: Couldn't find your init_image {init_image}\")\n",
        "                    return\n",
        "            init_img = init_img.resize((dall_e_prefs['size'], dall_e_prefs['size']), resample=PILImage.LANCZOS)\n",
        "            init_img = ImageOps.exif_transpose(init_img).convert(\"RGB\")\n",
        "            init_img.save(init_file)\n",
        "        mask_img = None\n",
        "        if bool(mask_image):\n",
        "            fname = init_image.rpartition(slash)[2]\n",
        "            mask_file = os.path.join(save_dir, fname)\n",
        "            if mask_image.startswith('http'):\n",
        "                mask_img = PILImage.open(requests.get(mask_image, stream=True).raw)\n",
        "            else:\n",
        "                if os.path.isfile(mask_image):\n",
        "                    mask_img = PILImage.open(mask_image)\n",
        "                else:\n",
        "                    alert_msg(page, f\"ERROR: Couldn't find your mask_image {mask_image}\")\n",
        "                    return\n",
        "                if dall_e_prefs['invert_mask']:\n",
        "                    mask_img = ImageOps.invert(mask_img.convert('RGB'))\n",
        "            mask_img = mask_img.resize((dall_e_prefs['size'], dall_e_prefs['size']), resample=PILImage.NEAREST)\n",
        "            mask_img = ImageOps.exif_transpose(init_img).convert(\"RGB\")\n",
        "            mask_img.save(mask_file)\n",
        "        #print(f'Resize to {width}x{height}')\n",
        "        clear_pipes()\n",
        "        clear_last()\n",
        "        prt(\"Generating your Dall-E 2 Image...\")\n",
        "        prt(progress)\n",
        "\n",
        "        try:\n",
        "            if bool(init_image) and bool(dall_e_prefs['variation']):\n",
        "                response = openai.Image.create_variation(image=open(init_file, 'rb'), size=dall_e_prefs['size'], n=dall_e_prefs['num_images'])\n",
        "            elif bool(init_image) and not bool(mask_image):\n",
        "                response = openai.Image.create_edit(prompt=p['prompt'], size=dall_e_prefs['size'], n=dall_e_prefs['num_images'], image=open(init_file, 'rb'))\n",
        "            elif bool(init_image) and bool(mask_image):\n",
        "                response = openai.Image.create_edit(prompt=p['prompt'], size=dall_e_prefs['size'], n=dall_e_prefs['num_images'], image=open(init_file, 'rb'), mask=open(mask_file, 'rb'))\n",
        "            else:\n",
        "                response = openai.Image.create(prompt=p['prompt'], size=dall_e_prefs['size'], n=dall_e_prefs['num_images'])\n",
        "        except Exception as e:\n",
        "            clear_last()\n",
        "            clear_last()\n",
        "            alert_msg(page, f\"ERROR: Something went wrong generating image form API...\", content=Text(str(e)))\n",
        "            return\n",
        "        clear_last()\n",
        "        clear_last()\n",
        "        txt2img_output = stable_dir\n",
        "        batch_output = prefs['image_output']\n",
        "        #print(str(images))\n",
        "        if response is None:\n",
        "            prt(f\"ERROR: Problem generating images, check your settings and run above blocks again, or report the error to Skquark if it really seems broken.\")\n",
        "            return\n",
        "        #print(str(response))\n",
        "        idx = 0\n",
        "        for i in response['data']:\n",
        "            image = i['url']\n",
        "            #random_seed += idx\n",
        "            fname = format_filename(p['prompt'])\n",
        "            #seed_suffix = f\"-{random_seed}\" if bool(prefs['file_suffix_seed']) else ''\n",
        "            fname = f'{dall_e_prefs[\"file_prefix\"]}{fname}'\n",
        "            txt2img_output = stable_dir\n",
        "            if bool(dall_e_prefs['batch_folder_name']):\n",
        "                txt2img_output = os.path.join(stable_dir, dall_e_prefs['batch_folder_name'])\n",
        "            if not os.path.exists(txt2img_output):\n",
        "                os.makedirs(txt2img_output)\n",
        "            image_path = available_file(txt2img_output, fname, 1)\n",
        "            #image.save(image_path)\n",
        "            response = requests.get(image, stream=True)\n",
        "            with open(image_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            #img = i['url']\n",
        "            new_file = image_path.rpartition(slash)[2].rpartition('-')[0]\n",
        "            size = int(dall_e_prefs['size'].rpartition('x')[0])\n",
        "            if not dall_e_prefs['display_upscaled_image'] or not dall_e_prefs['apply_ESRGAN_upscale']:\n",
        "                prt(Row([Img(src=image_path, width=size, height=size, fit=ImageFit.FILL, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "\n",
        "            if save_to_GDrive:\n",
        "                batch_output = os.path.join(prefs['image_output'], dall_e_prefs['batch_folder_name'])\n",
        "                if not os.path.exists(batch_output):\n",
        "                    os.makedirs(batch_output)\n",
        "            elif storage_type == \"PyDrive Google Drive\":\n",
        "                newFolder = gdrive.CreateFile({'title': dall_e_prefs['batch_folder_name'], \"parents\": [{\"kind\": \"drive#fileLink\", \"id\": prefs['image_output']}],\"mimeType\": \"application/vnd.google-apps.folder\"})\n",
        "                newFolder.Upload()\n",
        "                batch_output = newFolder\n",
        "            out_path = batch_output if save_to_GDrive else txt2img_output\n",
        "            new_path = available_file(out_path, new_file, idx)\n",
        "            if dall_e_prefs['apply_ESRGAN_upscale'] and status['installed_ESRGAN']:\n",
        "                os.chdir(os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "                upload_folder = 'upload'\n",
        "                result_folder = 'results'     \n",
        "                if os.path.isdir(upload_folder):\n",
        "                    shutil.rmtree(upload_folder)\n",
        "                if os.path.isdir(result_folder):\n",
        "                    shutil.rmtree(result_folder)\n",
        "                os.mkdir(upload_folder)\n",
        "                os.mkdir(result_folder)\n",
        "                short_name = f'{fname[:80]}-{idx}.png'\n",
        "                dst_path = os.path.join(dist_dir, 'Real-ESRGAN', upload_folder, short_name)\n",
        "                #print(f'Moving {fpath} to {dst_path}')\n",
        "                #shutil.move(fpath, dst_path)\n",
        "                shutil.copy(image_path, dst_path)\n",
        "                faceenhance = ' --face_enhance' if dall_e_prefs[\"face_enhance\"] else ''\n",
        "                run_sp(f'python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --outscale {dall_e_prefs[\"enlarge_scale\"]}{faceenhance}', cwd=os.path.join(dist_dir, 'Real-ESRGAN'), realtime=False)\n",
        "                out_file = short_name.rpartition('.')[0] + '_out.png'\n",
        "                upscaled_path = new_path #os.path.join(out_path, new_file)\n",
        "                shutil.move(os.path.join(dist_dir, 'Real-ESRGAN', result_folder, out_file), upscaled_path)\n",
        "                # python inference_realesrgan.py --model_path experiments/pretrained_models/RealESRGAN_x4plus.pth --input upload --netscale 4 --outscale 3.5 --half --face_enhance\n",
        "                os.chdir(stable_dir)\n",
        "                if dall_e_prefs['display_upscaled_image']:\n",
        "                    time.sleep(0.6)\n",
        "                    prt(Row([Img(src=upscaled_path, width=size * float(dall_e_prefs[\"enlarge_scale\"]), height=size * float(dall_e_prefs[\"enlarge_scale\"]), fit=ImageFit.CONTAIN, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "            else:\n",
        "                shutil.copy(image_path, new_path)#os.path.join(out_path, new_file))\n",
        "            # TODO: Add Metadata\n",
        "            prt(Row([Text(new_path)], alignment=MainAxisAlignment.CENTER))\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "def run_kandinsky(page):\n",
        "    global kandinsky_prefs, pipe_kandinsky, prefs\n",
        "    if not bool(kandinsky_prefs['prompt']):\n",
        "      alert_msg(page, \"You must provide a text prompt to process your image generation...\")\n",
        "      return\n",
        "    def prt(line):\n",
        "      if type(line) == str:\n",
        "        line = Text(line, size=17)\n",
        "      page.kandinsky_output.controls.append(line)\n",
        "      page.kandinsky_output.update()\n",
        "    def clear_last():\n",
        "      del page.kandinsky_output.controls[-1]\n",
        "      page.kandinsky_output.update()\n",
        "    progress = ProgressBar(bar_height=8)\n",
        "    prt(Row([ProgressRing(), Text(\"Installing Kandinsky 2.0 Engine & Models... See console log for progress.\", weight=FontWeight.BOLD)]))\n",
        "    try:\n",
        "        from kandinsky2 import get_kandinsky2\n",
        "    except Exception:\n",
        "        run_process(\"pip install transformers==4.23.1 --upgrade --force-reinstall\", realtime=False)\n",
        "        #run_process(\"pip install -q git+https://github.com/ai-forever/Kandinsky-2.0.git\", realtime=False)\n",
        "        run_sp('pip install \"git+https://github.com/ai-forever/Kandinsky-2.0.git\"', realtime=True)\n",
        "        from kandinsky2 import get_kandinsky2\n",
        "        pass\n",
        "    import requests\n",
        "    from io import BytesIO\n",
        "    from PIL import ImageOps\n",
        "    #save_dir = os.path.join(root_dir, 'kandinsky_inputs')\n",
        "    init_img = None\n",
        "    if bool(kandinsky_prefs['init_image']):\n",
        "        fname = kandinsky_prefs['init_image'].rpartition(slash)[2]\n",
        "        #init_file = os.path.join(save_dir, fname)\n",
        "        if kandinsky_prefs['init_image'].startswith('http'):\n",
        "            init_img = PILImage.open(requests.get(kandinsky_prefs['init_image'], stream=True).raw)\n",
        "        else:\n",
        "            if os.path.isfile(kandinsky_prefs['init_image']):\n",
        "                init_img = PILImage.open(kandinsky_prefs['init_image'])\n",
        "            else:\n",
        "                alert_msg(page, f\"ERROR: Couldn't find your init_image {kandinsky_prefs['init_image']}\")\n",
        "                return\n",
        "        init_img = init_img.resize((kandinsky_prefs['width'], kandinsky_prefs['height']), resample=PILImage.LANCZOS)\n",
        "        init_img = ImageOps.exif_transpose(init_img).convert(\"RGB\")\n",
        "        #init_img.save(init_file)\n",
        "    mask_img = None\n",
        "    if bool(kandinsky_prefs['mask_image']):\n",
        "        fname = kandinsky_prefs['init_image'].rpartition(slash)[2]\n",
        "        #mask_file = os.path.join(save_dir, fname)\n",
        "        if kandinsky_prefs['mask_image'].startswith('http'):\n",
        "            mask_img = PILImage.open(requests.get(kandinsky_prefs['mask_image'], stream=True).raw)\n",
        "        else:\n",
        "            if os.path.isfile(kandinsky_prefs['mask_image']):\n",
        "                mask_img = PILImage.open(kandinsky_prefs['mask_image'])\n",
        "            else:\n",
        "                alert_msg(page, f\"ERROR: Couldn't find your mask_image {kandinsky_prefs['mask_image']}\")\n",
        "                return\n",
        "            if kandinsky_prefs['invert_mask']:\n",
        "                mask_img = ImageOps.invert(mask_img.convert('RGB'))\n",
        "        mask_img = mask_img.resize((kandinsky_prefs['width'], kandinsky_prefs['height']), resample=PILImage.NEAREST)\n",
        "        mask_img = ImageOps.exif_transpose(init_img).convert(\"RGB\")\n",
        "        mask_img = numpy.asarray(mask_img)\n",
        "        #mask_img.save(mask_file)\n",
        "    #print(f'Resize to {width}x{height}')\n",
        "    clear_pipes()\n",
        "    if bool(kandinsky_prefs['init_image']) and not bool(kandinsky_prefs['mask_image']):\n",
        "        pipe_kandinsky = get_kandinsky2('cuda', task_type='img2img')\n",
        "    elif bool(kandinsky_prefs['init_image']) and bool(kandinsky_prefs['mask_image']):\n",
        "        pipe_kandinsky = get_kandinsky2('cuda', task_type='inpainting')\n",
        "    else:\n",
        "        pipe_kandinsky = get_kandinsky2('cuda', task_type='text2img')\n",
        "    clear_last()\n",
        "    prt(\"Generating your Kandinsky 2.0 Image...\")\n",
        "    prt(progress)\n",
        "\n",
        "    try:\n",
        "        if bool(kandinsky_prefs['init_image']) and not bool(kandinsky_prefs['mask_image']):\n",
        "            images = pipe_kandinsky.generate_img2img(kandinsky_prefs['prompt'], init_img, strength=kandinsky_prefs['strength'], batch_size=kandinsky_prefs['num_images'], w=kandinsky_prefs['width'], h=kandinsky_prefs['height'], num_steps=kandinsky_prefs['steps'], denoised_type=kandinsky_prefs['denoised_type'], dynamic_threshold_v=kandinsky_prefs['dynamic_threshold_v'], sampler=kandinsky_prefs['sampler'], ddim_eta=kandinsky_prefs['ddim_eta'], guidance_scale=kandinsky_prefs['guidance_scale'])\n",
        "        elif bool(kandinsky_prefs['init_image']) and bool(kandinsky_prefs['mask_image']):\n",
        "            images = pipe_kandinsky.generate_inpainting(kandinsky_prefs['prompt'], init_img, mask_img, batch_size=kandinsky_prefs['num_images'], w=kandinsky_prefs['width'], h=kandinsky_prefs['height'], num_steps=kandinsky_prefs['steps'], denoised_type=kandinsky_prefs['denoised_type'], dynamic_threshold_v=kandinsky_prefs['dynamic_threshold_v'], sampler=kandinsky_prefs['sampler'], ddim_eta=kandinsky_prefs['ddim_eta'], guidance_scale=kandinsky_prefs['guidance_scale'])\n",
        "        else:\n",
        "            images = pipe_kandinsky.generate_text2img(kandinsky_prefs['prompt'], batch_size=kandinsky_prefs['num_images'], w=kandinsky_prefs['width'], h=kandinsky_prefs['height'], num_steps=kandinsky_prefs['steps'], denoised_type=kandinsky_prefs['denoised_type'], dynamic_threshold_v=kandinsky_prefs['dynamic_threshold_v'], sampler=kandinsky_prefs['sampler'], ddim_eta=kandinsky_prefs['ddim_eta'], guidance_scale=kandinsky_prefs['guidance_scale'])\n",
        "    except Exception as e:\n",
        "        clear_last()\n",
        "        clear_last()\n",
        "        alert_msg(page, f\"ERROR: Something went wrong generating images...\", content=Text(str(e)))\n",
        "        return\n",
        "    clear_last()\n",
        "    clear_last()\n",
        "    txt2img_output = stable_dir\n",
        "    batch_output = prefs['image_output']\n",
        "    #print(str(images))\n",
        "    if images is None:\n",
        "        prt(f\"ERROR: Problem generating images, check your settings and run again, or report the error to Skquark if it really seems broken.\")\n",
        "        return\n",
        "    idx = 0\n",
        "    for image in images:\n",
        "        fname = format_filename(kandinsky_prefs['prompt'])\n",
        "        #seed_suffix = f\"-{random_seed}\" if bool(prefs['file_suffix_seed']) else ''\n",
        "        fname = f'{kandinsky_prefs[\"file_prefix\"]}{fname}'\n",
        "        txt2img_output = stable_dir\n",
        "        if bool(kandinsky_prefs['batch_folder_name']):\n",
        "            txt2img_output = os.path.join(stable_dir, kandinsky_prefs['batch_folder_name'])\n",
        "        if not os.path.exists(txt2img_output):\n",
        "            os.makedirs(txt2img_output)\n",
        "        image_path = available_file(txt2img_output, fname, 1)\n",
        "        image.save(image_path)\n",
        "        new_file = image_path.rpartition(slash)[2]\n",
        "        if not kandinsky_prefs['display_upscaled_image'] or not kandinsky_prefs['apply_ESRGAN_upscale']:\n",
        "            prt(Row([Img(src=image_path, width=kandinsky_prefs['width'], height=kandinsky_prefs['height'], fit=ImageFit.FILL, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "\n",
        "        if save_to_GDrive:\n",
        "            batch_output = os.path.join(prefs['image_output'], kandinsky_prefs['batch_folder_name'])\n",
        "            if not os.path.exists(batch_output):\n",
        "                os.makedirs(batch_output)\n",
        "        elif storage_type == \"PyDrive Google Drive\":\n",
        "            newFolder = gdrive.CreateFile({'title': kandinsky_prefs['batch_folder_name'], \"parents\": [{\"kind\": \"drive#fileLink\", \"id\": prefs['image_output']}],\"mimeType\": \"application/vnd.google-apps.folder\"})\n",
        "            newFolder.Upload()\n",
        "            batch_output = newFolder\n",
        "        out_path = batch_output if save_to_GDrive else txt2img_output\n",
        "        \n",
        "        if kandinsky_prefs['apply_ESRGAN_upscale'] and status['installed_ESRGAN']:\n",
        "            os.chdir(os.path.join(dist_dir, 'Real-ESRGAN'))\n",
        "            upload_folder = 'upload'\n",
        "            result_folder = 'results'     \n",
        "            if os.path.isdir(upload_folder):\n",
        "                shutil.rmtree(upload_folder)\n",
        "            if os.path.isdir(result_folder):\n",
        "                shutil.rmtree(result_folder)\n",
        "            os.mkdir(upload_folder)\n",
        "            os.mkdir(result_folder)\n",
        "            short_name = f'{fname[:80]}-{idx}.png'\n",
        "            dst_path = os.path.join(dist_dir, 'Real-ESRGAN', upload_folder, short_name)\n",
        "            #print(f'Moving {fpath} to {dst_path}')\n",
        "            #shutil.move(fpath, dst_path)\n",
        "            shutil.copy(image_path, dst_path)\n",
        "            faceenhance = ' --face_enhance' if kandinsky_prefs[\"face_enhance\"] else ''\n",
        "            run_sp(f'python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --outscale {kandinsky_prefs[\"enlarge_scale\"]}{faceenhance}', cwd=os.path.join(dist_dir, 'Real-ESRGAN'), realtime=False)\n",
        "            out_file = short_name.rpartition('.')[0] + '_out.png'\n",
        "            upscaled_path = os.path.join(out_path, new_file)\n",
        "            shutil.move(os.path.join(dist_dir, 'Real-ESRGAN', result_folder, out_file), upscaled_path)\n",
        "            # python inference_realesrgan.py --model_path experiments/pretrained_models/RealESRGAN_x4plus.pth --input upload --netscale 4 --outscale 3.5 --half --face_enhance\n",
        "            os.chdir(stable_dir)\n",
        "            if kandinsky_prefs['display_upscaled_image']:\n",
        "                time.sleep(0.6)\n",
        "                prt(Row([Img(src=upscaled_path, width=kandinsky_prefs['width'] * float(kandinsky_prefs[\"enlarge_scale\"]), height=kandinsky_prefs['height'] * float(kandinsky_prefs[\"enlarge_scale\"]), fit=ImageFit.CONTAIN, gapless_playback=True)], alignment=MainAxisAlignment.CENTER))\n",
        "        else:\n",
        "            shutil.copy(image_path, os.path.join(out_path, new_file))\n",
        "        # TODO: Add Metadata\n",
        "        prt(Row([Text(new_file)], alignment=MainAxisAlignment.CENTER))\n",
        "    if prefs['enable_sounds']: page.snd_alert.play()\n",
        "\n",
        "\n",
        "def main(page: Page):\n",
        "    page.title = \"Stable Diffusion Deluxe - FletUI\"\n",
        "    #page.scroll=ScrollMode.AUTO\n",
        "    #page.auto_scroll=True\n",
        "    def open_help_dlg(e):\n",
        "        page.dialog = help_dlg\n",
        "        help_dlg.open = True\n",
        "        page.update()\n",
        "    def close_help_dlg(e):\n",
        "        help_dlg.open = False\n",
        "        page.update()\n",
        "    def open_url(e):\n",
        "        page.launch_url(e.data)\n",
        "    def exit_disconnect(e):\n",
        "        save_settings_file(page)\n",
        "        if is_Colab:\n",
        "          #run_sp(\"install pyautogui\", realtime=False)\n",
        "          #import pyautogui\n",
        "          #pyautogui.hotkey('ctrl', 'w')\n",
        "          #import keyboard\n",
        "          #keyboard.press_and_release('ctrl+w')\n",
        "          #time.sleep(1.5)\n",
        "          from google.colab import runtime\n",
        "          runtime.unassign()\n",
        "          #import time\n",
        "    help_dlg = AlertDialog(\n",
        "        title=Text(\"üíÅ   Help/Information - Stable Diffusion Deluxe \" + version), content=Column([Text(\"If you don't know what Stable Diffusion is, you're in for a pleasant surprise.. If you're already familiar, you're gonna love how easy it is to be an artist with the help of our AI friends with our pretty interface.\"),\n",
        "              Text(\"Simply go through the self-explanitory tabs step-by-step and set your preferences to get started. The default values are good for most, but you can have some fun experimenting. All values are automatically saved as you make changes and change tabs.\"),\n",
        "              Text(\"Each time you open the app, you should start in the Installers section, turn on all the components you plan on using in you session, then Run the Installers and let them download. You can multitask and work in other tabs while it's installing.\"),\n",
        "              Text(\"In the Prompts List, add as many text prompts as you can think of, and edit any prompt to override any default Image Parameter.  Once you're ready, run diffusion on your prompts list and watch it fill your Google Drive..\"),\n",
        "              Text(\"Try out any and all of our Prompt Helpers to use practical text AIs to make unique descriptive prompts fast, with our Prompt Generator, Remixer, Brainstormer and Advanced Writer.  You'll never run out of inspiration again...\"),\n",
        "        ], scroll=ScrollMode.AUTO),\n",
        "        actions=[TextButton(\"üëç  Thanks! \", on_click=close_help_dlg)], actions_alignment=MainAxisAlignment.END,\n",
        "    )\n",
        "    def open_credits_dlg(e):\n",
        "        page.dialog = credits_dlg\n",
        "        credits_dlg.open = True\n",
        "        page.update()\n",
        "    def close_credits_dlg(e):\n",
        "        credits_dlg.open = False\n",
        "        page.update()\n",
        "    credits_markdown = '''This notebook is an Open-Source side project by [Skquark, Inc.](https://Skquark.com), primarily created by Alan Bedian for fun and functionality.\n",
        "\n",
        "The real credit goes to the team at [Stability.ai](https://Stability.ai) for making Stable Diffusion so great, and [HuggingFace](https://HuggingFace.co) for their work on the Diffusers Pipeline.\n",
        "\n",
        "For the great app UI framework, we thank [Flet](https://Flet.dev) with the amazing Flutter based Python library with a very functional dev platform that made this possible.\n",
        "\n",
        "For the brains behind our Prompt Helpers, we thank our friend [OpenAI GPT-3](https://beta.OpenAI.com), [Bloom-AI](https://huggingface.co/bigscience/bloom) and [TextSynth](https://TextSynth.com) for making an AI so fun to talk to and use.\n",
        "\n",
        "Shoutouts to the Discord Community of [Disco Diffusion](https://discord.gg/d5ZVbAfm), [Stable Diffusion](https://discord.gg/stablediffusion), and [Flet](https://discord.gg/nFqy742h) for their support and user contributions.'''\n",
        "    credits_dlg = AlertDialog(\n",
        "        title=Text(\"üôå   Credits/Acknowledgments\"), content=Column([Markdown(credits_markdown, extension_set=\"gitHubWeb\", on_tap_link=open_url)\n",
        "        ], scroll=ScrollMode.AUTO),\n",
        "        actions=[TextButton(\"üëä   Good Stuff... \", on_click=close_credits_dlg)], actions_alignment=MainAxisAlignment.END,\n",
        "    )\n",
        "    page.theme_mode = prefs['theme_mode'].lower()\n",
        "    if prefs['theme_mode'] == 'Dark':\n",
        "      page.dark_theme = theme.Theme(color_scheme_seed=prefs['theme_color'].lower())#, use_material3=True)\n",
        "    else:\n",
        "      page.theme = theme.Theme(color_scheme_seed=prefs['theme_color'].lower())\n",
        "    app_icon_color = colors.AMBER_800\n",
        "    \n",
        "    appbar=AppBar(title=Text(\"üë®‚Äçüé®Ô∏è  Stable Diffusion - Deluxe Edition  üñåÔ∏è\" if page.width >= 768 else \"Stable Diffusion Deluxe  üñåÔ∏è\", weight=FontWeight.BOLD),elevation=20,\n",
        "      center_title=True,\n",
        "          bgcolor=colors.SURFACE_VARIANT,\n",
        "          leading=IconButton(icon=icons.LOCAL_FIRE_DEPARTMENT_OUTLINED, icon_color=app_icon_color, icon_size=32, tooltip=\"Save Settings File\", on_click=lambda _: app_icon_save()),\n",
        "          #leading_width=40,\n",
        "          actions=[\n",
        "              PopupMenuButton(\n",
        "                  items=[\n",
        "                      PopupMenuItem(text=\"ü§î  Help/Info\", on_click=open_help_dlg),\n",
        "                      PopupMenuItem(text=\"üëè  Credits\", on_click=open_credits_dlg),\n",
        "                      PopupMenuItem(text=\"ü§ß  Issues/Suggestions\", on_click=lambda _:page.launch_url(\"https://github.com/Skquark/AI-Friends/issues\")),\n",
        "                      PopupMenuItem(text=\"üì®  Email Skquark\", on_click=lambda _:page.launch_url(\"mailto:Alan@Skquark.com\")),\n",
        "                      PopupMenuItem(text=\"ü§ë  Offer Donation\", on_click=lambda _:page.launch_url(\"https://paypal.me/StarmaTech\")),\n",
        "                      #PopupMenuItem(text=\"‚ùé  Exit/Disconnect Runtime\", on_click=exit_disconnect) if is_Colab else PopupMenuItem(),\n",
        "                  ]\n",
        "              ),\n",
        "          ])\n",
        "    if is_Colab:\n",
        "      appbar.actions[0].items.append(PopupMenuItem())\n",
        "      appbar.actions[0].items.append(PopupMenuItem(text=\"‚ùé  Exit/Disconnect Runtime\", on_click=exit_disconnect))\n",
        "    page.appbar = appbar\n",
        "    def app_icon_save():\n",
        "      app_icon_color = colors.GREEN_800\n",
        "      appbar.leading = IconButton(icon=icons.LOCAL_FIRE_DEPARTMENT_OUTLINED, icon_color=app_icon_color, icon_size=32, tooltip=\"Saving Settings File\")\n",
        "      appbar.update()\n",
        "      time.sleep(0.6)\n",
        "      app_icon_color = colors.AMBER_800\n",
        "      appbar.leading = IconButton(icon=icons.LOCAL_FIRE_DEPARTMENT_OUTLINED, icon_color=app_icon_color, icon_size=32, tooltip=\"Save Settings File\", on_click=lambda _: app_icon_save())\n",
        "      appbar.update()\n",
        "    page.app_icon_save = app_icon_save\n",
        "    page.vertical_alignment = MainAxisAlignment.START\n",
        "    page.horizontal_alignment = CrossAxisAlignment.START\n",
        "    t = buildTabs(page)\n",
        "    t.on_change = tab_on_change\n",
        "    #(t,page)\n",
        "    def close_banner(e):\n",
        "        page.banner.open = False\n",
        "        page.update()\n",
        "    #leading=Icon(icons.DOWNLOADING, color=colors.AMBER, size=40), \n",
        "    page.banner = Banner(bgcolor=colors.SECONDARY_CONTAINER, content=Column([]), actions=[TextButton(\"Close\", on_click=close_banner)])\n",
        "    def show_banner_click(e):\n",
        "        page.banner.open = True\n",
        "        page.update()\n",
        "\n",
        "    page.add(t)\n",
        "    if not status['initialized']:\n",
        "        initState(page)\n",
        "        status['initialized'] = True\n",
        "    #page.add(ElevatedButton(\"Show Banner\", on_click=show_banner_click))\n",
        "    #page.add (Text (\"Enhanced Stable Diffusion Deluxe by Skquark, Inc.\"))\n",
        "\n",
        "class NumberPicker(UserControl):\n",
        "    def __init__(self, label=\"\", value=1, min=0, max=20, step=1, on_change=None):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "        self.min = min\n",
        "        self.max = max\n",
        "        self.step = step\n",
        "        self.label = label\n",
        "        self.on_change = on_change\n",
        "        self.build()\n",
        "    def build(self):\n",
        "        def changed(e):\n",
        "            self.value = int(e.control.value)\n",
        "            if self.value < self.min:\n",
        "              self.value = self.min\n",
        "              self.txt_number.value = self.value\n",
        "              self.txt_number.update()\n",
        "            if self.value > self.max:\n",
        "              self.value = self.max\n",
        "              self.txt_number.value = self.value\n",
        "              self.txt_number.update()\n",
        "            if self.on_change is not None:\n",
        "              e.control = self\n",
        "              self.on_change(e)\n",
        "        def minus_click(e):\n",
        "            v = int(self.value)\n",
        "            if v > self.min:\n",
        "              self.value -= self.step\n",
        "              self.txt_number.value = self.value\n",
        "              self.txt_number.update()\n",
        "              e.control = self\n",
        "              if self.on_change is not None:\n",
        "                self.on_change(e)\n",
        "        def plus_click(e):\n",
        "            v = int(self.value)\n",
        "            if v < self.max:\n",
        "              self.value += self.step\n",
        "              self.txt_number.value = self.value\n",
        "              self.txt_number.update()\n",
        "              e.control = self\n",
        "              if self.on_change is not None:\n",
        "                self.on_change(e)\n",
        "        self.txt_number = TextField(value=str(self.value), text_align=TextAlign.CENTER, width=55, height=42, content_padding=padding.only(top=4), keyboard_type=KeyboardType.NUMBER, on_change=changed)\n",
        "        return Row([Text(self.label), IconButton(icons.REMOVE, on_click=minus_click), self.txt_number, IconButton(icons.ADD, on_click=plus_click)], spacing=1)\n",
        "\n",
        "''' Sample alt Object format\n",
        "class Component(UserControl):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.build()\n",
        "    def search(self, e):\n",
        "        pass\n",
        "    def build(self):\n",
        "        self.expand = True\n",
        "        #self.table\n",
        "        self.parameter = Ref[TextField]()\n",
        "        return Column(\n",
        "            controls=[\n",
        "            ],\n",
        "        )\n",
        "class Main:\n",
        "    def __init__(self):\n",
        "        self.page = None\n",
        "    def __call__(self, page: Page):\n",
        "        self.page = page\n",
        "        page.title = \"Alternative Boot experiment\"\n",
        "        self.add_stuff()\n",
        "    def add_stuff(self):\n",
        "        self.page.add(\n",
        "            Text(\"Some text\", size=20),\n",
        "        )\n",
        "        self.page.update()\n",
        "main = Main()'''\n",
        "\n",
        "port = 8510\n",
        "if tunnel_type == \"ngrok\":\n",
        "  if bool(url):\n",
        "    public_url = url\n",
        "  else:\n",
        "    from pyngrok import ngrok\n",
        "    public_url = ngrok.connect(port = str(port)).public_url\n",
        "elif tunnel_type == \"localtunnel\":\n",
        "  if False:\n",
        "  #if bool(url):\n",
        "    public_url = url\n",
        "  else:\n",
        "    import re\n",
        "    localtunnel = subprocess.Popen(['lt', '--port', '80', 'http'], stdout=subprocess.PIPE)\n",
        "    url = str(localtunnel.stdout.readline())\n",
        "    public_url = (re.search(\"(?P<url>https?:\\/\\/[^\\s]+loca.lt)\", url).group(\"url\"))\n",
        "else: public_url=\"\"\n",
        "from IPython.display import Javascript\n",
        "if bool(public_url):\n",
        "    if auto_launch_website:\n",
        "        display(Javascript('window.open(\"{url}\");'.format(url=public_url)))\n",
        "        time.sleep(0.7)\n",
        "        clear_output()\n",
        "    print(\"\\nOpen URL in browser to launch app in tab: \" + str(public_url))\n",
        "\n",
        "#await google.colab.kernel.proxyPort(%s)\n",
        "# Still not working to display app in Colab console, but tried.\n",
        "def show_port(adr, height=500):\n",
        "  display(Javascript(\"\"\"\n",
        "  (async ()=>{\n",
        "    fm = document.createElement('iframe')\n",
        "    fm.src = '%s'\n",
        "    fm.width = '100%%'\n",
        "    fm.height = '%d'\n",
        "    fm.frameBorder = 0\n",
        "    document.body.append(fm)\n",
        "  })();\n",
        "  \"\"\" % (adr, height) ))\n",
        "#import requests\n",
        "#r = requests.get('http://localhost:4040/api/tunnels')\n",
        "#url = r.json()['tunnels'][0]['public_url']\n",
        "#print(url)\n",
        "#await google.colab.kernel.proxyPort(%s)\n",
        "#get_ipython().system_raw('python3 -m http.server 8888 &') \n",
        "#get_ipython().system_raw('./ngrok http 8501 &')\n",
        "#show_port(public_url.public_url, port)\n",
        "#show_port(public_url.public_url)\n",
        "#run_sp(f'python -m webbrowser -t \"{public_url.public_url}\"')\n",
        "#webbrowser.open(public_url.public_url, new=0, autoraise=True)\n",
        "#webbrowser.open_new_tab(public_url.public_url)\n",
        "#flet.app(target=main, view=flet.WEB_BROWSER, port=port, host=socket_host)\n",
        "#flet.app(target=main, view=flet.WEB_BROWSER, port=port, host=host_address)\n",
        "#flet.app(target=main, view=flet.WEB_BROWSER, port=80, host=public_url.public_url)\n",
        "#flet.app(target=main, view=flet.WEB_BROWSER, port=port, host=\"0.0.0.0\")\n",
        "if tunnel_type == \"desktop\":\n",
        "  flet.app(target=main, assets_dir=root_dir, upload_dir=root_dir)\n",
        "else:\n",
        "  flet.app(target=main, view=flet.WEB_BROWSER, port=80, assets_dir=root_dir, upload_dir=root_dir, web_renderer=\"html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gfi-vDp6A8it"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "raise(RuntimeError(\"Stopping Execution for Run All to end...\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## ‚ñ∂Ô∏è **Inpaint Dream Mask Maker** - GradIO WebUI (temporary until I make better Mask Painter in Flet UI)\n",
        "#@markdown Prepared your B&W ***mask_image*** and resizes ***init_image*** to add to your batch prompts list easily.\n",
        "max_image_resolution = 960 #@param {'type':'slider', min:256, max:1280, step:64}\n",
        "init_image_strength_override = False #param {type:'boolean'}\n",
        "import string\n",
        "#import PIL.ImageOps\n",
        "#@title ## üì• **Install GradIO Web Server** (_if_ you want to use Inpaint Helper interface)\n",
        "try:\n",
        "  import gradio as gr\n",
        "except ImportError:\n",
        "  run_sp(\"pip install gradio datasets tqdm\")\n",
        "  pass\n",
        "finally:\n",
        "  import gradio as gr\n",
        "\n",
        "#import numpy as np\n",
        "import torch\n",
        "from torch import autocast\n",
        "import requests\n",
        "import PIL\n",
        "from PIL import Image, ImageOps\n",
        "from io import BytesIO\n",
        "clear_output()\n",
        "#print(f'{Color.BLUE}Successfully Installed GradIO...{Color.END}')\n",
        "\n",
        "image = None\n",
        "def multiple_of_64(x):\n",
        "    return int(round(x/64)*64)\n",
        "def multiple_of_8(x):\n",
        "    return int(round(x/8)*8)\n",
        "def scale_dimensions(width, height):\n",
        "  max = int(max_image_resolution)\n",
        "  r_width = width\n",
        "  r_height = height\n",
        "  if width < max and height < max:\n",
        "    if width >= height:\n",
        "      ratio = max / width\n",
        "      r_width = max\n",
        "      r_height = int(height * ratio)\n",
        "    else:\n",
        "      ratio = max / height\n",
        "      r_height = max\n",
        "      r_width = int(width * ratio)\n",
        "    width = r_width\n",
        "    height = r_height\n",
        "  if width >= height:\n",
        "    if width > max:\n",
        "      r_width = max\n",
        "      r_height = int(height * (max/width))\n",
        "    else:\n",
        "      r_width = width\n",
        "      r_height = height\n",
        "  else:\n",
        "    if height > max:\n",
        "      r_height = max\n",
        "      r_width = int(width * (max/height))\n",
        "    else:\n",
        "      r_width = width\n",
        "      r_height = height\n",
        "  return multiple_of_64(r_width), multiple_of_64(r_height)\n",
        "\n",
        "def format_filename(s):\n",
        "    valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n",
        "    filename = ''.join(c for c in s if c in valid_chars)\n",
        "    filename = filename.replace(' ','_')\n",
        "    return filename[:24]\n",
        "\n",
        "def available_file(folder, name, idx, mask=False):\n",
        "  available = False\n",
        "  mask_str = '-mask' if mask else ''\n",
        "  while not available:\n",
        "    if os.path.isfile(os.path.join(folder, f'{name}-{idx}{mask_str}.png')):\n",
        "      idx += 1\n",
        "    else: available = True\n",
        "  return os.path.join(folder, f'{name}-{idx}{mask_str}.png')\n",
        "\n",
        "def available_folder(folder, name, idx):\n",
        "  available = False\n",
        "  while not available:\n",
        "    if os.path.isdir(os.path.join(folder, f'{name}-{idx}')):\n",
        "      idx += 1\n",
        "    else: available = True\n",
        "  return os.path.join(folder, f'{name}-{idx}')\n",
        "  \n",
        "def create(prompt, img, option):\n",
        "    global prefs\n",
        "    mask_img = img[\"mask\"]\n",
        "    init_img = img[\"image\"]\n",
        "    w, h = init_img.size\n",
        "    w, h = scale_dimensions(w, h)\n",
        "    mask_img = mask_img.convert(\"1\")\n",
        "    mask_img = mask_img.resize((w, h), resample=PIL.Image.LANCZOS)\n",
        "    if option == \"Replace everything else\":\n",
        "       mask_img = ImageOps.invert(mask_img.convert('RGB'))\n",
        "       #mask = mask.convert('1')\n",
        "    init_img = init_img.convert(\"RGB\")\n",
        "    init_img = init_img.resize((w, h))\n",
        "\n",
        "    fname = format_filename(prompt)\n",
        "    mask_name = f'{root_dir}{fname}-mask.png'\n",
        "    img_name = f'{root_dir}{fname}.png'\n",
        "    if os.path.isfile(img_name):\n",
        "      img_name = available_file(root_dir, fname, 1, False)\n",
        "    if os.path.isfile(mask_name):\n",
        "      mask_name = available_file(root_dir, fname, 1, True)\n",
        "    mask_img.save(mask_name)\n",
        "    init_img.save(img_name)\n",
        "    #print(str(img.name))\n",
        "    #print(str(img.filename))\n",
        "    image_strength = f'init_image_strength=0.4, ' if init_image_strength_override else ''\n",
        "    print(f'    Dream(\"{prompt}\", init_image=\"{img_name}\", mask_image=\"{mask_name}\", {image_strength}width={w}, height={h}),')\n",
        "    if prefs is not None:\n",
        "      prompt_pref = prefs['prompt_list']\n",
        "      new_dream = {'prompt': prompt, 'init_image': img_name, 'mask_image': mask_name, 'width': w, 'height': h}\n",
        "      if init_image_strength_override:\n",
        "        new_dream['init_image_strength':]\n",
        "      prompt_pref.append(new_dream)\n",
        "      prefs['prompt_list'] = prompt_pref\n",
        "      print(\"Added to your Stable Diffusion Deluxe Prompts List (in saved preferences)\")\n",
        "    #display(mask)\n",
        "    return f'Dream(\"{prompt}\", init_image=\"{img_name}\", mask_image=\"{mask_name}\", {image_strength}width={w}, height={h}),'\n",
        "\n",
        "block = gr.Blocks(css=\".container { max-width: 1200px; margin: auto; }\")\n",
        "with block as demo:\n",
        "    gr.Markdown(\"<h1><center>Stable Diffusion Inpaint Dream Mask Maker</center></h1>\")\n",
        "    with gr.Group():\n",
        "        with gr.Row().style(mobile_collapse=False, equal_height=False):\n",
        "                text = gr.Textbox(\n",
        "                    label=\"Enter your Inpaint prompt\", show_label=True, max_lines=1\n",
        "                ).style(\n",
        "                    border=(True, False, True, True),\n",
        "                    rounded=(True, False, False, True),\n",
        "                    container=False,\n",
        "                )\n",
        "        with gr.Row().style(mobile_collapse=False, equal_height=True):\n",
        "          option = gr.Radio(label=\"Masking\", choices=[\"Replace selection\", \"Replace everything else\"], value=\"Replace selection\")\n",
        "          btn = gr.Button(\"Prepare Dream\").style(\n",
        "                    margin=True,\n",
        "                    rounded=(True, True, True, True),\n",
        "                )\n",
        "        image = gr.Image(\n",
        "            tool=\"sketch\",\n",
        "            source=\"upload\",\n",
        "            #image_mode=\"L\", shape=(42, 42), invert_colors=True,\n",
        "            label=\"Input Init Image\",\n",
        "            type=\"pil\"\n",
        "            #type=\"numpy\"\n",
        "        )\n",
        "        gallery = gr.Markdown('')\n",
        "        #gallery = gr.Gallery(label=\"Generated mask_image\", show_label=False).style(grid=[2], height=\"auto\")\n",
        "        text.submit(create, inputs=[text,image,option], outputs=gallery)\n",
        "        btn.click(create, inputs=[text,image,option], outputs=gallery)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xM0rAUJzYuVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAcYiftnvHGL"
      },
      "source": [
        "---\n",
        "# üìÑ **PyDrive2 Google Drive** Setup Instructions (for non-Colab Jupyter notebooks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQf4CWmfuIEg"
      },
      "source": [
        "Drive API requires OAuth2.0 for authentication. PyDrive2 makes your life much easier by handling complex authentication steps for you.\n",
        "\n",
        "* [Go to APIs Console](https://console.developers.google.com/iam-admin/projects) and make your own project.\n",
        "* Search for ‚ÄòGoogle Drive API‚Äô, select the entry, and click ‚ÄòEnable‚Äô.\n",
        "* Select ‚ÄòCredentials‚Äô from the left menu, click ‚ÄòCreate Credentials‚Äô, select ‚ÄòOAuth client ID‚Äô.\n",
        "* Now, the product name and consent screen need to be set -> click ‚ÄòConfigure consent screen‚Äô and follow the instructions. Once finished:\n",
        "* Select _‚ÄòApplication type‚Äô_ to be Web application.\n",
        "* Enter an appropriate name.\n",
        "* Input http://localhost:8080/ for ‚ÄòAuthorized redirect URIs‚Äô.\n",
        "* Click ‚ÄòCreate‚Äô.\n",
        "* Click ‚ÄòDownload JSON‚Äô on the right side of Client ID to download client_secret_<really long ID>.json.\n",
        "* The downloaded file has all authentication information of your application. Rename the file to ‚Äú**client_secrets.json**‚Äù and place it in your working directory.\n",
        "* Copy file to project dir and link path to Google_OAuth_client_secret_json"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "za8wL7yUJJYI"
      ],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "aecaad1160391d286dea8adfafabc0106aa931e7deb6a40f00e2f89f1c4ee412"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}